{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of hackaton.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpmSbtrCklRB",
        "colab_type": "code",
        "outputId": "b8aba03c-1f2b-49ab-86f9-bd47e54b4c3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNLhWWCxYfLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "import scipy\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import logging\n",
        "import multiprocessing\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8IzA7Rx-VzU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Bidirectional, GlobalMaxPooling1D, GlobalMaxPool1D, MaxPooling1D, Flatten, concatenate\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras import initializers, regularizers, constraints, optimizers, layers\n",
        "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1vZGIRYYR9G",
        "colab_type": "text"
      },
      "source": [
        "# Hanna's data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFKrCtLZYBcV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import zipfile\n",
        "#with zipfile.ZipFile('./drive/My Drive/hackaton/wili-2018.zip', 'r') as zip_ref:\n",
        "#    zip_ref.extractall('./')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcwIDfWAYOUl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data_path = '/content/drive/My Drive/Colab Notebooks/Hackathon/'\n",
        "#wili_data_path = ''\n",
        "\n",
        "#x_train_path = wili_data_path + 'x_train.txt'\n",
        "#x_test_path = wili_data_path + 'x_test.txt'\n",
        "#y_train_path = wili_data_path + 'y_train.txt'\n",
        "#y_test_path = wili_data_path + 'y_test.txt'\n",
        "#labels_path = wili_data_path + 'labels.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc94smEhjbA_",
        "colab_type": "text"
      },
      "source": [
        "# Download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75potnAshWU4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path = '/content/drive/My Drive/Colab Notebooks/Hackathon/'\n",
        "wili_data_path = data_path + 'wili-2018/'\n",
        "\n",
        "x_train_path = wili_data_path + 'x_train.txt'\n",
        "x_test_path = wili_data_path + 'x_test.txt'\n",
        "y_train_path = wili_data_path + 'y_train.txt'\n",
        "y_test_path = wili_data_path + 'y_test.txt'\n",
        "labels_path = wili_data_path + 'labels.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhsiujWS3QR8",
        "colab_type": "code",
        "outputId": "3b15ecab-b6ea-475b-b899-f7e6e20228c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "labels = pd.read_csv(labels_path, sep=';')\n",
        "labels = labels.drop(labels=['German', 'Writing system', 'Remarks', 'Synonyms'], axis=1)\n",
        "labels"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>English</th>\n",
              "      <th>Wiki Code</th>\n",
              "      <th>ISO 369-3</th>\n",
              "      <th>Language family</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ace</td>\n",
              "      <td>Achinese</td>\n",
              "      <td>ace</td>\n",
              "      <td>ace</td>\n",
              "      <td>Austronesian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>afr</td>\n",
              "      <td>Afrikaans</td>\n",
              "      <td>af</td>\n",
              "      <td>afr</td>\n",
              "      <td>Indo-European</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>als</td>\n",
              "      <td>Alemannic German</td>\n",
              "      <td>als</td>\n",
              "      <td>gsw</td>\n",
              "      <td>Indo-European</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>amh</td>\n",
              "      <td>Amharic</td>\n",
              "      <td>am</td>\n",
              "      <td>amh</td>\n",
              "      <td>Afro-Asiatic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ang</td>\n",
              "      <td>Old English</td>\n",
              "      <td>ang</td>\n",
              "      <td>ang</td>\n",
              "      <td>Indo-European</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>230</th>\n",
              "      <td>yid</td>\n",
              "      <td>Yiddish</td>\n",
              "      <td>yi</td>\n",
              "      <td>yid</td>\n",
              "      <td>Indo-European</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>231</th>\n",
              "      <td>yor</td>\n",
              "      <td>Yoruba</td>\n",
              "      <td>yo</td>\n",
              "      <td>yor</td>\n",
              "      <td>Niger-Congo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>232</th>\n",
              "      <td>zea</td>\n",
              "      <td>Zeeuws</td>\n",
              "      <td>zea</td>\n",
              "      <td>zea</td>\n",
              "      <td>Indo-European</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>233</th>\n",
              "      <td>zh-yue</td>\n",
              "      <td>Cantonese</td>\n",
              "      <td>zh-yue</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Sino-Tibetan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>234</th>\n",
              "      <td>zho</td>\n",
              "      <td>Standard Chinese</td>\n",
              "      <td>zh</td>\n",
              "      <td>zho</td>\n",
              "      <td>Sino-Tibetan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>235 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Label           English Wiki Code ISO 369-3 Language family\n",
              "0       ace          Achinese       ace       ace    Austronesian\n",
              "1       afr         Afrikaans        af       afr   Indo-European\n",
              "2       als  Alemannic German       als       gsw   Indo-European\n",
              "3       amh           Amharic        am       amh    Afro-Asiatic\n",
              "4       ang      Old English        ang       ang   Indo-European\n",
              "..      ...               ...       ...       ...             ...\n",
              "230     yid           Yiddish        yi       yid   Indo-European\n",
              "231     yor            Yoruba        yo       yor     Niger-Congo\n",
              "232     zea            Zeeuws       zea       zea   Indo-European\n",
              "233  zh-yue         Cantonese    zh-yue       NaN    Sino-Tibetan\n",
              "234     zho  Standard Chinese        zh       zho    Sino-Tibetan\n",
              "\n",
              "[235 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpH6qYnlYrBN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_to_language = labels.Label.astype(str).to_dict()\n",
        "language_to_class = {v: k for k, v in class_to_language.items()}\n",
        "num_classes = len(class_to_language)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDFr3-rKmDdv",
        "colab_type": "code",
        "outputId": "1d5fb5bd-2475-444f-8621-1d2c3b71cd93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(list(language_to_class.items())[:5])\n",
        "num_classes"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('ace', 0), ('afr', 1), ('als', 2), ('amh', 3), ('ang', 4)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "235"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBqkjck1Yc7q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_data():\n",
        "    with open(x_train_path) as f:\n",
        "        mylist = f.read().splitlines() \n",
        "    x_train = pd.DataFrame(mylist, columns=[\"sent\"])\n",
        "    with open(x_test_path) as f:\n",
        "        mylist = f.read().splitlines() \n",
        "    x_test = pd.DataFrame(mylist, columns=[\"sent\"])\n",
        "\n",
        "    with open(y_train_path) as f:\n",
        "        mylist = f.read().splitlines() \n",
        "    y_train = []\n",
        "    for lan in mylist:\n",
        "        y_train.append(language_to_class[lan])\n",
        "    y_train = pd.DataFrame(y_train)\n",
        "    with open(y_test_path) as f:\n",
        "        mylist = f.read().splitlines()\n",
        "\n",
        "    y_test = []\n",
        "    for lan in mylist:\n",
        "        y_test.append(language_to_class[lan])\n",
        "    y_test = pd.DataFrame(y_test)\n",
        "    \n",
        "    return (x_train, y_train), (x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRo0Wf1lZXsE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = read_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhKRW6V8hhIc",
        "colab_type": "code",
        "outputId": "d3dcf0f0-8089-419d-ea18-31e71fd597ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "print(x_train.head())\n",
        "print(y_train.head())\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                sent\n",
            "0  Klement Gottwaldi surnukeha palsameeriti ning ...\n",
            "1  Sebes, Joseph; Pereira Thomas (1961) (på eng)....\n",
            "2  भारतीय स्वातन्त्र्य आन्दोलन राष्ट्रीय एवम क्षे...\n",
            "3  Après lo cort periòde d'establiment a Basilèa,...\n",
            "4  ถนนเจริญกรุง (อักษรโรมัน: Thanon Charoen Krung...\n",
            "     0\n",
            "0   52\n",
            "1  198\n",
            "2  124\n",
            "3  155\n",
            "4  207\n",
            "(117500, 1)\n",
            "(117500, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zcUciRigFYu",
        "colab_type": "code",
        "outputId": "5937e64c-93a7-42f4-b137-3db0acb72726",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "lens = x_train.sent.str.split(' ').str.len().values\n",
        "plt.hist(lens, bins=np.linspace(0,1000,20), facecolor='blue', alpha=0.9)\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xdCSiHnhlX1",
        "colab_type": "text"
      },
      "source": [
        "# Experiment on small dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFTqOQmChknq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# small_dataset = pd.read_csv(data_path + 'kaggle_dataset/dataset.csv')\n",
        "# small_dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwtWy38ehtGO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X=small_dataset['Text']\n",
        "# y=small_dataset['language']\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# print(len(X_train))\n",
        "# print(len(X_test))\n",
        "# print(len(y_train))\n",
        "# print(len(y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNoYz_IwjeY_",
        "colab_type": "text"
      },
      "source": [
        "# Embedding **data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEr8pklSjQLP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filter_out = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n1234567890'\n",
        "tokenizer = Tokenizer(filters=filter_out, lower=True)\n",
        "tokenizer.fit_on_texts(x_train.sent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5jxVwDcftcn",
        "colab_type": "text"
      },
      "source": [
        "Выбираю какое количество слов оставить. Если оставлять все, то будет 1500000, что слишком много. Можно поменять `count` и оно покажет сколько слов встречается больше, чем `count` раз"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xKQt34TAG2-",
        "colab_type": "code",
        "outputId": "713c201c-ef0d-42aa-9d11-c07c5acf3965",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# try different values of `count`\n",
        "# show how many words are presenting more than `count` times\n",
        "count = 10\n",
        "frequent_words = [w for w,c in tokenizer.word_counts.items() if c > count]\n",
        "len(frequent_words)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64157"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwDeU_wRph8C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_data(train_x, train_y, tokenizator, max_len_of_vector):\n",
        "    x_tr, x_val, y_tr, y_val = train_test_split(train_x, train_y, test_size=0.1, random_state=1, stratify=train_y.values)\n",
        "   \n",
        "    tokenizator.fit_on_texts(x_tr.sent)\n",
        "\n",
        "    train_X = tokenizator.texts_to_sequences(x_tr.sent)\n",
        "    val_X = tokenizator.texts_to_sequences(x_val.sent)\n",
        "\n",
        "    ## Pad the sentences \n",
        "    train_X = pad_sequences(train_X, maxlen=max_len_of_vector)\n",
        "    val_X = pad_sequences(val_X, maxlen=max_len_of_vector)\n",
        "\n",
        "    return (train_X, y_tr), (val_X, y_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJacuBHhHEng",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embed_size = 300 # how big is each word vector\n",
        "max_features = len(frequent_words) # how many unique words to use (i.e num rows in embedding vector)\n",
        "maxlen = 200 # max number of words in a question to use\n",
        "\n",
        "## Tokenize the sentences\n",
        "tokenizer = Tokenizer(num_words=max_features, filters=filter_out, lower=True)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qW1oK9wfHEnm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_X, train_Y), (val_X, val_Y) = prepare_data(x_train, y_train, tokenizer, maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxyyqzKsgF9K",
        "colab_type": "text"
      },
      "source": [
        "Проверила, что в тренировочном и валидационном датасетах встречаются все классы. Балансировка регулируется вот этим параметром: stratify=y_train.values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1iJF7cyU5iK",
        "colab_type": "code",
        "outputId": "0e2796e5-74ff-40f6-ffaa-9fa0044504d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(set(val_Y.values.reshape(1, -1)[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "235"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPITYtR8UqNx",
        "colab_type": "code",
        "outputId": "bd6109d0-bee2-49da-e883-fa693349294c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(set(train_Y.values.reshape(1, -1)[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "235"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYuurOSQgYUl",
        "colab_type": "text"
      },
      "source": [
        "Ниже меняю представление векторов ответов из [1, 23, 10,...] в вектор длины 235 и с 1 на месте соответсвующего языка"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0iIyf4bIXg_",
        "colab_type": "code",
        "outputId": "cf095999-bdf1-4ad0-f0ca-ee48aeff00b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "lb = LabelEncoder()\n",
        "y = lb.fit_transform(train_Y.values)\n",
        "dummy_y_train = to_categorical(y)\n",
        "print(len(dummy_y_train))\n",
        "print(len(dummy_y_train[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "105750\n",
            "235\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:251: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCBYAruyIxUm",
        "colab_type": "code",
        "outputId": "8e017e4b-2ea7-4c28-fa64-b80035ec4555",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "y = lb.fit_transform(val_Y.values)\n",
        "dummy_y_val = to_categorical(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:251: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeXXgZJ6miyl",
        "colab_type": "text"
      },
      "source": [
        "# Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vp4rfHfplm6O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f1(y_true, y_pred): #taken from old keras source code\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return f1_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dzi3zyNsmNIR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def recall(y_true, y_pred): #taken from old keras source code\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    return true_positives / (possible_positives + K.epsilon())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JX13CaozmRhy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def precision(y_true, y_pred): #taken from old keras source code\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    return true_positives / (predicted_positives + K.epsilon())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtGH8P89gTXf",
        "colab_type": "text"
      },
      "source": [
        "#CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdsE9d9SjdsW",
        "colab_type": "code",
        "outputId": "a4d07a9a-e05b-4f1b-a701-cbf8acb49cc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        }
      },
      "source": [
        "cnn_model = Sequential()\n",
        "cnn_model.add(Embedding(max_features, embed_size,input_shape=(maxlen,)))\n",
        "cnn_model.add(Conv1D(256, 5, activation='relu', input_shape=(embed_size,)))\n",
        "cnn_model.add(MaxPooling1D(5))\n",
        "cnn_model.add(Dropout(0.2))\n",
        "cnn_model.add(Conv1D(256, 5, activation='relu'))\n",
        "cnn_model.add(MaxPooling1D(5))\n",
        "cnn_model.add(Flatten())\n",
        "cnn_model.add(Dense(512, activation=\"relu\"))\n",
        "cnn_model.add(Dropout(0.2))\n",
        "cnn_model.add(Dense(num_classes, activation='softmax'))\n",
        "cnn_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 200, 300)          19247100  \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 196, 256)          384256    \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 39, 256)           0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 39, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 35, 256)           327936    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 7, 256)            0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1792)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               918016    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 235)               120555    \n",
            "=================================================================\n",
            "Total params: 20,997,863\n",
            "Trainable params: 20,997,863\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sndko3XlZ806",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', f1, recall, precision])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aa9rf4_Oq6nX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn_cp_path = data_path+'model_cnn.hdf5'\n",
        "cnn_cp=ModelCheckpoint(cnn_cp_path, monitor='val_loss',save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIhz76oFHo_c",
        "colab_type": "code",
        "outputId": "9aebd8bb-4d02-4870-c6a5-7112d5901217",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "cnn_model.fit(train_X, dummy_y_train, batch_size=512, epochs=5, \n",
        "              validation_data=(val_X, dummy_y_val),\n",
        "              callbacks = [cnn_cp]\n",
        "             )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "207/207 [==============================] - 57s 277ms/step - loss: 0.2398 - accuracy: 0.9342 - f1: 0.9476 - recall: 0.9183 - precision: 0.9789 - val_loss: 0.5040 - val_accuracy: 0.8928 - val_f1: 0.9124 - val_recall: 0.8751 - val_precision: 0.9531\n",
            "Epoch 2/5\n",
            "207/207 [==============================] - 56s 270ms/step - loss: 0.1736 - accuracy: 0.9495 - f1: 0.9601 - recall: 0.9371 - precision: 0.9844 - val_loss: 0.5702 - val_accuracy: 0.8906 - val_f1: 0.9106 - val_recall: 0.8776 - val_precision: 0.9463\n",
            "Epoch 3/5\n",
            "207/207 [==============================] - 55s 267ms/step - loss: 0.1442 - accuracy: 0.9568 - f1: 0.9671 - recall: 0.9473 - precision: 0.9878 - val_loss: 0.6290 - val_accuracy: 0.8901 - val_f1: 0.9063 - val_recall: 0.8773 - val_precision: 0.9375\n",
            "Epoch 4/5\n",
            "207/207 [==============================] - 55s 265ms/step - loss: 0.1313 - accuracy: 0.9602 - f1: 0.9702 - recall: 0.9521 - precision: 0.9891 - val_loss: 0.6761 - val_accuracy: 0.8877 - val_f1: 0.9057 - val_recall: 0.8786 - val_precision: 0.9346\n",
            "Epoch 5/5\n",
            "207/207 [==============================] - 55s 266ms/step - loss: 0.1295 - accuracy: 0.9609 - f1: 0.9709 - recall: 0.9536 - precision: 0.9888 - val_loss: 0.7026 - val_accuracy: 0.8906 - val_f1: 0.9080 - val_recall: 0.8822 - val_precision: 0.9353\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb8f6b0c1d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkmpFZmyUjF8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dependencies = {\n",
        "     'f1': f1,\n",
        "     'recall': recall,\n",
        "     'precision': precision\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qji8xqW2WiS-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cnn_model = load_model(cnn_cp_path, custom_objects=dependencies)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-T-4MO1ZR_S",
        "colab_type": "text"
      },
      "source": [
        "#RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ch0GFZ-ZSzb",
        "colab_type": "code",
        "outputId": "2d842e33-e0f9-4b8e-ae8d-e6d2b85eb4cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "rnn_model = Sequential()\n",
        "rnn_model.add(Embedding(max_features, embed_size))\n",
        "rnn_model.add(Bidirectional(LSTM(128, return_sequences=True, activation='tanh',input_dim=embed_size)))\n",
        "rnn_model.add(Dropout(0.2))\n",
        "rnn_model.add(Bidirectional(LSTM(128, return_sequences=True, activation='tanh')))\n",
        "rnn_model.add(GlobalMaxPool1D())\n",
        "rnn_model.add(Dropout(0.2))\n",
        "rnn_model.add(Dense(512, activation=\"relu\"))\n",
        "rnn_model.add(Dropout(0.2))\n",
        "rnn_model.add(Dense(num_classes, activation='softmax'))\n",
        "rnn_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 300)         19247100  \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, None, 512)         1140736   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, None, 512)         0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, None, 512)         1574912   \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 235)               120555    \n",
            "=================================================================\n",
            "Total params: 22,345,959\n",
            "Trainable params: 22,345,959\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1W3XFHXZiVR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', f1, recall, precision])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPtLB7kUrGgE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rnn_cp_path = data_path + 'model_rnn.hdf5'\n",
        "rnn_cp=ModelCheckpoint(rnn_cp_path,monitor='val_f1',save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qK-tgijZk7L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# rnn_model.fit(train_X, dummy_y_train, batch_size=512, epochs=3, \n",
        "#               validation_data=(val_X, dummy_y_val), callbacks = [rnn_cp])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kk3g4PLUumt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rnn_model = load_model(rnn_cp_path, custom_objects=dependencies)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCeuUze_qnC2",
        "colab_type": "text"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jS0Tq-Cqb4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test['sc'] = y_test\n",
        "x_test['lang'] = [class_to_language[y] for y in list(y_test.iloc[:,0])]\n",
        "x_train['sc'] = y_train\n",
        "x_train['lang'] = [class_to_language[y] for y in list(y_train.iloc[:,0])]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wowtwiinqwm0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Be careful! Tokenizer and maxlen is taken from train dataset from 1st part\n",
        "def convert(x, tokenizator, max_vector_len):\n",
        "    train_X = tokenizator.texts_to_sequences(x.sent)\n",
        "    ## Pad the sentences \n",
        "    train_X = pad_sequences(train_X, maxlen=max_vector_len)\n",
        "    return train_X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvOMHL7Nx_eO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def metr(y_true, y_pred): #taken from old keras source code\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return precision, recall, f1_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hs6AXcPcsj1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f1(y_true, y_pred):\n",
        "    y_pred = K.round(y_pred)\n",
        "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
        "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
        "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
        "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
        "\n",
        "    p = tp / (tp + fp + K.epsilon())\n",
        "    r = tp / (tp + fn + K.epsilon())\n",
        "\n",
        "    f1 = 2*p*r / (p+r+K.epsilon())\n",
        "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
        "    return max(p), max(r), max(f1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adUqSHYSc2Ye",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# New metric!\n",
        "def f1_met(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)), axis=0)\n",
        "    false_positives = K.sum(K.round(K.clip((1 - y_true) * y_pred, 0, 1)), axis=0)\n",
        "    true_negatives = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)), axis=0)\n",
        "    false_negatives = K.sum(K.round(K.clip(y_true * (1 - y_pred), 0, 1)), axis=0)\n",
        "    precision = max(true_positives / (true_positives + false_positives  + K.epsilon()))\n",
        "    recall = max(true_positives / (true_positives + false_negatives  + K.epsilon()))\n",
        "    f1 = 2 * precision * recall / (precision + recall + K.epsilon())\n",
        "    return precision, recall, f1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OwT-3obvsIo",
        "colab_type": "text"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P006Z5Sgzeal",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "a8263a88-ac57-45b5-dc8b-ca0d433936a8"
      },
      "source": [
        "ps = []\n",
        "rs = []\n",
        "fs = []\n",
        "for lan in range(num_classes):\n",
        "    x_t = x_test[x_test['sc'] == lan]\n",
        "    x = convert(x_t, tokenizer, maxlen)\n",
        "    y = np.zeros((x.shape[0], num_classes))\n",
        "    y[:, lan] = 1\n",
        "    y = y.astype('float32')\n",
        "    y_pred = cnn_model.predict(x)\n",
        "    p, r, f = met(y, y_pred)\n",
        "    ps.append(p.numpy())\n",
        "    rs.append(r.numpy())\n",
        "    fs.append(f.numpy())\n",
        "    #print(\"language: \", class_to_language[lan], \"precision: \", p.numpy(), \"recall: \", r.numpy(), \"f1: \", f.numpy())"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-fc647d125cd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlan\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mx_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sc'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlan\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlan\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jFoYvQVzg0C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_metrics = pd.DataFrame(\n",
        "    {'precision': ps,\n",
        "     'recall': rs,\n",
        "     'f1': fs\n",
        "    })"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXV6tZ4Dzh4L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "metrics = raw_metrics.rename(class_to_language, axis='index')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zstxcPVgfUig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bad_quality_metrics = metrics[metrics.f1 < 0.7]\n",
        "lab = labels.set_index('Label')\n",
        "bad_quality_labels = lab.loc[bad_quality_metrics.index]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaImgEefHae0",
        "colab_type": "code",
        "outputId": "3bd7446b-545b-4073-ffa8-c6b222f13f06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "res = pd.merge(bad_quality_labels.reset_index(), bad_quality_metrics.reset_index()) \\\n",
        ".set_index('index')\n",
        "res"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Wiki Code</th>\n",
              "      <th>ISO 369-3</th>\n",
              "      <th>Language family</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>bod</th>\n",
              "      <td>Tibetan</td>\n",
              "      <td>bo</td>\n",
              "      <td>bod</td>\n",
              "      <td>Sino-Tibetan</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.166</td>\n",
              "      <td>0.284734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hrv</th>\n",
              "      <td>Croatian</td>\n",
              "      <td>hr</td>\n",
              "      <td>hrv</td>\n",
              "      <td>Indo-European</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.522</td>\n",
              "      <td>0.685939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>jpn</th>\n",
              "      <td>Japanese</td>\n",
              "      <td>ja</td>\n",
              "      <td>jpn</td>\n",
              "      <td>Japonic</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.114</td>\n",
              "      <td>0.204668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>khm</th>\n",
              "      <td>Central Khmer</td>\n",
              "      <td>km</td>\n",
              "      <td>khm</td>\n",
              "      <td>Austronesian</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.432</td>\n",
              "      <td>0.603352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lzh</th>\n",
              "      <td>Literary Chinese</td>\n",
              "      <td>zh-classical</td>\n",
              "      <td>lzh</td>\n",
              "      <td>Sino-Tibetan</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tha</th>\n",
              "      <td>Thai</td>\n",
              "      <td>th</td>\n",
              "      <td>tha</td>\n",
              "      <td>Tai-Kadai</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.530</td>\n",
              "      <td>0.692810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>wuu</th>\n",
              "      <td>Wu Chinese</td>\n",
              "      <td>wuu</td>\n",
              "      <td>wuu</td>\n",
              "      <td>Sino-Tibetan</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.030</td>\n",
              "      <td>0.058252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zh-yue</th>\n",
              "      <td>Cantonese</td>\n",
              "      <td>zh-yue</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Sino-Tibetan</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.068</td>\n",
              "      <td>0.127341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zho</th>\n",
              "      <td>Standard Chinese</td>\n",
              "      <td>zh</td>\n",
              "      <td>zho</td>\n",
              "      <td>Sino-Tibetan</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.054</td>\n",
              "      <td>0.102467</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 English     Wiki Code ISO 369-3  ... precision  recall        f1\n",
              "index                                             ...                            \n",
              "bod              Tibetan            bo       bod  ...       1.0   0.166  0.284734\n",
              "hrv             Croatian            hr       hrv  ...       1.0   0.522  0.685939\n",
              "jpn             Japanese            ja       jpn  ...       1.0   0.114  0.204668\n",
              "khm        Central Khmer            km       khm  ...       1.0   0.432  0.603352\n",
              "lzh     Literary Chinese  zh-classical       lzh  ...       0.0   0.000  0.000000\n",
              "tha                 Thai            th       tha  ...       1.0   0.530  0.692810\n",
              "wuu           Wu Chinese           wuu       wuu  ...       1.0   0.030  0.058252\n",
              "zh-yue         Cantonese        zh-yue       NaN  ...       1.0   0.068  0.127341\n",
              "zho     Standard Chinese            zh       zho  ...       1.0   0.054  0.102467\n",
              "\n",
              "[9 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUkII9aS9iK1",
        "colab_type": "code",
        "outputId": "ac207c1c-4c4b-4b44-973d-b02b18116454",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        }
      },
      "source": [
        "print(x_train[x_train.sc == language_to_class['wuu']])\n",
        "print(x_train[x_train.sc == language_to_class['lzh']])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                     sent   sc\n",
            "19      UNC有得一只历史悠久个'诚信守则'。渠是由学堂个诚信法庭（Honor Court）来执行个...  227\n",
            "276     武器，是人类为达到杀伤或者防御个目的制造个器械。武器从人类文明发展开始就有出现，之后，伴随战...  227\n",
            "387     弗过，太后个信任是一方面，具体西班牙个政治局面又是另外一番情形：贵族对迭个外国人一点也无信任...  227\n",
            "720     从12世纪挨末阶段开始，日本个统治权就转移到日本武士贵族个手里向。到13世纪，出身清和源氏个...  227\n",
            "930     箇种毛病潜伏期一般勒7日天以内，病人一般表现为流感箇浪个症状，像发寒热，咳嗽，少痰，有种辰光...  227\n",
            "...                                                   ...  ...\n",
            "116805  Linux個低成本、強大個定制功能搭良好個移植性能，使得Linux來嵌入式系統方面也得到廣泛...  227\n",
            "116947  余杭區勒拉杭嘉湖平原南端，西依天目山，南瀕錢塘江，是長江三角洲个圓心地。地理座標爲北緯30°...  227\n",
            "117034  北師大是以京師大學堂師範專業做基礎，搭仔由北京個高校匯聚一批勒師範教育領域窮有聲望個名師組建...  227\n",
            "117037  到清中期（約18世紀），傳奇開始衰微，向書齋文學轉化，彈詞卻逐步興盛起來了。出版之錢德蒼編个...  227\n",
            "117257  摩嘉娜夺权计划失败后，带领奄奄一息个莫高絲逃出卡美洛特，徕萨温节夜里，摩嘉娜徕莫高絲个要求之...  227\n",
            "\n",
            "[500 rows x 2 columns]\n",
            "                                                     sent   sc\n",
            "336     武漢市，亦稱以漢，乃中華鄂省之會，亦為七大都市於中華之中原也。方八千四百六十七公里，於西元二...  123\n",
            "420     按黃帝為法，數有十等。及其用也，乃有三焉。十等者，謂「億、兆、京、垓、秭、壤、溝、澗、正、載...  123\n",
            "1254    范蠡浮海出齊，變姓名，自謂鴟夷子皮，耕於海畔，苦身戮力，父子治產。居無幾何，致產數千萬。齊人...  123\n",
            "1414    周迪據臨川反，詔昭達便道征之。迪敗走，徵為護軍將軍，改封邵武縣侯。四年，陳寶應納迪，共寇臨川...  123\n",
            "1549    喇克達長子敬德，康熙十一年(一六七二年)封三等奉恩將軍，四十七年(一七零八年)卒。敬德次子班...  123\n",
            "...                                                   ...  ...\n",
            "116047  士族者，或曰門第、衣冠、世族、門閥、勢族、世家、巨室。蓋謂世居要位之高門也，世族所居不同，中...  123\n",
            "116419  淳化二年秋七月，李繼遷請降，以爲銀州觀察使，賜姓名趙保吉。繼捧至夏州數月，即言繼遷悔過歸款，...  123\n",
            "116596  孟嘗君怨秦，將以齊為韓、魏攻楚，因與韓、魏攻秦，而借兵食於西周。蘇代為西周謂曰：「君以齊為韓...  123\n",
            "116749  陳敏之亂，弘以侃為江夏太守，加鷹揚將軍。侃備威儀，迎母官舍，鄉裡榮之。敏遣其弟恢來寇武昌，侃...  123\n",
            "117497  同年，太后崩。絳侯周勃、陳平諸臣共謀誅呂。朱虛侯章已殺呂產，文帝使人持節勞章。朱虛侯欲奪節信...  123\n",
            "\n",
            "[500 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dH862g-VYj8J",
        "colab_type": "text"
      },
      "source": [
        "# Fix Chinese langs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yltabFr0UYF_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_features_chinese = 10000\n",
        "\n",
        "## Tokenize the sentences\n",
        "tokenizer_chinese = Tokenizer(num_words=max_features_chinese, char_level=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuUBpVDruwFi",
        "colab_type": "code",
        "outputId": "0f30e405-ee50-49ca-b46d-61abf17f155f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        }
      },
      "source": [
        "x_train_bad = x_train.set_index('lang')\n",
        "bad_quality_langs_train = x_train_bad.loc[bad_quality_metrics.index]\n",
        "bad_quality_langs_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sent</th>\n",
              "      <th>sc</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lang</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>bod</th>\n",
              "      <td>༡༩༣༥ལོར་ཞང་པོ་དང་ལྷན་དུ་ནན་ཅིང་དུ་སློབ་སྦྱོང་མ...</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bod</th>\n",
              "      <td>བཀའ་རྩ་གསལ་བསྒྲགས་དངོས་ཤོག་གྲངས་ ༡༢ ལ་བཀོད་ཡོད...</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bod</th>\n",
              "      <td>སྤྱི་ལོ་༡༩༥༣ལོའི་ཟླ་བ་༨པར་སྨན་པས་ཁོང་གི་རྐང་པ་...</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bod</th>\n",
              "      <td>ཐ་མལ་དུ་གནས་པའི་མི་དར་མའི་སྙིང་གི་ཕར་ཚད་ནི་དུས...</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bod</th>\n",
              "      <td>ཀློང་རྡོལ་བླ་མ་རིན་པོ་ཆེའི་བརྟག་ཐབས་ནང་སྤོས་ཤེ...</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zho</th>\n",
              "      <td>赛里木湖属于封闭型的断陷湖，是地壳下沉形成洼地，由四周的高山雪水历百万年慢慢汇聚而成。如今主...</td>\n",
              "      <td>234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zho</th>\n",
              "      <td>约瑟夫·维萨里奥诺维奇·泽·朱加什维利生于俄罗斯帝国哥里，毕业于梯弗里斯神学院。成为马克思主...</td>\n",
              "      <td>234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zho</th>\n",
              "      <td>和印度其他地方一样，板球也是孟买最为流行的一项运动。板球比赛通常在遍布全市的操场上进行。后院...</td>\n",
              "      <td>234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zho</th>\n",
              "      <td>1994年，邓斯特还与薇诺娜·瑞德和克萊兒·丹妮絲一起出演了同名原著改编的电影《小妇人》，该...</td>\n",
              "      <td>234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zho</th>\n",
              "      <td>4月8日首度訪泰，在新聞發布會現場超過200名記者爭相採訪，泰國主要的7頻道及報章雜誌等均大...</td>\n",
              "      <td>234</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4500 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   sent   sc\n",
              "lang                                                        \n",
              "bod   ༡༩༣༥ལོར་ཞང་པོ་དང་ལྷན་དུ་ནན་ཅིང་དུ་སློབ་སྦྱོང་མ...   22\n",
              "bod   བཀའ་རྩ་གསལ་བསྒྲགས་དངོས་ཤོག་གྲངས་ ༡༢ ལ་བཀོད་ཡོད...   22\n",
              "bod   སྤྱི་ལོ་༡༩༥༣ལོའི་ཟླ་བ་༨པར་སྨན་པས་ཁོང་གི་རྐང་པ་...   22\n",
              "bod   ཐ་མལ་དུ་གནས་པའི་མི་དར་མའི་སྙིང་གི་ཕར་ཚད་ནི་དུས...   22\n",
              "bod   ཀློང་རྡོལ་བླ་མ་རིན་པོ་ཆེའི་བརྟག་ཐབས་ནང་སྤོས་ཤེ...   22\n",
              "...                                                 ...  ...\n",
              "zho   赛里木湖属于封闭型的断陷湖，是地壳下沉形成洼地，由四周的高山雪水历百万年慢慢汇聚而成。如今主...  234\n",
              "zho   约瑟夫·维萨里奥诺维奇·泽·朱加什维利生于俄罗斯帝国哥里，毕业于梯弗里斯神学院。成为马克思主...  234\n",
              "zho   和印度其他地方一样，板球也是孟买最为流行的一项运动。板球比赛通常在遍布全市的操场上进行。后院...  234\n",
              "zho   1994年，邓斯特还与薇诺娜·瑞德和克萊兒·丹妮絲一起出演了同名原著改编的电影《小妇人》，该...  234\n",
              "zho   4月8日首度訪泰，在新聞發布會現場超過200名記者爭相採訪，泰國主要的7頻道及報章雜誌等均大...  234\n",
              "\n",
              "[4500 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXhcTGMaYZXt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_X_chinese, train_Y_chinese), (val_X_chinese, val_Y_chinese) = \\\n",
        "prepare_data(bad_quality_langs_train, bad_quality_langs_train.sc, tokenizer_chinese, maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IA91PJA_Nvio",
        "colab_type": "code",
        "outputId": "a26fcd30-9e03-48cf-bdb8-b0ad38ee7a00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "chinese_labels_dict = {lang:index for index, lang in enumerate(set(train_Y_chinese))}\n",
        "chinese_labels_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{22: 6, 77: 4, 92: 8, 99: 0, 123: 7, 207: 5, 227: 1, 233: 2, 234: 3}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubiHl-tGxu89",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dummy_y_train_chinese = to_categorical([chinese_labels_dict[lan] for lan in train_Y_chinese])\n",
        "dummy_y_val_chinese = to_categorical([chinese_labels_dict[lan] for lan in val_Y_chinese])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1Px5m0yyLUA",
        "colab_type": "code",
        "outputId": "43380ac7-7c0f-4020-f1b8-f5977af1b759",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        }
      },
      "source": [
        "cnn_model_chinese = Sequential()\n",
        "cnn_model_chinese.add(Embedding(max_features, embed_size,input_shape=(maxlen,)))\n",
        "cnn_model_chinese.add(Conv1D(256, 5, activation='relu', input_shape=(embed_size,)))\n",
        "cnn_model_chinese.add(MaxPooling1D(5))\n",
        "cnn_model_chinese.add(Dropout(0.2))\n",
        "cnn_model_chinese.add(Conv1D(256, 5, activation='relu'))\n",
        "cnn_model_chinese.add(MaxPooling1D(5))\n",
        "cnn_model_chinese.add(Flatten())\n",
        "cnn_model_chinese.add(Dense(512, activation=\"relu\"))\n",
        "cnn_model_chinese.add(Dropout(0.2))\n",
        "cnn_model_chinese.add(Dense(len(dummy_y_train_chinese[0]), activation='softmax'))\n",
        "cnn_model_chinese.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 200, 300)          19247100  \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 196, 256)          384256    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_4 (MaxPooling1 (None, 39, 256)           0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 39, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 35, 256)           327936    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_5 (MaxPooling1 (None, 7, 256)            0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 1792)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 512)               918016    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 9)                 4617      \n",
            "=================================================================\n",
            "Total params: 20,881,925\n",
            "Trainable params: 20,881,925\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlFTZRq8ya9i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn_model_chinese.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', f1, recall, precision])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QiHi0eYrgaU",
        "colab_type": "code",
        "outputId": "d0dbfbb9-ed23-493b-8018-337b391aa85e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "cnn_model_chinese.fit(train_X_chinese, dummy_y_train_chinese, batch_size=128, epochs=10, \n",
        "              validation_data=(val_X_chinese, dummy_y_val_chinese))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "8/8 [==============================] - 2s 237ms/step - loss: 0.0096 - accuracy: 0.9970 - f1: 0.9973 - recall: 0.9958 - precision: 0.9988 - val_loss: 0.2196 - val_accuracy: 0.9489 - val_f1: 0.9477 - val_recall: 0.9467 - val_precision: 0.9488\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 2s 237ms/step - loss: 0.0070 - accuracy: 0.9985 - f1: 0.9981 - recall: 0.9975 - precision: 0.9988 - val_loss: 0.2061 - val_accuracy: 0.9600 - val_f1: 0.9600 - val_recall: 0.9600 - val_precision: 0.9600\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 2s 239ms/step - loss: 0.0047 - accuracy: 0.9995 - f1: 0.9991 - recall: 0.9985 - precision: 0.9998 - val_loss: 0.2146 - val_accuracy: 0.9556 - val_f1: 0.9544 - val_recall: 0.9533 - val_precision: 0.9555\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 2s 233ms/step - loss: 0.0046 - accuracy: 0.9990 - f1: 0.9988 - recall: 0.9983 - precision: 0.9993 - val_loss: 0.2148 - val_accuracy: 0.9556 - val_f1: 0.9556 - val_recall: 0.9556 - val_precision: 0.9556\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 2s 240ms/step - loss: 0.0031 - accuracy: 1.0000 - f1: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.2138 - val_accuracy: 0.9578 - val_f1: 0.9588 - val_recall: 0.9578 - val_precision: 0.9599\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 2s 244ms/step - loss: 0.0027 - accuracy: 0.9998 - f1: 0.9996 - recall: 0.9995 - precision: 0.9997 - val_loss: 0.2099 - val_accuracy: 0.9600 - val_f1: 0.9611 - val_recall: 0.9600 - val_precision: 0.9621\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 2s 238ms/step - loss: 0.0025 - accuracy: 0.9998 - f1: 0.9998 - recall: 0.9998 - precision: 0.9998 - val_loss: 0.2082 - val_accuracy: 0.9600 - val_f1: 0.9588 - val_recall: 0.9578 - val_precision: 0.9599\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 2s 233ms/step - loss: 0.0034 - accuracy: 0.9990 - f1: 0.9990 - recall: 0.9990 - precision: 0.9990 - val_loss: 0.2101 - val_accuracy: 0.9533 - val_f1: 0.9565 - val_recall: 0.9533 - val_precision: 0.9597\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 2s 235ms/step - loss: 0.0018 - accuracy: 1.0000 - f1: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.2107 - val_accuracy: 0.9600 - val_f1: 0.9611 - val_recall: 0.9600 - val_precision: 0.9621\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 2s 240ms/step - loss: 0.0015 - accuracy: 1.0000 - f1: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.2198 - val_accuracy: 0.9600 - val_f1: 0.9600 - val_recall: 0.9600 - val_precision: 0.9600\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb8e91b6da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWwS0BKMsUGO",
        "colab_type": "code",
        "outputId": "c52f78fc-dfb3-4fab-bc9d-e70ff63a3367",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "ps_chinese = []\n",
        "rs_chinese = []\n",
        "fs_chinese = []\n",
        "short_len = len(set(train_Y_chinese))\n",
        "\n",
        "for lan in set(train_Y_chinese):\n",
        "    x_t = x_test[x_test['sc'] == lan]\n",
        "    x = convert(x_t, tokenizer_chinese, maxlen)\n",
        "    y = np.zeros((x.shape[0], short_len))\n",
        "    y[:, chinese_labels_dict[lan]] = 1\n",
        "    y = y.astype('float32')\n",
        "    y_pred = cnn_model_chinese.predict(x)\n",
        "    p, r, f = met(y, y_pred)\n",
        "    ps_chinese.append(p.numpy())\n",
        "    rs_chinese.append(r.numpy())\n",
        "    fs_chinese.append(f.numpy())\n",
        "    print(\"language: \", class_to_language[lan], \"precision: \", p.numpy(), \"recall: \", r.numpy(), \"f1: \", f.numpy())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "language:  khm precision:  1.0 recall:  0.966 f1:  0.98270595\n",
            "language:  wuu precision:  1.0 recall:  0.896 f1:  0.94514763\n",
            "language:  zh-yue precision:  1.0 recall:  0.928 f1:  0.96265554\n",
            "language:  zho precision:  1.0 recall:  0.936 f1:  0.9669421\n",
            "language:  hrv precision:  1.0 recall:  0.992 f1:  0.99598384\n",
            "language:  tha precision:  1.0 recall:  0.988 f1:  0.9939637\n",
            "language:  bod precision:  1.0 recall:  0.998 f1:  0.99899894\n",
            "language:  lzh precision:  1.0 recall:  0.994 f1:  0.996991\n",
            "language:  jpn precision:  1.0 recall:  0.998 f1:  0.99899894\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qimQESgMQpVG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JakikCyXZA0m",
        "colab_type": "text"
      },
      "source": [
        "#Hanna's try for merging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AszQrmS7ZeTd",
        "colab": {}
      },
      "source": [
        "filter_out = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n1234567890'\n",
        "## Tokenize the sentences\n",
        "tokenizer = Tokenizer(filters=filter_out, char_level=True)\n",
        "tokenizer.fit_on_texts(x_train.sent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HORVrXGGZDYZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3f541299-5ceb-46a1-d897-d87d75abf726"
      },
      "source": [
        "# try different values of `count`\n",
        "# show how many words are presenting more than `count` times\n",
        "count = 0\n",
        "frequent_words = [w for w,c in tokenizer.word_counts.items() if c > count]\n",
        "len(frequent_words)"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10489"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5VnelMpbh1z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer.fit_on_texts(x_train.sent)\n",
        "\n",
        "train_X = tokenizer.texts_to_sequences(x_train.sent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cppm020qbwi7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "52c0fe5b-3480-4ba6-e8af-c015239f554e"
      },
      "source": [
        "lens = [len(train_X[i]) for i in range(len(train_X))]\n",
        "plt.hist(lens, bins=np.linspace(0,1000,20), facecolor='blue', alpha=0.9)\n",
        "plt.show()"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVPnHv12cujE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXvyyaJAcsoE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_data(train_x, train_y, tokenizer_char, tokenizer_word, maxlen_char, maxlen_word):\n",
        "    x_tr, x_val, y_tr, y_val = train_test_split(train_x, train_y, test_size=0.1, random_state=1, stratify=train_y.values)\n",
        "\n",
        "    train_X_char = tokenizer_char.texts_to_sequences(x_tr.sent)\n",
        "    val_X_char = tokenizer_char.texts_to_sequences(x_val.sent)\n",
        "\n",
        "    train_X_word = tokenizer_word.texts_to_sequences(x_tr.sent)\n",
        "    val_X_word = tokenizer_word.texts_to_sequences(x_val.sent)\n",
        "\n",
        "    ## Pad chars\n",
        "    train_X_char = pad_sequences(train_X_char, maxlen=maxlen_char)\n",
        "    val_X_char = pad_sequences(val_X_char, maxlen=maxlen_char)\n",
        "\n",
        "    ## Pad words\n",
        "    train_X_word = pad_sequences(train_X_word, maxlen=maxlen_word)\n",
        "    val_X_word = pad_sequences(val_X_word, maxlen=maxlen_word)\n",
        "\n",
        "    return ((train_X_char, train_X_word), y_tr), ((val_X_char, val_X_word), y_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TA8yhaT7cstt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filter_out = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n1234567890'\n",
        "\n",
        "maxlen_char = 500\n",
        "maxlen_word = 200\n",
        "\n",
        "max_features_words = 64157\n",
        "max_features_chars = 10489\n",
        "\n",
        "## Tokenize words\n",
        "tokenizer_words = Tokenizer(num_words=max_features_words, filters=filter_out, lower=True)  \n",
        "tokenizer_words.fit_on_texts(x_train.sent)\n",
        "\n",
        "## Tokenize chars\n",
        "tokenizer_char = Tokenizer(num_words=max_features_chars, filters=filter_out, char_level=True)\n",
        "tokenizer_char.fit_on_texts(x_train.sent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlPh-tgucsrY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "((train_X_char, train_X_word), train_Y), ((val_X_char, val_X_word), val_Y) = prepare_data(x_train, y_train, tokenizer_char, tokenizer_words, maxlen_char, maxlen_word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "24541c15-02f4-406b-f4ad-ce0aef86baba",
        "id": "P_Ra_ggYfnkP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(set(val_Y.values.reshape(1, -1)[0]))"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "235"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d3451e6b-f93a-4a83-bb5c-31f73f7f20b9",
        "id": "6WdpDN9vfnkU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(set(train_Y.values.reshape(1, -1)[0]))"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "235"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oG-2AAm8fnkW"
      },
      "source": [
        "Ниже меняю представление векторов ответов из [1, 23, 10,...] в вектор длины 235 и с 1 на месте соответсвующего языка"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d484cf01-0323-4de8-ed99-596913f8628c",
        "id": "sZZ5EXTvfnkW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "lb = LabelEncoder()\n",
        "y = lb.fit_transform(train_Y.values)\n",
        "dummy_y_train = to_categorical(y)\n",
        "print(len(dummy_y_train))\n",
        "print(len(dummy_y_train[0]))"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "105750\n",
            "235\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:251: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "8c35cbf4-93d9-4956-c7ce-14c647adcb01",
        "id": "hmbJkbgGfnka",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "y = lb.fit_transform(val_Y.values)\n",
        "dummy_y_val = to_categorical(y)"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:251: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbNHOv0Y1_V5",
        "colab_type": "text"
      },
      "source": [
        "#Fixed metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8TNKtrm2BG6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kbF16x2GifgV",
        "colab": {}
      },
      "source": [
        "# New metric!\n",
        "def f1_met(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)), axis=0)\n",
        "    false_positives = K.sum(K.round(K.clip((1 - y_true) * y_pred, 0, 1)), axis=0)\n",
        "    true_negatives = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)), axis=0)\n",
        "    false_negatives = K.sum(K.round(K.clip(y_true * (1 - y_pred), 0, 1)), axis=0)\n",
        "    precision = true_positives / (true_positives + false_positives  + K.epsilon())\n",
        "    recall = true_positives / (true_positives + false_negatives  + K.epsilon())\n",
        "    f1 = 2 * precision * recall / (precision + recall + K.epsilon())\n",
        "    return f1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3Wyb4M-1sWp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# New metric!\n",
        "def precision(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)), axis=0)\n",
        "    false_positives = K.sum(K.round(K.clip((1 - y_true) * y_pred, 0, 1)), axis=0)\n",
        "    true_negatives = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)), axis=0)\n",
        "    false_negatives = K.sum(K.round(K.clip(y_true * (1 - y_pred), 0, 1)), axis=0)\n",
        "    precision = true_positives / (true_positives + false_positives  + K.epsilon())\n",
        "    return precision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1YAsEAH1xNF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# New metric!\n",
        "def recall(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)), axis=0)\n",
        "    false_positives = K.sum(K.round(K.clip((1 - y_true) * y_pred, 0, 1)), axis=0)\n",
        "    true_negatives = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)), axis=0)\n",
        "    false_negatives = K.sum(K.round(K.clip(y_true * (1 - y_pred), 0, 1)), axis=0)\n",
        "    recall = true_positives / (true_positives + false_negatives  + K.epsilon())\n",
        "    return recall"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWqoMTcofr1-",
        "colab_type": "text"
      },
      "source": [
        "# Model with two embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1M7jq0xq86d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_double_cnn():\n",
        "    inp_char = Input(shape=(maxlen_char,))\n",
        "    inp_word = Input(shape=(maxlen_word,))\n",
        "\n",
        "    x1 = Embedding(max_features_chars, embed_size, input_shape=(maxlen_char,))(inp_char)\n",
        "    x2 = Embedding(max_features_words, embed_size, input_shape=(maxlen_word,))(inp_word)\n",
        "\n",
        "    concatted = tf.keras.layers.Concatenate(axis=1)([x1, x2])\n",
        "\n",
        "    lay = Conv1D(256, 5, activation='relu')(concatted)\n",
        "    lay = MaxPooling1D(5)(lay)\n",
        "    lay = Dropout(0.2)(lay)\n",
        "\n",
        "    lay = Conv1D(256, 5, activation='relu')(lay)\n",
        "    lay = MaxPooling1D(5)(lay)\n",
        "    lay = Flatten()(lay)\n",
        "\n",
        "    lay = Dense(512, activation=\"relu\")(lay)\n",
        "    lay = Dropout(0.2)(lay)\n",
        "\n",
        "    lay = Dense(num_classes, activation='softmax')(lay)\n",
        "    return Model(inputs=[inp_char, inp_word], outputs=lay)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIJ61uEdsONc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "outputId": "d3b75f56-090d-4d49-986a-4729ad5bdfab"
      },
      "source": [
        "double_model = create_double_cnn()\n",
        "double_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf.metrics.categorical_accuracy, f1_met, precision, recall])\n",
        "print(double_model.summary())"
      ],
      "execution_count": 258,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_16\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_11 (InputLayer)           [(None, 500)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_12 (InputLayer)           [(None, 200)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_11 (Embedding)        (None, 500, 200)     2097800     input_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "embedding_12 (Embedding)        (None, 200, 200)     12831400    input_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 700, 200)     0           embedding_11[0][0]               \n",
            "                                                                 embedding_12[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_10 (Conv1D)              (None, 696, 256)     256256      concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_10 (MaxPooling1D) (None, 139, 256)     0           conv1d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 139, 256)     0           max_pooling1d_10[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_11 (Conv1D)              (None, 135, 256)     327936      dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_11 (MaxPooling1D) (None, 27, 256)      0           conv1d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_5 (Flatten)             (None, 6912)         0           max_pooling1d_11[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 512)          3539456     flatten_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 512)          0           dense_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_11 (Dense)                (None, 235)          120555      dropout_11[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 19,173,403\n",
            "Trainable params: 19,173,403\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nwSTVaDwxydc",
        "colab": {}
      },
      "source": [
        "double_cp_path = data_path+'model_double.hdf5'\n",
        "double_cp=ModelCheckpoint(double_cp_path, monitor='val_loss',save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "bfb08d0e-e5bd-4efd-86b8-8db39648c396",
        "id": "fFkm8zFufy_a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "double_model.fit([train_X_char, train_X_word], dummy_y_train, batch_size=512, epochs=4, \n",
        "              validation_data=([val_X_char, val_X_word], dummy_y_val),\n",
        "               callbacks = [double_cp]\n",
        "             )"
      ],
      "execution_count": 260,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "207/207 [==============================] - 74s 358ms/step - loss: 2.4673 - categorical_accuracy: 0.4426 - f1_met: 0.3220 - precision: 0.3610 - recall: 0.3106 - val_loss: 0.5033 - val_categorical_accuracy: 0.8784 - val_f1_met: 0.7538 - val_precision: 0.7962 - val_recall: 0.7394\n",
            "Epoch 2/4\n",
            "207/207 [==============================] - 74s 356ms/step - loss: 0.4068 - categorical_accuracy: 0.8993 - f1_met: 0.7798 - precision: 0.8137 - recall: 0.7695 - val_loss: 0.3570 - val_categorical_accuracy: 0.9186 - val_f1_met: 0.8074 - val_precision: 0.8329 - val_recall: 0.8010\n",
            "Epoch 3/4\n",
            "207/207 [==============================] - 74s 358ms/step - loss: 0.2119 - categorical_accuracy: 0.9473 - f1_met: 0.8330 - precision: 0.8515 - recall: 0.8275 - val_loss: 0.3369 - val_categorical_accuracy: 0.9230 - val_f1_met: 0.8139 - val_precision: 0.8359 - val_recall: 0.8089\n",
            "Epoch 4/4\n",
            "207/207 [==============================] - 73s 354ms/step - loss: 0.1385 - categorical_accuracy: 0.9652 - f1_met: 0.8527 - precision: 0.8655 - recall: 0.8489 - val_loss: 0.3682 - val_categorical_accuracy: 0.9235 - val_f1_met: 0.8146 - val_precision: 0.8339 - val_recall: 0.8128\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7ca0f22e48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 260
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nU3Grknm3WRK",
        "colab_type": "text"
      },
      "source": [
        "# RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "28HMvK9S3cW9",
        "colab": {}
      },
      "source": [
        "def create_double_rnn():\n",
        "    inp_char = Input(shape=(maxlen_char,))\n",
        "    inp_word = Input(shape=(maxlen_word,))\n",
        "\n",
        "    x1 = Embedding(max_features_chars, embed_size, input_shape=(maxlen_char,))(inp_char)\n",
        "    x2 = Embedding(max_features_words, embed_size, input_shape=(maxlen_word,))(inp_word)\n",
        "\n",
        "    concatted = tf.keras.layers.Concatenate(axis=1)([x1, x2])\n",
        "\n",
        "    lay = Bidirectional(LSTM(150, return_sequences=True, activation='tanh',input_dim=embed_size))(concatted)\n",
        "    lay = Dropout(0.2)(lay)\n",
        "\n",
        "    lay = Bidirectional(LSTM(150, return_sequences=True, activation='tanh',input_dim=embed_size))(lay)\n",
        "    lay = Dropout(0.2)(lay)\n",
        "    lay = GlobalMaxPool1D()(lay)\n",
        "\n",
        "    lay = Dense(512, activation=\"relu\")(lay)\n",
        "    lay = Dropout(0.2)(lay)\n",
        "\n",
        "    lay = Dense(num_classes, activation='softmax')(lay)\n",
        "    return Model(inputs=[inp_char, inp_word], outputs=lay)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e6d38e20-2d1f-4c41-8584-f8607c0428e0",
        "id": "ubbiWaky3cXB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "source": [
        "double_rnn_model = create_double_rnn()\n",
        "double_rnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf.metrics.categorical_accuracy, f1_met, precision, recall])\n",
        "print(double_rnn_model.summary())"
      ],
      "execution_count": 282,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_17\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_13 (InputLayer)           [(None, 500)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_14 (InputLayer)           [(None, 200)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_13 (Embedding)        (None, 500, 200)     2097800     input_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "embedding_14 (Embedding)        (None, 200, 200)     12831400    input_14[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 700, 200)     0           embedding_13[0][0]               \n",
            "                                                                 embedding_14[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 700, 300)     421200      concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 700, 300)     0           bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 700, 300)     541200      dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 700, 300)     0           bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d (GlobalMax (None, 300)          0           dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_12 (Dense)                (None, 512)          154112      global_max_pooling1d[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 512)          0           dense_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_13 (Dense)                (None, 235)          120555      dropout_14[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 16,166,267\n",
            "Trainable params: 16,166,267\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7d78KEhF3cXE",
        "colab": {}
      },
      "source": [
        "double_rnn_cp_path = data_path+'model_rnn_double.hdf5'\n",
        "double_rnn_cp=ModelCheckpoint(double_rnn_cp_path, monitor='val_loss',save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "5032cb12-ebfa-4c21-d16b-fd528ffac57a",
        "id": "hUbN_l1V3cXH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "double_rnn_model.fit([train_X_char, train_X_word], dummy_y_train, batch_size=512, epochs=4, \n",
        "              validation_data=([val_X_char, val_X_word], dummy_y_val),\n",
        "               callbacks = [double_cp]\n",
        "             )"
      ],
      "execution_count": 284,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "207/207 [==============================] - 202s 978ms/step - loss: 3.0349 - categorical_accuracy: 0.2906 - f1_met: 0.1364 - precision: 0.1603 - recall: 0.1281 - val_loss: 1.0926 - val_categorical_accuracy: 0.7745 - val_f1_met: 0.4468 - val_precision: 0.4972 - val_recall: 0.4264\n",
            "Epoch 2/4\n",
            "207/207 [==============================] - 202s 975ms/step - loss: 0.5729 - categorical_accuracy: 0.8619 - f1_met: 0.7208 - precision: 0.7657 - recall: 0.7063 - val_loss: 0.4369 - val_categorical_accuracy: 0.9067 - val_f1_met: 0.7790 - val_precision: 0.8156 - val_recall: 0.7638\n",
            "Epoch 3/4\n",
            "207/207 [==============================] - 202s 978ms/step - loss: 0.2365 - categorical_accuracy: 0.9437 - f1_met: 0.8311 - precision: 0.8499 - recall: 0.8258 - val_loss: 0.3671 - val_categorical_accuracy: 0.9192 - val_f1_met: 0.8058 - val_precision: 0.8346 - val_recall: 0.7954\n",
            "Epoch 4/4\n",
            "207/207 [==============================] - 202s 976ms/step - loss: 0.1420 - categorical_accuracy: 0.9663 - f1_met: 0.8543 - precision: 0.8659 - recall: 0.8511 - val_loss: 0.3634 - val_categorical_accuracy: 0.9227 - val_f1_met: 0.8143 - val_precision: 0.8385 - val_recall: 0.8075\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7ca12f4d68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 284
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XRmhIRA2ifgE"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LIXo-d-MifgK",
        "colab": {}
      },
      "source": [
        "x_test['sc'] = y_test\n",
        "x_test['lang'] = [class_to_language[y] for y in list(y_test.iloc[:,0])]\n",
        "x_train['sc'] = y_train\n",
        "x_train['lang'] = [class_to_language[y] for y in list(y_train.iloc[:,0])]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbsUXroCik0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert(x, tokenizer_char, tokenizer_word, maxlen_char, maxlen_word):\n",
        "    X_char = tokenizer_char.texts_to_sequences(x.sent)\n",
        "    X_word = tokenizer_word.texts_to_sequences(x.sent)\n",
        "\n",
        "    ## Pad chars\n",
        "    X_char = pad_sequences(X_char, maxlen=maxlen_char)\n",
        "\n",
        "    ## Pad words\n",
        "    X_word = pad_sequences(X_word, maxlen=maxlen_word)\n",
        "\n",
        "    return (X_char, X_word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUYVAmRe1tEz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# New metric!\n",
        "def met(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)), axis=0)\n",
        "    false_positives = K.sum(K.round(K.clip((1 - y_true) * y_pred, 0, 1)), axis=0)\n",
        "    true_negatives = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)), axis=0)\n",
        "    false_negatives = K.sum(K.round(K.clip(y_true * (1 - y_pred), 0, 1)), axis=0)\n",
        "    precision = true_positives / (true_positives + false_positives  + K.epsilon())\n",
        "    recall = true_positives / (true_positives + false_negatives  + K.epsilon())\n",
        "    f1 = 2 * precision * recall / (precision + recall + K.epsilon())\n",
        "    return precision, recall, f1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eXHS2UEkifgX"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g20c21Q-ns24",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_char, x_word = convert(x_test, tokenizer_char, tokenizer_words, maxlen_char, maxlen_word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXvca94Vn7mx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "9e51d1d6-ddc6-49aa-fc2e-336f2d651ef7"
      },
      "source": [
        "y = lb.fit_transform(y_test.values)\n",
        "dummy_y_test = to_categorical(y)"
      ],
      "execution_count": 287,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:251: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViVAmYQMns7L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_rnn = double_rnn_model.predict([x_char, x_word])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dA8vNiBMok1F",
        "colab": {}
      },
      "source": [
        "p, r, f = met(dummy_y_test, y_pred_rnn)\n",
        "raw_metrics_rnn = pd.DataFrame(\n",
        "    {'precision': p,\n",
        "     'recall': r,\n",
        "     'f1': f\n",
        "    })\n",
        "metrics_rnn = raw_metrics_rnn.rename(class_to_language, axis='index')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lewvapp4ns-j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_cnn = double_model.predict([x_char, x_word])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gT5N-zsBok1P",
        "colab": {}
      },
      "source": [
        "p, r, f = met(dummy_y_test, y_pred_cnn)\n",
        "raw_metrics_cnn = pd.DataFrame(\n",
        "    {'precision': p,\n",
        "     'recall': r,\n",
        "     'f1': f\n",
        "    })\n",
        "metrics_cnn = raw_metrics_cnn.rename(class_to_language, axis='index')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e7be1d08-0b46-44c2-d4bb-4dde4ff256c8",
        "id": "8NPx1FlIok1R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "metrics_rnn[metrics_rnn.f1 < 0.7]"
      ],
      "execution_count": 290,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>bos</th>\n",
              "      <td>0.596847</td>\n",
              "      <td>0.530</td>\n",
              "      <td>0.561441</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>eng</th>\n",
              "      <td>0.610345</td>\n",
              "      <td>0.354</td>\n",
              "      <td>0.448101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hbs</th>\n",
              "      <td>0.684588</td>\n",
              "      <td>0.382</td>\n",
              "      <td>0.490372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hrv</th>\n",
              "      <td>0.630923</td>\n",
              "      <td>0.506</td>\n",
              "      <td>0.561598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>spa</th>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.474</td>\n",
              "      <td>0.580882</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     precision  recall        f1\n",
              "bos   0.596847   0.530  0.561441\n",
              "eng   0.610345   0.354  0.448101\n",
              "hbs   0.684588   0.382  0.490372\n",
              "hrv   0.630923   0.506  0.561598\n",
              "spa   0.750000   0.474  0.580882"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 290
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_4vq2x09TcD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ce687a7f-8ab1-4cbd-8dc9-797113395904"
      },
      "source": [
        "metrics_rnn[metrics_rnn.f1 > 0.95].shape"
      ],
      "execution_count": 303,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(121, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 303
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O677cW306pID",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "63cba974-e4ab-4c56-98f1-0d4828d272ff"
      },
      "source": [
        "metrics_cnn[metrics_cnn.f1 < 0.7]"
      ],
      "execution_count": 293,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>bos</th>\n",
              "      <td>0.551402</td>\n",
              "      <td>0.590</td>\n",
              "      <td>0.570048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>eng</th>\n",
              "      <td>0.607921</td>\n",
              "      <td>0.614</td>\n",
              "      <td>0.610945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hbs</th>\n",
              "      <td>0.566667</td>\n",
              "      <td>0.374</td>\n",
              "      <td>0.450602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hrv</th>\n",
              "      <td>0.545692</td>\n",
              "      <td>0.418</td>\n",
              "      <td>0.473386</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     precision  recall        f1\n",
              "bos   0.551402   0.590  0.570048\n",
              "eng   0.607921   0.614  0.610945\n",
              "hbs   0.566667   0.374  0.450602\n",
              "hrv   0.545692   0.418  0.473386"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 293
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZNJ0JpJ9Wid",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4e7beead-0812-4d4e-9868-cf11d8fdac28"
      },
      "source": [
        "metrics_cnn[metrics_cnn.f1 > 0.95].shape"
      ],
      "execution_count": 304,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(127, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 304
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clcmJUe-zXo3",
        "colab_type": "text"
      },
      "source": [
        "# My"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQZTpyljpG4R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my = pd.DataFrame(\n",
        "    {'sent': ['English is a West Germanic language that was first spoken in early medieval England and eventually became a global lingua franca.[4][5] It is named after the Angles, one of the ancient Germanic peoples that migrated to the area of Great Britain that later took their name, England. Both names derive from Anglia, ',\n",
        "              'язык англо-фризской подгруппы западной группы германской ветви индоевропейской языковой семьи. Английский язык — важнейший международный язык[4], что является следствием колониальной политики Британской империи в XIX веке и мирового влияния США в XX—XXI веках. Существует значительное разнообразие диалектов и говоров английского языка.',\n",
        "              'Produkcja aparatów fotograficznych w kijowskich zakładach Arsenal rozpoczęła się od przeniesienia w 1946 r. z Drezna całej, ledwie uruchomionej po zniszczeniach wojennych linii produkcyjnej aparatów małoobrazkowych Contax, wraz z zatrudnionymi przy niej fachowcami. ',\n",
        "              'З 1944 года дзейнічае Дзяржаўны літаратурны музей Янкі Купалы. У гонар паэта ў 1957 годзе была заснавана Літаратурная прэмія імя Янкі Купалы. З 1995 года сістэматычна праводзяцца штогадовыя Купалаўскія чытанні — прафесійны форум для абмеркавання навуковых дасягненняў і праблем купалазнаўства.'\n",
        "              ],\n",
        "    })"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaQacjIxzfP2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_char, x_word = convert(my, tokenizer_char, tokenizer_words, maxlen_char, maxlen_word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1vdlKvpz6rs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "199c814d-de88-453e-b774-09b601819aad"
      },
      "source": [
        "ys = double_model.predict([x_char, x_word])\n",
        "ys.argmax(axis=1)"
      ],
      "execution_count": 302,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([164, 177, 168,  18])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 302
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RkJ4yjnnrwv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d133328b-5f08-4b8f-b100-3162a0856046"
      },
      "source": [
        "ys = double_rnn_model.predict([x_char, x_word])\n",
        "ys.argmax(axis=1)"
      ],
      "execution_count": 297,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([228, 177, 168,  18])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 297
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csZ668ko9ENQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e3bcd1fe-3999-4520-be23-91eaf8425aab"
      },
      "source": [
        "class_to_language[164]"
      ],
      "execution_count": 298,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'pcd'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 298
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUQrR-s29G5I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4c82edf4-7801-441a-cf88-0fddf1855086"
      },
      "source": [
        "class_to_language[228]"
      ],
      "execution_count": 299,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'xho'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 299
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gnA4ZEn0v2d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d2be843-9d29-43f6-977e-0fd97b5f22ca"
      },
      "source": [
        "class_to_language[50]"
      ],
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'eng'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 236
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uo6mDP6GzmDX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b7e5b8d9-1c88-4110-a8bd-246f85202765"
      },
      "source": [
        "class_to_language[177]"
      ],
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'rus'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 237
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6UjGQGmzrs0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c7fe0aed-7f10-43de-8d60-bc7e977e2d60"
      },
      "source": [
        "class_to_language[168]"
      ],
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'pol'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 238
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6n7eluk1zyIS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2a491c12-155e-4b71-e12e-502006fa27f3"
      },
      "source": [
        "class_to_language[18]"
      ],
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'bel'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 239
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOcT_sy300dj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOVR3qXw4JAx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}