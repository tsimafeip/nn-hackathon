{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of hackaton.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpmSbtrCklRB",
        "colab_type": "code",
        "outputId": "b74737a2-7648-405b-d3fa-f6e3b7f7f739",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNLhWWCxYfLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "import scipy\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import logging\n",
        "import multiprocessing\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8IzA7Rx-VzU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Bidirectional, GlobalMaxPooling1D, GlobalMaxPool1D, MaxPooling1D, Flatten, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import initializers, regularizers, constraints, optimizers, layers\n",
        "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc94smEhjbA_",
        "colab_type": "text"
      },
      "source": [
        "# Download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75potnAshWU4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path = '/content/drive/My Drive/Colab Notebooks/Hackathon/'\n",
        "wili_data_path = data_path + 'wili-2018/'\n",
        "\n",
        "x_train_path = wili_data_path + 'x_train.txt'\n",
        "x_test_path = wili_data_path + 'x_test.txt'\n",
        "y_train_path = wili_data_path + 'y_train.txt'\n",
        "y_test_path = wili_data_path + 'y_test.txt'\n",
        "labels_path = wili_data_path + 'labels.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhsiujWS3QR8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "004c1745-c78d-46b7-c8d7-4095eaad3486"
      },
      "source": [
        "labels = pd.read_csv(labels_path, sep=';')\n",
        "labels = labels.drop(labels=['German', 'Writing system', 'Remarks', 'Synonyms'], axis=1)\n",
        "labels"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>English</th>\n",
              "      <th>Wiki Code</th>\n",
              "      <th>ISO 369-3</th>\n",
              "      <th>Language family</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ace</td>\n",
              "      <td>Achinese</td>\n",
              "      <td>ace</td>\n",
              "      <td>ace</td>\n",
              "      <td>Austronesian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>afr</td>\n",
              "      <td>Afrikaans</td>\n",
              "      <td>af</td>\n",
              "      <td>afr</td>\n",
              "      <td>Indo-European</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>als</td>\n",
              "      <td>Alemannic German</td>\n",
              "      <td>als</td>\n",
              "      <td>gsw</td>\n",
              "      <td>Indo-European</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>amh</td>\n",
              "      <td>Amharic</td>\n",
              "      <td>am</td>\n",
              "      <td>amh</td>\n",
              "      <td>Afro-Asiatic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ang</td>\n",
              "      <td>Old English</td>\n",
              "      <td>ang</td>\n",
              "      <td>ang</td>\n",
              "      <td>Indo-European</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>230</th>\n",
              "      <td>yid</td>\n",
              "      <td>Yiddish</td>\n",
              "      <td>yi</td>\n",
              "      <td>yid</td>\n",
              "      <td>Indo-European</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>231</th>\n",
              "      <td>yor</td>\n",
              "      <td>Yoruba</td>\n",
              "      <td>yo</td>\n",
              "      <td>yor</td>\n",
              "      <td>Niger-Congo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>232</th>\n",
              "      <td>zea</td>\n",
              "      <td>Zeeuws</td>\n",
              "      <td>zea</td>\n",
              "      <td>zea</td>\n",
              "      <td>Indo-European</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>233</th>\n",
              "      <td>zh-yue</td>\n",
              "      <td>Cantonese</td>\n",
              "      <td>zh-yue</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Sino-Tibetan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>234</th>\n",
              "      <td>zho</td>\n",
              "      <td>Standard Chinese</td>\n",
              "      <td>zh</td>\n",
              "      <td>zho</td>\n",
              "      <td>Sino-Tibetan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>235 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Label           English Wiki Code ISO 369-3 Language family\n",
              "0       ace          Achinese       ace       ace    Austronesian\n",
              "1       afr         Afrikaans        af       afr   Indo-European\n",
              "2       als  Alemannic German       als       gsw   Indo-European\n",
              "3       amh           Amharic        am       amh    Afro-Asiatic\n",
              "4       ang      Old English        ang       ang   Indo-European\n",
              "..      ...               ...       ...       ...             ...\n",
              "230     yid           Yiddish        yi       yid   Indo-European\n",
              "231     yor            Yoruba        yo       yor     Niger-Congo\n",
              "232     zea            Zeeuws       zea       zea   Indo-European\n",
              "233  zh-yue         Cantonese    zh-yue       NaN    Sino-Tibetan\n",
              "234     zho  Standard Chinese        zh       zho    Sino-Tibetan\n",
              "\n",
              "[235 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vt7kVtUgYRi8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert title of language in class\n",
        "with open(y_train_path) as f:\n",
        "    mylist = f.read().splitlines() \n",
        "languages = list(set(mylist))\n",
        "language_to_class = dict()\n",
        "class_to_language = dict()\n",
        "for i in range(len(languages)):\n",
        "    language_to_class[languages[i]] = i\n",
        "    class_to_language[i] = languages[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDFr3-rKmDdv",
        "colab_type": "code",
        "outputId": "7035dee3-d081-4e84-b802-690c5247cc86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(list(language_to_class.items())[:5])\n",
        "len(languages)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('nep', 0), ('est', 1), ('vie', 2), ('pam', 3), ('csb', 4)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "235"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBqkjck1Yc7q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_data():\n",
        "    with open(x_train_path) as f:\n",
        "        mylist = f.read().splitlines() \n",
        "    x_train = pd.DataFrame(mylist, columns=[\"sent\"])\n",
        "    with open(x_test_path) as f:\n",
        "        mylist = f.read().splitlines() \n",
        "    x_test = pd.DataFrame(mylist, columns=[\"sent\"])\n",
        "\n",
        "    with open(y_train_path) as f:\n",
        "        mylist = f.read().splitlines() \n",
        "    y_train = []\n",
        "    for lan in mylist:\n",
        "        y_train.append(language_to_class[lan])\n",
        "    y_train = pd.DataFrame(y_train)\n",
        "    with open(y_test_path) as f:\n",
        "        mylist = f.read().splitlines()\n",
        "\n",
        "    y_test = []\n",
        "    for lan in mylist:\n",
        "        y_test.append(language_to_class[lan])\n",
        "    y_test = pd.DataFrame(y_test)\n",
        "    \n",
        "    return (x_train, y_train), (x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRo0Wf1lZXsE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = read_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhKRW6V8hhIc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "79671fc3-0a48-4641-f285-5e5050bb4f3e"
      },
      "source": [
        "print(x_train.head())\n",
        "print(y_train.head())\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                sent\n",
            "0  Klement Gottwaldi surnukeha palsameeriti ning ...\n",
            "1  Sebes, Joseph; Pereira Thomas (1961) (på eng)....\n",
            "2  भारतीय स्वातन्त्र्य आन्दोलन राष्ट्रीय एवम क्षे...\n",
            "3  Après lo cort periòde d'establiment a Basilèa,...\n",
            "4  ถนนเจริญกรุง (อักษรโรมัน: Thanon Charoen Krung...\n",
            "     0\n",
            "0    1\n",
            "1  140\n",
            "2  170\n",
            "3  210\n",
            "4   28\n",
            "(117500, 1)\n",
            "(117500, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zcUciRigFYu",
        "colab_type": "code",
        "outputId": "7e5114aa-18b1-4d4a-fdae-f0040bc9c413",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "lens = x_train.sent.str.split(' ').str.len().values\n",
        "plt.hist(lens, bins=np.linspace(0,1000,20), facecolor='blue', alpha=0.9)\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xdCSiHnhlX1",
        "colab_type": "text"
      },
      "source": [
        "# Experiment on small dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFTqOQmChknq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# small_dataset = pd.read_csv(data_path + 'kaggle_dataset/dataset.csv')\n",
        "# small_dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwtWy38ehtGO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X=small_dataset['Text']\n",
        "# y=small_dataset['language']\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# print(len(X_train))\n",
        "# print(len(X_test))\n",
        "# print(len(y_train))\n",
        "# print(len(y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNoYz_IwjeY_",
        "colab_type": "text"
      },
      "source": [
        "# Embedding **data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEr8pklSjQLP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filter_out = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n1234567890'\n",
        "tokenizer = Tokenizer(filters=filter_out, lower=True)\n",
        "tokenizer.fit_on_texts(x_train.sent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5jxVwDcftcn",
        "colab_type": "text"
      },
      "source": [
        "Выбираю какое количество слов оставить. Если оставлять все, то будет 1500000, что слишком много. Можно поменять `count` и оно покажет сколько слов встречается больше, чем `count` раз"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xKQt34TAG2-",
        "colab_type": "code",
        "outputId": "08a62b36-dffa-47b5-c2c0-2a87459e411a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# try different values of `count`\n",
        "# show how many words are presenting more than `count` times\n",
        "count = 10\n",
        "frequent_words = [w for w,c in tokenizer.word_counts.items() if c > count]\n",
        "len(frequent_words)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64157"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJacuBHhHEng",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embed_size = 300 # how big is each word vector\n",
        "max_features = len(frequent_words) # how many unique words to use (i.e num rows in embedding vector)\n",
        "maxlen = 200 # max number of words in a question to use\n",
        "\n",
        "## Tokenize the sentences\n",
        "tokenizer = Tokenizer(num_words=max_features, filters=filter_out, lower=True)\n",
        "\n",
        "def prepare_data():\n",
        "    x_tr, x_val, y_tr, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=1, stratify=y_train.values)\n",
        "   \n",
        "    tokenizer.fit_on_texts(x_tr.sent)\n",
        "\n",
        "    train_X = tokenizer.texts_to_sequences(x_tr.sent)\n",
        "    val_X = tokenizer.texts_to_sequences(x_val.sent)\n",
        "\n",
        "    ## Pad the sentences \n",
        "    train_X = pad_sequences(train_X, maxlen=maxlen)\n",
        "    val_X = pad_sequences(val_X, maxlen=maxlen)\n",
        "\n",
        "    return (train_X, y_tr), (val_X, y_val)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qW1oK9wfHEnm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_X, train_Y), (val_X, val_Y) = prepare_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxyyqzKsgF9K",
        "colab_type": "text"
      },
      "source": [
        "Проверила, что в тренировочном и валидационном датасетах встречаются все классы. Балансировка регулируется вот этим параметром: stratify=y_train.values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1iJF7cyU5iK",
        "colab_type": "code",
        "outputId": "7d7f6d81-b54f-49ba-8f75-be2a63878fc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(set(val_Y.values.reshape(1, -1)[0]))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "235"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPITYtR8UqNx",
        "colab_type": "code",
        "outputId": "e75bf9df-59b9-403f-e6fc-f0f3d2d2dfe6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(set(train_Y.values.reshape(1, -1)[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "235"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYuurOSQgYUl",
        "colab_type": "text"
      },
      "source": [
        "Ниже меняю представление векторов ответов из [1, 23, 10,...] в вектор длины 235 и с 1 на месте соответсвующего языка"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0iIyf4bIXg_",
        "colab_type": "code",
        "outputId": "a4cc6780-ace0-4eb1-e0c3-8cd92cbea560",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "lb = LabelEncoder()\n",
        "y = lb.fit_transform(train_Y.values)\n",
        "dummy_y_train = to_categorical(y)\n",
        "print(len(dummy_y_train))\n",
        "print(len(dummy_y_train[0]))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "105750\n",
            "235\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:251: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCBYAruyIxUm",
        "colab_type": "code",
        "outputId": "c2be0cca-a62c-4d6a-ae80-6bb062466b4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "y = lb.fit_transform(val_Y.values)\n",
        "dummy_y_val = to_categorical(y)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:251: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeXXgZJ6miyl",
        "colab_type": "text"
      },
      "source": [
        "# Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vp4rfHfplm6O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f1(y_true, y_pred): #taken from old keras source code\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return f1_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dzi3zyNsmNIR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def recall(y_true, y_pred): #taken from old keras source code\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    return true_positives / (possible_positives + K.epsilon())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JX13CaozmRhy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def precision(y_true, y_pred): #taken from old keras source code\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    return true_positives / (predicted_positives + K.epsilon())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtGH8P89gTXf",
        "colab_type": "text"
      },
      "source": [
        "#CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdsE9d9SjdsW",
        "colab_type": "code",
        "outputId": "11b64422-eda0-47e7-de1e-c9d87979a78a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        }
      },
      "source": [
        "cnn_model = Sequential()\n",
        "cnn_model.add(Embedding(max_features, embed_size,input_shape=(maxlen,)))\n",
        "cnn_model.add(Conv1D(256, 5, activation='relu', input_shape=(embed_size,)))\n",
        "cnn_model.add(MaxPooling1D(5))\n",
        "cnn_model.add(Dropout(0.2))\n",
        "cnn_model.add(Conv1D(256, 5, activation='relu'))\n",
        "cnn_model.add(MaxPooling1D(5))\n",
        "cnn_model.add(Flatten())\n",
        "cnn_model.add(Dense(512, activation=\"relu\"))\n",
        "cnn_model.add(Dropout(0.2))\n",
        "cnn_model.add(Dense(len(languages), activation='softmax'))\n",
        "cnn_model.summary()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 200, 300)          19247100  \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 196, 256)          384256    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 39, 256)           0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 39, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 35, 256)           327936    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, 7, 256)            0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1792)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 528)               946704    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 528)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 235)               124315    \n",
            "=================================================================\n",
            "Total params: 21,030,311\n",
            "Trainable params: 21,030,311\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sndko3XlZ806",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', f1, recall, precision])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aa9rf4_Oq6nX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn_cp_path = data_path+'model_cnn.hdf5'\n",
        "cnn_cp=ModelCheckpoint(cnn_cp_path, monitor='val_f1',save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIhz76oFHo_c",
        "colab_type": "code",
        "outputId": "7f4612ee-3dd1-4f84-b2a9-d50b6ee3c118",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "cnn_model.fit(train_X, dummy_y_train, batch_size=512, epochs=5, \n",
        "              validation_data=(val_X, dummy_y_val),\n",
        "              callbacks = [cnn_cp])"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "207/207 [==============================] - 87s 418ms/step - loss: 3.2681 - accuracy: 0.3020 - f1: 0.2766 - recall: 0.2162 - precision: 0.6018 - val_loss: 0.7261 - val_accuracy: 0.8397 - val_f1: 0.8468 - val_recall: 0.7590 - val_precision: 0.9581\n",
            "Epoch 2/5\n",
            "207/207 [==============================] - 86s 414ms/step - loss: 0.5337 - accuracy: 0.8660 - f1: 0.8820 - recall: 0.8239 - precision: 0.9495 - val_loss: 0.4821 - val_accuracy: 0.8918 - val_f1: 0.9104 - val_recall: 0.8615 - val_precision: 0.9651\n",
            "Epoch 3/5\n",
            "207/207 [==============================] - 85s 413ms/step - loss: 0.2602 - accuracy: 0.9291 - f1: 0.9427 - recall: 0.9112 - precision: 0.9765 - val_loss: 0.4964 - val_accuracy: 0.8921 - val_f1: 0.9114 - val_recall: 0.8736 - val_precision: 0.9528\n",
            "Epoch 4/5\n",
            "207/207 [==============================] - 86s 413ms/step - loss: 0.1830 - accuracy: 0.9478 - f1: 0.9589 - recall: 0.9353 - precision: 0.9838 - val_loss: 0.5692 - val_accuracy: 0.8871 - val_f1: 0.9085 - val_recall: 0.8762 - val_precision: 0.9434\n",
            "Epoch 5/5\n",
            "207/207 [==============================] - 85s 411ms/step - loss: 0.1536 - accuracy: 0.9551 - f1: 0.9655 - recall: 0.9454 - precision: 0.9866 - val_loss: 0.6166 - val_accuracy: 0.8894 - val_f1: 0.9087 - val_recall: 0.8790 - val_precision: 0.9407\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbd7b5dda58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-T-4MO1ZR_S",
        "colab_type": "text"
      },
      "source": [
        "#RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ch0GFZ-ZSzb",
        "colab_type": "code",
        "outputId": "8915e7d5-17a0-4664-e176-16330d433c79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "rnn_model = Sequential()\n",
        "rnn_model.add(Embedding(max_features, embed_size))\n",
        "rnn_model.add(Bidirectional(LSTM(256, return_sequences=True, activation='tanh',input_dim=embed_size)))\n",
        "rnn_model.add(Dropout(0.2))\n",
        "rnn_model.add(Bidirectional(LSTM(256, return_sequences=True, activation='tanh')))\n",
        "rnn_model.add(GlobalMaxPool1D())\n",
        "rnn_model.add(Dropout(0.2))\n",
        "rnn_model.add(Dense(512, activation=\"relu\"))\n",
        "rnn_model.add(Dropout(0.2))\n",
        "rnn_model.add(Dense(len(languages), activation='softmax'))\n",
        "rnn_model.summary()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, None, 300)         19247100  \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, None, 512)         1140736   \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, None, 512)         0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, None, 512)         1574912   \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 235)               120555    \n",
            "=================================================================\n",
            "Total params: 22,345,959\n",
            "Trainable params: 22,345,959\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1W3XFHXZiVR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', f1, recall, precision])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPtLB7kUrGgE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rnn_cp_path = data_path + 'model_rnn.hdf5'\n",
        "rnn_cp=ModelCheckpoint(rnn_cp_path,monitor='val_f1',save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qK-tgijZk7L",
        "colab_type": "code",
        "outputId": "2bce9dfc-fe71-42a1-964e-f89701f3486b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "source": [
        "rnn_model.fit(train_X, dummy_y_train, batch_size=512, epochs=3, \n",
        "              validation_data=(val_X, dummy_y_val), callbacks = [rnn_cp])"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "207/207 [==============================] - 321s 2s/step - loss: 2.5891 - accuracy: 0.4243 - f1: 0.3768 - recall: 0.3188 - precision: 0.5763 - val_loss: 0.5165 - val_accuracy: 0.8675 - val_f1: 0.8854 - val_recall: 0.8305 - val_precision: 0.9481\n",
            "Epoch 2/3\n",
            "207/207 [==============================] - 317s 2s/step - loss: 0.4045 - accuracy: 0.8951 - f1: 0.9097 - recall: 0.8678 - precision: 0.9561 - val_loss: 0.3988 - val_accuracy: 0.8985 - val_f1: 0.9145 - val_recall: 0.8762 - val_precision: 0.9565\n",
            "Epoch 3/3\n",
            "207/207 [==============================] - 317s 2s/step - loss: 0.2285 - accuracy: 0.9368 - f1: 0.9492 - recall: 0.9225 - precision: 0.9775 - val_loss: 0.3939 - val_accuracy: 0.9061 - val_f1: 0.9226 - val_recall: 0.8887 - val_precision: 0.9592\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbd892680b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCeuUze_qnC2",
        "colab_type": "text"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jS0Tq-Cqb4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test['sc'] = y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wowtwiinqwm0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Be careful! Tokenizer and maxlen is taken from train dataset from 1st part\n",
        "def convert(x):\n",
        "    train_X = tokenizer.texts_to_sequences(x.sent)\n",
        "    ## Pad the sentences \n",
        "    train_X = pad_sequences(train_X, maxlen=maxlen)\n",
        "    return train_X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvOMHL7Nx_eO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def metr(y_true, y_pred): #taken from old keras source code\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return precision, recall, f1_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OwT-3obvsIo",
        "colab_type": "text"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P006Z5Sgzeal",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "462303bc-7a4c-4ce4-98f0-8d4ffdc411ef"
      },
      "source": [
        "ps = []\n",
        "rs = []\n",
        "fs = []\n",
        "for lan in range(len(languages)):\n",
        "    x_t = x_test[x_test['sc'] == lan]\n",
        "    x = convert(x_t)\n",
        "    y = np.zeros((x.shape[0], len(languages)))\n",
        "    y[:, lan] = 1\n",
        "    y = y.astype('float32')\n",
        "    y_pred = cnn_model.predict(x)\n",
        "    p, r, f = metr(y, y_pred)\n",
        "    ps.append(p.numpy())\n",
        "    rs.append(r.numpy())\n",
        "    fs.append(f.numpy())\n",
        "    print(\"language: \", class_to_language[lan], \"precision: \", p.numpy(), \"recall: \", r.numpy(), \"f1: \", f.numpy())"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "language:  nep precision:  0.90123457 recall:  0.876 f1:  0.88843805\n",
            "language:  est precision:  0.8597701 recall:  0.748 f1:  0.79999995\n",
            "language:  vie precision:  0.98993963 recall:  0.984 f1:  0.9869609\n",
            "language:  pam precision:  0.9605809 recall:  0.926 f1:  0.9429734\n",
            "language:  csb precision:  0.9122449 recall:  0.894 f1:  0.9030303\n",
            "language:  gle precision:  0.9816701 recall:  0.964 f1:  0.9727547\n",
            "language:  ava precision:  0.8496732 recall:  0.78 f1:  0.8133471\n",
            "language:  fra precision:  0.80131006 recall:  0.734 f1:  0.7661795\n",
            "language:  zh-yue precision:  0.47887325 recall:  0.068 f1:  0.1190893\n",
            "language:  msa precision:  0.8178054 recall:  0.79 f1:  0.80366224\n",
            "language:  ext precision:  0.9414226 recall:  0.9 f1:  0.92024535\n",
            "language:  bre precision:  0.9757576 recall:  0.966 f1:  0.97085416\n",
            "language:  lad precision:  0.89979124 recall:  0.862 f1:  0.88049024\n",
            "language:  snd precision:  0.99597585 recall:  0.99 f1:  0.9929789\n",
            "language:  sin precision:  0.9627329 recall:  0.93 f1:  0.9460834\n",
            "language:  kok precision:  0.90618336 recall:  0.85 f1:  0.8771929\n",
            "language:  spa precision:  0.74832964 recall:  0.672 f1:  0.7081138\n",
            "language:  kab precision:  0.9460581 recall:  0.912 f1:  0.9287169\n",
            "language:  ron precision:  0.9587629 recall:  0.93 f1:  0.94416237\n",
            "language:  deu precision:  0.87004405 recall:  0.79 f1:  0.8280922\n",
            "language:  kin precision:  0.95247936 recall:  0.922 f1:  0.9369919\n",
            "language:  pol precision:  0.975052 recall:  0.938 f1:  0.95616716\n",
            "language:  udm precision:  0.9601677 recall:  0.916 f1:  0.9375639\n",
            "language:  lim precision:  0.95740366 recall:  0.944 f1:  0.9506545\n",
            "language:  glv precision:  0.9717172 recall:  0.962 f1:  0.96683407\n",
            "language:  por precision:  0.8886555 recall:  0.846 f1:  0.8668032\n",
            "language:  hun precision:  0.97131145 recall:  0.948 f1:  0.9595141\n",
            "language:  cym precision:  0.97987926 recall:  0.974 f1:  0.97693074\n",
            "language:  tha precision:  0.9530686 recall:  0.528 f1:  0.6795366\n",
            "language:  new precision:  0.9778672 recall:  0.972 f1:  0.9749247\n",
            "language:  zho precision:  0.34375 recall:  0.022 f1:  0.04135337\n",
            "language:  tcy precision:  0.97330594 recall:  0.948 f1:  0.9604863\n",
            "language:  heb precision:  0.9836401 recall:  0.962 f1:  0.97269964\n",
            "language:  gag precision:  0.8972746 recall:  0.856 f1:  0.8761514\n",
            "language:  tet precision:  0.9392713 recall:  0.928 f1:  0.93360156\n",
            "language:  lug precision:  0.9525773 recall:  0.924 f1:  0.93807095\n",
            "language:  kan precision:  0.96025103 recall:  0.918 f1:  0.9386502\n",
            "language:  nno precision:  0.90123457 recall:  0.876 f1:  0.88843805\n",
            "language:  san precision:  0.97540987 recall:  0.952 f1:  0.9635627\n",
            "language:  mdf precision:  0.9352818 recall:  0.896 f1:  0.9152195\n",
            "language:  roh precision:  0.9459459 recall:  0.91 f1:  0.9276248\n",
            "language:  slv precision:  0.9426752 recall:  0.888 f1:  0.9145211\n",
            "language:  nap precision:  0.9425051 recall:  0.918 f1:  0.93009114\n",
            "language:  ori precision:  0.98971194 recall:  0.962 f1:  0.9756592\n",
            "language:  rup precision:  0.875803 recall:  0.818 f1:  0.84591514\n",
            "language:  oss precision:  0.9756098 recall:  0.96 f1:  0.96774185\n",
            "language:  tgk precision:  0.9776423 recall:  0.962 f1:  0.96975803\n",
            "language:  mrj precision:  0.97352344 recall:  0.956 f1:  0.96468204\n",
            "language:  lmo precision:  0.84199584 recall:  0.81 f1:  0.82568794\n",
            "language:  hat precision:  0.979716 recall:  0.966 f1:  0.97280955\n",
            "language:  que precision:  0.9450317 recall:  0.894 f1:  0.91880774\n",
            "language:  hbs precision:  0.6473214 recall:  0.58 f1:  0.61181426\n",
            "language:  pus precision:  0.9734694 recall:  0.954 f1:  0.9636363\n",
            "language:  fur precision:  0.92339545 recall:  0.892 f1:  0.90742624\n",
            "language:  amh precision:  0.9837067 recall:  0.966 f1:  0.9747729\n",
            "language:  cos precision:  0.94639176 recall:  0.918 f1:  0.93197966\n",
            "language:  nan precision:  1.0 recall:  0.998 f1:  0.99899894\n",
            "language:  diq precision:  0.9546392 recall:  0.926 f1:  0.94010144\n",
            "language:  jpn precision:  0.8405797 recall:  0.116 f1:  0.20386639\n",
            "language:  map-bms precision:  0.8530021 recall:  0.824 f1:  0.8382502\n",
            "language:  xho precision:  0.9330544 recall:  0.892 f1:  0.9120654\n",
            "language:  bho precision:  0.9670782 recall:  0.94 f1:  0.9533468\n",
            "language:  stq precision:  0.965587 recall:  0.954 f1:  0.95975846\n",
            "language:  jav precision:  0.9288618 recall:  0.914 f1:  0.92137086\n",
            "language:  xmf precision:  0.98329854 recall:  0.942 f1:  0.9622063\n",
            "language:  scn precision:  0.97183096 recall:  0.966 f1:  0.96890664\n",
            "language:  vec precision:  0.92339545 recall:  0.892 f1:  0.90742624\n",
            "language:  dty precision:  0.7321063 recall:  0.716 f1:  0.7239636\n",
            "language:  pfl precision:  0.84504133 recall:  0.818 f1:  0.8313008\n",
            "language:  lit precision:  0.9364035 recall:  0.854 f1:  0.89330536\n",
            "language:  koi precision:  0.8867521 recall:  0.83 f1:  0.85743797\n",
            "language:  urd precision:  0.9959432 recall:  0.982 f1:  0.98892236\n",
            "language:  nrm precision:  0.95501024 recall:  0.934 f1:  0.9443883\n",
            "language:  sco precision:  0.9006211 recall:  0.87 f1:  0.88504577\n",
            "language:  sme precision:  0.95454544 recall:  0.882 f1:  0.9168399\n",
            "language:  hye precision:  0.99383986 recall:  0.968 f1:  0.98074967\n",
            "language:  nav precision:  1.0 recall:  0.998 f1:  0.99899894\n",
            "language:  olo precision:  0.95680344 recall:  0.886 f1:  0.92004144\n",
            "language:  kur precision:  0.96734697 recall:  0.948 f1:  0.95757574\n",
            "language:  cdo precision:  0.99364406 recall:  0.938 f1:  0.9650205\n",
            "language:  bel precision:  0.7257732 recall:  0.704 f1:  0.7147208\n",
            "language:  eng precision:  0.89081883 recall:  0.718 f1:  0.7951273\n",
            "language:  ara precision:  0.97363085 recall:  0.96 f1:  0.9667673\n",
            "language:  vls precision:  0.9381443 recall:  0.91 f1:  0.92385787\n",
            "language:  roa-tara precision:  0.9613035 recall:  0.944 f1:  0.95257306\n",
            "language:  mri precision:  0.993988 recall:  0.992 f1:  0.99299294\n",
            "language:  frp precision:  0.9189189 recall:  0.884 f1:  0.90112126\n",
            "language:  aym precision:  0.94045174 recall:  0.916 f1:  0.9280648\n",
            "language:  ast precision:  0.8947368 recall:  0.816 f1:  0.8535564\n",
            "language:  kaa precision:  0.93360996 recall:  0.9 f1:  0.9164969\n",
            "language:  mar precision:  0.96025103 recall:  0.918 f1:  0.9386502\n",
            "language:  hrv precision:  0.5 recall:  0.462 f1:  0.48024943\n",
            "language:  bar precision:  0.8742004 recall:  0.82 f1:  0.8462331\n",
            "language:  mhr precision:  0.95501024 recall:  0.934 f1:  0.9443883\n",
            "language:  mal precision:  0.975 recall:  0.858 f1:  0.9127659\n",
            "language:  epo precision:  0.96066254 recall:  0.928 f1:  0.9440487\n",
            "language:  bod precision:  0.97530866 recall:  0.158 f1:  0.2719449\n",
            "language:  uzb precision:  0.9489796 recall:  0.93 f1:  0.9393939\n",
            "language:  hsb precision:  0.9665272 recall:  0.924 f1:  0.94478524\n",
            "language:  eus precision:  0.97325104 recall:  0.946 f1:  0.959432\n",
            "language:  tat precision:  0.93775934 recall:  0.904 f1:  0.9205702\n",
            "language:  wln precision:  0.98163265 recall:  0.962 f1:  0.9717172\n",
            "language:  tsn precision:  0.9653768 recall:  0.948 f1:  0.9566094\n",
            "language:  war precision:  0.996 recall:  0.996 f1:  0.99599993\n",
            "language:  lzh precision:  0.0 recall:  0.0 f1:  0.0\n",
            "language:  egl precision:  0.93660533 recall:  0.916 f1:  0.926188\n",
            "language:  swa precision:  0.95679015 recall:  0.93 f1:  0.9432048\n",
            "language:  nds-nl precision:  0.9018405 recall:  0.882 f1:  0.8918098\n",
            "language:  arg precision:  0.8953975 recall:  0.856 f1:  0.8752555\n",
            "language:  bul precision:  0.95625 recall:  0.918 f1:  0.9367346\n",
            "language:  pan precision:  0.9979716 recall:  0.984 f1:  0.99093646\n",
            "language:  lat precision:  0.94725275 recall:  0.862 f1:  0.9026177\n",
            "language:  lez precision:  0.94409937 recall:  0.912 f1:  0.92777205\n",
            "language:  ukr precision:  0.9240506 recall:  0.876 f1:  0.8993839\n",
            "language:  vro precision:  0.9373695 recall:  0.898 f1:  0.91726243\n",
            "language:  slk precision:  0.9378882 recall:  0.906 f1:  0.9216683\n",
            "language:  isl precision:  0.9757576 recall:  0.966 f1:  0.97085416\n",
            "language:  tur precision:  0.8898305 recall:  0.84 f1:  0.8641975\n",
            "language:  kir precision:  0.9756098 recall:  0.96 f1:  0.96774185\n",
            "language:  afr precision:  0.96957403 recall:  0.956 f1:  0.96273905\n",
            "language:  nob precision:  0.89938396 recall:  0.876 f1:  0.8875379\n",
            "language:  sah precision:  0.96487606 recall:  0.934 f1:  0.949187\n",
            "language:  che precision:  0.9777778 recall:  0.968 f1:  0.9728642\n",
            "language:  tel precision:  0.9663158 recall:  0.918 f1:  0.9415384\n",
            "language:  sna precision:  0.94600433 recall:  0.876 f1:  0.90965724\n",
            "language:  bjn precision:  0.954918 recall:  0.932 f1:  0.94331974\n",
            "language:  kat precision:  0.9853557 recall:  0.942 f1:  0.96319014\n",
            "language:  yor precision:  0.9227468 recall:  0.86 f1:  0.8902691\n",
            "language:  hak precision:  0.95188284 recall:  0.91 f1:  0.9304702\n",
            "language:  vol precision:  0.9898167 recall:  0.972 f1:  0.9808274\n",
            "language:  glg precision:  0.88631576 recall:  0.842 f1:  0.86358964\n",
            "language:  div precision:  1.0 recall:  0.97 f1:  0.98477155\n",
            "language:  som precision:  0.95218295 recall:  0.916 f1:  0.93374103\n",
            "language:  lav precision:  0.96218485 recall:  0.916 f1:  0.93852454\n",
            "language:  ksh precision:  0.91463417 recall:  0.9 f1:  0.90725803\n",
            "language:  ltg precision:  0.9456067 recall:  0.904 f1:  0.9243353\n",
            "language:  ckb precision:  0.99597585 recall:  0.99 f1:  0.9929789\n",
            "language:  kaz precision:  0.94813275 recall:  0.914 f1:  0.9307534\n",
            "language:  hif precision:  0.9392034 recall:  0.896 f1:  0.9170931\n",
            "language:  grn precision:  0.95501024 recall:  0.934 f1:  0.9443883\n",
            "language:  swe precision:  0.9717742 recall:  0.964 f1:  0.9678714\n",
            "language:  asm precision:  0.97148675 recall:  0.954 f1:  0.9626639\n",
            "language:  ibo precision:  0.92484343 recall:  0.886 f1:  0.90500504\n",
            "language:  yid precision:  0.9859155 recall:  0.98 f1:  0.98294884\n",
            "language:  guj precision:  0.97938144 recall:  0.95 f1:  0.964467\n",
            "language:  srd precision:  0.9259259 recall:  0.9 f1:  0.91277885\n",
            "language:  khm precision:  0.80737704 recall:  0.394 f1:  0.52956986\n",
            "language:  tyv precision:  0.98556703 recall:  0.956 f1:  0.97055835\n",
            "language:  jam precision:  0.97565925 recall:  0.962 f1:  0.9687814\n",
            "language:  uig precision:  0.98128897 recall:  0.944 f1:  0.9622833\n",
            "language:  pag precision:  0.88612837 recall:  0.856 f1:  0.87080365\n",
            "language:  ton precision:  0.99597585 recall:  0.99 f1:  0.9929789\n",
            "language:  aze precision:  0.9670103 recall:  0.938 f1:  0.9522842\n",
            "language:  mlg precision:  0.994 recall:  0.994 f1:  0.99399996\n",
            "language:  tuk precision:  0.96303904 recall:  0.938 f1:  0.9503545\n",
            "language:  pap precision:  0.927686 recall:  0.898 f1:  0.9126016\n",
            "language:  kom precision:  0.88322717 recall:  0.832 f1:  0.8568486\n",
            "language:  min precision:  0.992 recall:  0.992 f1:  0.9919999\n",
            "language:  vep precision:  0.97649574 recall:  0.914 f1:  0.94421476\n",
            "language:  ind precision:  0.87708336 recall:  0.842 f1:  0.8591836\n",
            "language:  mlt precision:  0.99196786 recall:  0.988 f1:  0.98997986\n",
            "language:  lij precision:  0.9409283 recall:  0.892 f1:  0.915811\n",
            "language:  wuu precision:  0.0 recall:  0.0 f1:  0.0\n",
            "language:  crh precision:  0.9246862 recall:  0.884 f1:  0.90388536\n",
            "language:  mon precision:  0.9593496 recall:  0.944 f1:  0.95161283\n",
            "language:  azb precision:  0.9777328 recall:  0.966 f1:  0.97183096\n",
            "language:  fry precision:  0.97125256 recall:  0.946 f1:  0.9584599\n",
            "language:  chv precision:  0.97077245 recall:  0.93 f1:  0.94994885\n",
            "language:  chr precision:  0.9878296 recall:  0.974 f1:  0.98086596\n",
            "language:  ido precision:  0.96480334 recall:  0.932 f1:  0.9481179\n",
            "language:  mai precision:  0.94715446 recall:  0.932 f1:  0.93951607\n",
            "language:  cat precision:  0.96694213 recall:  0.936 f1:  0.95121944\n",
            "language:  lrc precision:  0.92168677 recall:  0.918 f1:  0.9198396\n",
            "language:  rue precision:  0.9051724 recall:  0.84 f1:  0.87136924\n",
            "language:  cbk precision:  0.7653277 recall:  0.724 f1:  0.7440904\n",
            "language:  ile precision:  0.9631236 recall:  0.888 f1:  0.9240374\n",
            "language:  ben precision:  0.970276 recall:  0.914 f1:  0.9412976\n",
            "language:  cor precision:  0.9714286 recall:  0.952 f1:  0.96161616\n",
            "language:  nci precision:  0.9198312 recall:  0.872 f1:  0.8952771\n",
            "language:  lao precision:  0.9102564 recall:  0.568 f1:  0.6995073\n",
            "language:  sun precision:  0.9570552 recall:  0.936 f1:  0.9464105\n",
            "language:  rus precision:  0.8512035 recall:  0.778 f1:  0.8129571\n",
            "language:  ell precision:  0.98790324 recall:  0.98 f1:  0.9839357\n",
            "language:  jbo precision:  0.99196786 recall:  0.988 f1:  0.98997986\n",
            "language:  kbd precision:  0.9876033 recall:  0.956 f1:  0.9715446\n",
            "language:  orm precision:  0.975 recall:  0.936 f1:  0.955102\n",
            "language:  zea precision:  0.85858583 recall:  0.85 f1:  0.8542713\n",
            "language:  fas precision:  0.94939274 recall:  0.938 f1:  0.9436619\n",
            "language:  nds precision:  0.91493773 recall:  0.882 f1:  0.898167\n",
            "language:  myv precision:  0.9079229 recall:  0.848 f1:  0.87693894\n",
            "language:  bcl precision:  0.9799197 recall:  0.976 f1:  0.9779558\n",
            "language:  fin precision:  0.9255319 recall:  0.87 f1:  0.89690715\n",
            "language:  szl precision:  0.9634146 recall:  0.948 f1:  0.95564514\n",
            "language:  lin precision:  0.9459459 recall:  0.91 f1:  0.9276248\n",
            "language:  tgl precision:  0.9878049 recall:  0.972 f1:  0.97983867\n",
            "language:  hau precision:  0.9635627 recall:  0.952 f1:  0.9577464\n",
            "language:  mya precision:  0.97952217 recall:  0.574 f1:  0.7238335\n",
            "language:  srn precision:  0.97946614 recall:  0.954 f1:  0.96656525\n",
            "language:  hin precision:  0.95714283 recall:  0.938 f1:  0.94747466\n",
            "language:  fao precision:  0.9632653 recall:  0.944 f1:  0.95353526\n",
            "language:  tam precision:  0.984375 recall:  0.882 f1:  0.93037975\n",
            "language:  ace precision:  0.98582995 recall:  0.974 f1:  0.9798792\n",
            "language:  wol precision:  0.96443516 recall:  0.922 f1:  0.9427402\n",
            "language:  ces precision:  0.9305263 recall:  0.884 f1:  0.90666664\n",
            "language:  sgs precision:  0.9682875 recall:  0.916 f1:  0.94141823\n",
            "language:  ceb precision:  0.98995984 recall:  0.986 f1:  0.9879759\n",
            "language:  bpy precision:  0.98991936 recall:  0.982 f1:  0.98594373\n",
            "language:  ltz precision:  0.9459459 recall:  0.91 f1:  0.9276248\n",
            "language:  dan precision:  0.9130435 recall:  0.882 f1:  0.89725333\n",
            "language:  ang precision:  0.94736844 recall:  0.9 f1:  0.9230768\n",
            "language:  oci precision:  0.85021096 recall:  0.806 f1:  0.82751536\n",
            "language:  dsb precision:  0.9458333 recall:  0.908 f1:  0.92653054\n",
            "language:  arz precision:  0.91902834 recall:  0.908 f1:  0.9134808\n",
            "language:  sqi precision:  0.9652352 recall:  0.944 f1:  0.95449936\n",
            "language:  krc precision:  0.9506173 recall:  0.924 f1:  0.9371196\n",
            "language:  mwl precision:  0.960334 recall:  0.92 f1:  0.9397344\n",
            "language:  mkd precision:  0.9672131 recall:  0.944 f1:  0.9554655\n",
            "language:  ita precision:  0.90295357 recall:  0.856 f1:  0.87885004\n",
            "language:  ina precision:  0.9378882 recall:  0.906 f1:  0.9216683\n",
            "language:  pdc precision:  0.88396627 recall:  0.838 f1:  0.86036956\n",
            "language:  be-tarask precision:  0.81041664 recall:  0.778 f1:  0.7938775\n",
            "language:  ilo precision:  0.9775051 recall:  0.956 f1:  0.9666329\n",
            "language:  pcd precision:  0.7311111 recall:  0.658 f1:  0.69263154\n",
            "language:  bak precision:  0.9755102 recall:  0.956 f1:  0.9656564\n",
            "language:  pnb precision:  0.98995984 recall:  0.986 f1:  0.9879759\n",
            "language:  bos precision:  0.57641923 recall:  0.528 f1:  0.5511482\n",
            "language:  nso precision:  0.97363085 recall:  0.96 f1:  0.9667673\n",
            "language:  bxr precision:  0.94214875 recall:  0.912 f1:  0.92682916\n",
            "language:  gla precision:  0.9816701 recall:  0.964 f1:  0.9727547\n",
            "language:  als precision:  0.93514645 recall:  0.894 f1:  0.9141104\n",
            "language:  glk precision:  0.9085366 recall:  0.894 f1:  0.9012096\n",
            "language:  mzn precision:  0.93509126 recall:  0.922 f1:  0.92849946\n",
            "language:  srp precision:  0.9411765 recall:  0.896 f1:  0.9180327\n",
            "language:  nld precision:  0.89117044 recall:  0.868 f1:  0.87943256\n",
            "language:  kor precision:  0.9979592 recall:  0.978 f1:  0.98787874\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jFoYvQVzg0C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_metrics = pd.DataFrame(\n",
        "    {'precision': ps,\n",
        "     'recall': rs,\n",
        "     'f1': fs\n",
        "    })"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXV6tZ4Dzh4L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "metrics = raw_metrics.rename(class_to_language, axis='index')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DIQwh8Z0Gq8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "ba95e574-54bc-4931-d3df-fb2a3385296d"
      },
      "source": [
        "print(metrics.head())"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     precision  recall        f1\n",
            "nep   0.901235   0.876  0.888438\n",
            "est   0.859770   0.748  0.800000\n",
            "vie   0.989940   0.984  0.986961\n",
            "pam   0.960581   0.926  0.942973\n",
            "csb   0.912245   0.894  0.903030\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tn_XJXIs45JJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "outputId": "4c36cef7-91ab-4464-ae15-a18c5d6cae83"
      },
      "source": [
        "bad_quality_metrics = metrics[metrics.f1 < 0.7]\n",
        "bad_quality_metrics"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>zh-yue</th>\n",
              "      <td>0.478873</td>\n",
              "      <td>0.068</td>\n",
              "      <td>0.119089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tha</th>\n",
              "      <td>0.953069</td>\n",
              "      <td>0.528</td>\n",
              "      <td>0.679537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zho</th>\n",
              "      <td>0.343750</td>\n",
              "      <td>0.022</td>\n",
              "      <td>0.041353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hbs</th>\n",
              "      <td>0.647321</td>\n",
              "      <td>0.580</td>\n",
              "      <td>0.611814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>jpn</th>\n",
              "      <td>0.840580</td>\n",
              "      <td>0.116</td>\n",
              "      <td>0.203866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hrv</th>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.462</td>\n",
              "      <td>0.480249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bod</th>\n",
              "      <td>0.975309</td>\n",
              "      <td>0.158</td>\n",
              "      <td>0.271945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lzh</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>khm</th>\n",
              "      <td>0.807377</td>\n",
              "      <td>0.394</td>\n",
              "      <td>0.529570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>wuu</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lao</th>\n",
              "      <td>0.910256</td>\n",
              "      <td>0.568</td>\n",
              "      <td>0.699507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pcd</th>\n",
              "      <td>0.731111</td>\n",
              "      <td>0.658</td>\n",
              "      <td>0.692632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bos</th>\n",
              "      <td>0.576419</td>\n",
              "      <td>0.528</td>\n",
              "      <td>0.551148</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        precision  recall        f1\n",
              "zh-yue   0.478873   0.068  0.119089\n",
              "tha      0.953069   0.528  0.679537\n",
              "zho      0.343750   0.022  0.041353\n",
              "hbs      0.647321   0.580  0.611814\n",
              "jpn      0.840580   0.116  0.203866\n",
              "hrv      0.500000   0.462  0.480249\n",
              "bod      0.975309   0.158  0.271945\n",
              "lzh      0.000000   0.000  0.000000\n",
              "khm      0.807377   0.394  0.529570\n",
              "wuu      0.000000   0.000  0.000000\n",
              "lao      0.910256   0.568  0.699507\n",
              "pcd      0.731111   0.658  0.692632\n",
              "bos      0.576419   0.528  0.551148"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqs-mCe43x4e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "outputId": "62ff6ae4-57ad-45f6-a3a4-36c1744b52bf"
      },
      "source": [
        "bad_quality_langs = list(bad_quality_metrics.index)\n",
        "bad_quality_labels = labels.loc[labels['Label'].isin(bad_quality_langs)]\n",
        "bad_quality_labels"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>English</th>\n",
              "      <th>Wiki Code</th>\n",
              "      <th>ISO 369-3</th>\n",
              "      <th>Language family</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>bod</td>\n",
              "      <td>Tibetan</td>\n",
              "      <td>bo</td>\n",
              "      <td>bod</td>\n",
              "      <td>Sino-Tibetan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>bos</td>\n",
              "      <td>Bosnian</td>\n",
              "      <td>bs</td>\n",
              "      <td>bos</td>\n",
              "      <td>Indo-European</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>hbs</td>\n",
              "      <td>Serbo-Croatian</td>\n",
              "      <td>sh</td>\n",
              "      <td>hbs</td>\n",
              "      <td>Indo-European</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>hrv</td>\n",
              "      <td>Croatian</td>\n",
              "      <td>hr</td>\n",
              "      <td>hrv</td>\n",
              "      <td>Indo-European</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>jpn</td>\n",
              "      <td>Japanese</td>\n",
              "      <td>ja</td>\n",
              "      <td>jpn</td>\n",
              "      <td>Japonic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>khm</td>\n",
              "      <td>Central Khmer</td>\n",
              "      <td>km</td>\n",
              "      <td>khm</td>\n",
              "      <td>Austronesian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>lao</td>\n",
              "      <td>Lao</td>\n",
              "      <td>lo</td>\n",
              "      <td>lao</td>\n",
              "      <td>Tai-Kadai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123</th>\n",
              "      <td>lzh</td>\n",
              "      <td>Literary Chinese</td>\n",
              "      <td>zh-classical</td>\n",
              "      <td>lzh</td>\n",
              "      <td>Sino-Tibetan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>pcd</td>\n",
              "      <td>Picard</td>\n",
              "      <td>pcd</td>\n",
              "      <td>pcd</td>\n",
              "      <td>Indo-European</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207</th>\n",
              "      <td>tha</td>\n",
              "      <td>Thai</td>\n",
              "      <td>th</td>\n",
              "      <td>tha</td>\n",
              "      <td>Tai-Kadai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227</th>\n",
              "      <td>wuu</td>\n",
              "      <td>Wu Chinese</td>\n",
              "      <td>wuu</td>\n",
              "      <td>wuu</td>\n",
              "      <td>Sino-Tibetan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>233</th>\n",
              "      <td>zh-yue</td>\n",
              "      <td>Cantonese</td>\n",
              "      <td>zh-yue</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Sino-Tibetan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>234</th>\n",
              "      <td>zho</td>\n",
              "      <td>Standard Chinese</td>\n",
              "      <td>zh</td>\n",
              "      <td>zho</td>\n",
              "      <td>Sino-Tibetan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Label           English     Wiki Code ISO 369-3 Language family\n",
              "22      bod           Tibetan            bo       bod    Sino-Tibetan\n",
              "23      bos           Bosnian            bs       bos   Indo-European\n",
              "73      hbs    Serbo-Croatian            sh       hbs   Indo-European\n",
              "77      hrv          Croatian            hr       hrv   Indo-European\n",
              "92      jpn          Japanese            ja       jpn         Japonic\n",
              "99      khm     Central Khmer            km       khm    Austronesian\n",
              "110     lao               Lao            lo       lao       Tai-Kadai\n",
              "123     lzh  Literary Chinese  zh-classical       lzh    Sino-Tibetan\n",
              "164     pcd            Picard           pcd       pcd   Indo-European\n",
              "207     tha              Thai            th       tha       Tai-Kadai\n",
              "227     wuu        Wu Chinese           wuu       wuu    Sino-Tibetan\n",
              "233  zh-yue         Cantonese        zh-yue       NaN    Sino-Tibetan\n",
              "234     zho  Standard Chinese            zh       zho    Sino-Tibetan"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUkII9aS9iK1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "883b7b6c-40a0-4dc4-e19f-f27921293ccb"
      },
      "source": [
        "print(x_train[x_train.sc == language_to_class['wuu']])\n",
        "print(x_train[x_train.sc == language_to_class['lzh']])"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                     sent   sc\n",
            "19      UNC有得一只历史悠久个'诚信守则'。渠是由学堂个诚信法庭（Honor Court）来执行个...  162\n",
            "276     武器，是人类为达到杀伤或者防御个目的制造个器械。武器从人类文明发展开始就有出现，之后，伴随战...  162\n",
            "387     弗过，太后个信任是一方面，具体西班牙个政治局面又是另外一番情形：贵族对迭个外国人一点也无信任...  162\n",
            "720     从12世纪挨末阶段开始，日本个统治权就转移到日本武士贵族个手里向。到13世纪，出身清和源氏个...  162\n",
            "930     箇种毛病潜伏期一般勒7日天以内，病人一般表现为流感箇浪个症状，像发寒热，咳嗽，少痰，有种辰光...  162\n",
            "...                                                   ...  ...\n",
            "116805  Linux個低成本、強大個定制功能搭良好個移植性能，使得Linux來嵌入式系統方面也得到廣泛...  162\n",
            "116947  余杭區勒拉杭嘉湖平原南端，西依天目山，南瀕錢塘江，是長江三角洲个圓心地。地理座標爲北緯30°...  162\n",
            "117034  北師大是以京師大學堂師範專業做基礎，搭仔由北京個高校匯聚一批勒師範教育領域窮有聲望個名師組建...  162\n",
            "117037  到清中期（約18世紀），傳奇開始衰微，向書齋文學轉化，彈詞卻逐步興盛起來了。出版之錢德蒼編个...  162\n",
            "117257  摩嘉娜夺权计划失败后，带领奄奄一息个莫高絲逃出卡美洛特，徕萨温节夜里，摩嘉娜徕莫高絲个要求之...  162\n",
            "\n",
            "[500 rows x 2 columns]\n",
            "                                                     sent   sc\n",
            "336     武漢市，亦稱以漢，乃中華鄂省之會，亦為七大都市於中華之中原也。方八千四百六十七公里，於西元二...  104\n",
            "420     按黃帝為法，數有十等。及其用也，乃有三焉。十等者，謂「億、兆、京、垓、秭、壤、溝、澗、正、載...  104\n",
            "1254    范蠡浮海出齊，變姓名，自謂鴟夷子皮，耕於海畔，苦身戮力，父子治產。居無幾何，致產數千萬。齊人...  104\n",
            "1414    周迪據臨川反，詔昭達便道征之。迪敗走，徵為護軍將軍，改封邵武縣侯。四年，陳寶應納迪，共寇臨川...  104\n",
            "1549    喇克達長子敬德，康熙十一年(一六七二年)封三等奉恩將軍，四十七年(一七零八年)卒。敬德次子班...  104\n",
            "...                                                   ...  ...\n",
            "116047  士族者，或曰門第、衣冠、世族、門閥、勢族、世家、巨室。蓋謂世居要位之高門也，世族所居不同，中...  104\n",
            "116419  淳化二年秋七月，李繼遷請降，以爲銀州觀察使，賜姓名趙保吉。繼捧至夏州數月，即言繼遷悔過歸款，...  104\n",
            "116596  孟嘗君怨秦，將以齊為韓、魏攻楚，因與韓、魏攻秦，而借兵食於西周。蘇代為西周謂曰：「君以齊為韓...  104\n",
            "116749  陳敏之亂，弘以侃為江夏太守，加鷹揚將軍。侃備威儀，迎母官舍，鄉裡榮之。敏遣其弟恢來寇武昌，侃...  104\n",
            "117497  同年，太后崩。絳侯周勃、陳平諸臣共謀誅呂。朱虛侯章已殺呂產，文帝使人持節勞章。朱虛侯欲奪節信...  104\n",
            "\n",
            "[500 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}