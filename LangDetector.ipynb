{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of hackaton.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpmSbtrCklRB",
        "colab_type": "code",
        "outputId": "65639546-7c53-44fc-b43c-46aa10c9f734",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNLhWWCxYfLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "import scipy\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import logging\n",
        "import multiprocessing\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8IzA7Rx-VzU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Bidirectional, GlobalMaxPooling1D, GlobalMaxPool1D, MaxPooling1D, Flatten, concatenate\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras import initializers, regularizers, constraints, optimizers, layers\n",
        "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1vZGIRYYR9G",
        "colab_type": "text"
      },
      "source": [
        "# Hanna's data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFKrCtLZYBcV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import zipfile\n",
        "# with zipfile.ZipFile('./drive/My Drive/hackaton/wili-2018.zip', 'r') as zip_ref:\n",
        "#     zip_ref.extractall('./')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcwIDfWAYOUl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data_path = '/content/drive/My Drive/Colab Notebooks/Hackathon/'\n",
        "# wili_data_path = ''\n",
        "\n",
        "# x_train_path = wili_data_path + 'x_train.txt'\n",
        "# x_test_path = wili_data_path + 'x_test.txt'\n",
        "# y_train_path = wili_data_path + 'y_train.txt'\n",
        "# y_test_path = wili_data_path + 'y_test.txt'\n",
        "# labels_path = wili_data_path + 'labels.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc94smEhjbA_",
        "colab_type": "text"
      },
      "source": [
        "# Download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75potnAshWU4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path = '/content/drive/My Drive/Colab Notebooks/Hackathon/'\n",
        "wili_data_path = data_path + 'wili-2018/'\n",
        "\n",
        "x_train_path = wili_data_path + 'x_train.txt'\n",
        "x_test_path = wili_data_path + 'x_test.txt'\n",
        "y_train_path = wili_data_path + 'y_train.txt'\n",
        "y_test_path = wili_data_path + 'y_test.txt'\n",
        "labels_path = wili_data_path + 'labels.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhsiujWS3QR8",
        "colab_type": "code",
        "outputId": "ae6b26cc-d4d3-4ccd-d23d-86804c9f8d58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "labels = pd.read_csv(labels_path, sep=';')\n",
        "labels = labels.drop(labels=['German', 'Writing system', 'Remarks', 'Synonyms'], axis=1)\n",
        "labels"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>English</th>\n",
              "      <th>Wiki Code</th>\n",
              "      <th>ISO 369-3</th>\n",
              "      <th>Language family</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ace</td>\n",
              "      <td>Achinese</td>\n",
              "      <td>ace</td>\n",
              "      <td>ace</td>\n",
              "      <td>Austronesian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>afr</td>\n",
              "      <td>Afrikaans</td>\n",
              "      <td>af</td>\n",
              "      <td>afr</td>\n",
              "      <td>Indo-European</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>als</td>\n",
              "      <td>Alemannic German</td>\n",
              "      <td>als</td>\n",
              "      <td>gsw</td>\n",
              "      <td>Indo-European</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>amh</td>\n",
              "      <td>Amharic</td>\n",
              "      <td>am</td>\n",
              "      <td>amh</td>\n",
              "      <td>Afro-Asiatic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ang</td>\n",
              "      <td>Old English</td>\n",
              "      <td>ang</td>\n",
              "      <td>ang</td>\n",
              "      <td>Indo-European</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>230</th>\n",
              "      <td>yid</td>\n",
              "      <td>Yiddish</td>\n",
              "      <td>yi</td>\n",
              "      <td>yid</td>\n",
              "      <td>Indo-European</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>231</th>\n",
              "      <td>yor</td>\n",
              "      <td>Yoruba</td>\n",
              "      <td>yo</td>\n",
              "      <td>yor</td>\n",
              "      <td>Niger-Congo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>232</th>\n",
              "      <td>zea</td>\n",
              "      <td>Zeeuws</td>\n",
              "      <td>zea</td>\n",
              "      <td>zea</td>\n",
              "      <td>Indo-European</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>233</th>\n",
              "      <td>zh-yue</td>\n",
              "      <td>Cantonese</td>\n",
              "      <td>zh-yue</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Sino-Tibetan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>234</th>\n",
              "      <td>zho</td>\n",
              "      <td>Standard Chinese</td>\n",
              "      <td>zh</td>\n",
              "      <td>zho</td>\n",
              "      <td>Sino-Tibetan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>235 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Label           English Wiki Code ISO 369-3 Language family\n",
              "0       ace          Achinese       ace       ace    Austronesian\n",
              "1       afr         Afrikaans        af       afr   Indo-European\n",
              "2       als  Alemannic German       als       gsw   Indo-European\n",
              "3       amh           Amharic        am       amh    Afro-Asiatic\n",
              "4       ang      Old English        ang       ang   Indo-European\n",
              "..      ...               ...       ...       ...             ...\n",
              "230     yid           Yiddish        yi       yid   Indo-European\n",
              "231     yor            Yoruba        yo       yor     Niger-Congo\n",
              "232     zea            Zeeuws       zea       zea   Indo-European\n",
              "233  zh-yue         Cantonese    zh-yue       NaN    Sino-Tibetan\n",
              "234     zho  Standard Chinese        zh       zho    Sino-Tibetan\n",
              "\n",
              "[235 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpH6qYnlYrBN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_to_language = labels.Label.astype(str).to_dict()\n",
        "language_to_class = {v: k for k, v in class_to_language.items()}\n",
        "num_classes = len(class_to_language)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDFr3-rKmDdv",
        "colab_type": "code",
        "outputId": "4825f94f-06da-485a-d4c6-843d37704e58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(list(language_to_class.items())[:5])\n",
        "num_classes"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('ace', 0), ('afr', 1), ('als', 2), ('amh', 3), ('ang', 4)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "235"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBqkjck1Yc7q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_data():\n",
        "    with open(x_train_path) as f:\n",
        "        mylist = f.read().splitlines() \n",
        "    x_train = pd.DataFrame(mylist, columns=[\"sent\"])\n",
        "    with open(x_test_path) as f:\n",
        "        mylist = f.read().splitlines() \n",
        "    x_test = pd.DataFrame(mylist, columns=[\"sent\"])\n",
        "\n",
        "    with open(y_train_path) as f:\n",
        "        mylist = f.read().splitlines() \n",
        "    y_train = []\n",
        "    for lan in mylist:\n",
        "        y_train.append(language_to_class[lan])\n",
        "    y_train = pd.DataFrame(y_train)\n",
        "    with open(y_test_path) as f:\n",
        "        mylist = f.read().splitlines()\n",
        "\n",
        "    y_test = []\n",
        "    for lan in mylist:\n",
        "        y_test.append(language_to_class[lan])\n",
        "    y_test = pd.DataFrame(y_test)\n",
        "    \n",
        "    return (x_train, y_train), (x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRo0Wf1lZXsE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = read_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhKRW6V8hhIc",
        "colab_type": "code",
        "outputId": "dd1ae54b-9c9a-4e42-8e4a-60e72c59e25a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "print(x_train.head())\n",
        "print(y_train.head())\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                sent\n",
            "0  Klement Gottwaldi surnukeha palsameeriti ning ...\n",
            "1  Sebes, Joseph; Pereira Thomas (1961) (på eng)....\n",
            "2  भारतीय स्वातन्त्र्य आन्दोलन राष्ट्रीय एवम क्षे...\n",
            "3  Après lo cort periòde d'establiment a Basilèa,...\n",
            "4  ถนนเจริญกรุง (อักษรโรมัน: Thanon Charoen Krung...\n",
            "     0\n",
            "0   52\n",
            "1  198\n",
            "2  124\n",
            "3  155\n",
            "4  207\n",
            "(117500, 1)\n",
            "(117500, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zcUciRigFYu",
        "colab_type": "code",
        "outputId": "af506a98-67ed-462e-9ea5-214ad7eb7835",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "lens = x_train.sent.str.split(' ').str.len().values\n",
        "plt.hist(lens, bins=np.linspace(0,1000,20), facecolor='blue', alpha=0.9)\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xdCSiHnhlX1",
        "colab_type": "text"
      },
      "source": [
        "# Experiment on small dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFTqOQmChknq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# small_dataset = pd.read_csv(data_path + 'kaggle_dataset/dataset.csv')\n",
        "# small_dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwtWy38ehtGO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X=small_dataset['Text']\n",
        "# y=small_dataset['language']\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# print(len(X_train))\n",
        "# print(len(X_test))\n",
        "# print(len(y_train))\n",
        "# print(len(y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNoYz_IwjeY_",
        "colab_type": "text"
      },
      "source": [
        "# Embedding **data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEr8pklSjQLP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filter_out = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n1234567890'\n",
        "tokenizer = Tokenizer(filters=filter_out, lower=True)\n",
        "tokenizer.fit_on_texts(x_train.sent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5jxVwDcftcn",
        "colab_type": "text"
      },
      "source": [
        "Выбираю какое количество слов оставить. Если оставлять все, то будет 1500000, что слишком много. Можно поменять `count` и оно покажет сколько слов встречается больше, чем `count` раз"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xKQt34TAG2-",
        "colab_type": "code",
        "outputId": "713c201c-ef0d-42aa-9d11-c07c5acf3965",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# try different values of `count`\n",
        "# show how many words are presenting more than `count` times\n",
        "count = 10\n",
        "frequent_words = [w for w,c in tokenizer.word_counts.items() if c > count]\n",
        "len(frequent_words)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64157"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwDeU_wRph8C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_data(train_x, train_y, tokenizator, max_len_of_vector):\n",
        "    x_tr, x_val, y_tr, y_val = train_test_split(train_x, train_y, test_size=0.1, random_state=1, stratify=train_y.values)\n",
        "   \n",
        "    tokenizator.fit_on_texts(x_tr.sent)\n",
        "\n",
        "    train_X = tokenizator.texts_to_sequences(x_tr.sent)\n",
        "    val_X = tokenizator.texts_to_sequences(x_val.sent)\n",
        "\n",
        "    ## Pad the sentences \n",
        "    train_X = pad_sequences(train_X, maxlen=max_len_of_vector)\n",
        "    val_X = pad_sequences(val_X, maxlen=max_len_of_vector)\n",
        "\n",
        "    return (train_X, y_tr), (val_X, y_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJacuBHhHEng",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embed_size = 300 # how big is each word vector\n",
        "max_features = len(frequent_words) # how many unique words to use (i.e num rows in embedding vector)\n",
        "maxlen = 200 # max number of words in a question to use\n",
        "\n",
        "## Tokenize the sentences\n",
        "tokenizer = Tokenizer(num_words=max_features, filters=filter_out, lower=True)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qW1oK9wfHEnm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_X, train_Y), (val_X, val_Y) = prepare_data(x_train, y_train, tokenizer, maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxyyqzKsgF9K",
        "colab_type": "text"
      },
      "source": [
        "Проверила, что в тренировочном и валидационном датасетах встречаются все классы. Балансировка регулируется вот этим параметром: stratify=y_train.values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1iJF7cyU5iK",
        "colab_type": "code",
        "outputId": "0e2796e5-74ff-40f6-ffaa-9fa0044504d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(set(val_Y.values.reshape(1, -1)[0]))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "235"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPITYtR8UqNx",
        "colab_type": "code",
        "outputId": "bd6109d0-bee2-49da-e883-fa693349294c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(set(train_Y.values.reshape(1, -1)[0]))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "235"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYuurOSQgYUl",
        "colab_type": "text"
      },
      "source": [
        "Ниже меняю представление векторов ответов из [1, 23, 10,...] в вектор длины 235 и с 1 на месте соответсвующего языка"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0iIyf4bIXg_",
        "colab_type": "code",
        "outputId": "cf095999-bdf1-4ad0-f0ca-ee48aeff00b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "lb = LabelEncoder()\n",
        "y = lb.fit_transform(train_Y.values)\n",
        "dummy_y_train = to_categorical(y)\n",
        "print(len(dummy_y_train))\n",
        "print(len(dummy_y_train[0]))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "105750\n",
            "235\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:251: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCBYAruyIxUm",
        "colab_type": "code",
        "outputId": "8e017e4b-2ea7-4c28-fa64-b80035ec4555",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "y = lb.fit_transform(val_Y.values)\n",
        "dummy_y_val = to_categorical(y)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:251: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeXXgZJ6miyl",
        "colab_type": "text"
      },
      "source": [
        "# Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vp4rfHfplm6O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f1(y_true, y_pred): #taken from old keras source code\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return f1_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dzi3zyNsmNIR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def recall(y_true, y_pred): #taken from old keras source code\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    return true_positives / (possible_positives + K.epsilon())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JX13CaozmRhy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def precision(y_true, y_pred): #taken from old keras source code\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    return true_positives / (predicted_positives + K.epsilon())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtGH8P89gTXf",
        "colab_type": "text"
      },
      "source": [
        "#CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdsE9d9SjdsW",
        "colab_type": "code",
        "outputId": "a4d07a9a-e05b-4f1b-a701-cbf8acb49cc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        }
      },
      "source": [
        "cnn_model = Sequential()\n",
        "cnn_model.add(Embedding(max_features, embed_size,input_shape=(maxlen,)))\n",
        "cnn_model.add(Conv1D(256, 5, activation='relu', input_shape=(embed_size,)))\n",
        "cnn_model.add(MaxPooling1D(5))\n",
        "cnn_model.add(Dropout(0.2))\n",
        "cnn_model.add(Conv1D(256, 5, activation='relu'))\n",
        "cnn_model.add(MaxPooling1D(5))\n",
        "cnn_model.add(Flatten())\n",
        "cnn_model.add(Dense(512, activation=\"relu\"))\n",
        "cnn_model.add(Dropout(0.2))\n",
        "cnn_model.add(Dense(num_classes, activation='softmax'))\n",
        "cnn_model.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 200, 300)          19247100  \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 196, 256)          384256    \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 39, 256)           0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 39, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 35, 256)           327936    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 7, 256)            0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1792)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               918016    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 235)               120555    \n",
            "=================================================================\n",
            "Total params: 20,997,863\n",
            "Trainable params: 20,997,863\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sndko3XlZ806",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', f1, recall, precision])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aa9rf4_Oq6nX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn_cp_path = data_path+'model_cnn.hdf5'\n",
        "cnn_cp=ModelCheckpoint(cnn_cp_path, monitor='val_loss',save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIhz76oFHo_c",
        "colab_type": "code",
        "outputId": "9aebd8bb-4d02-4870-c6a5-7112d5901217",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "cnn_model.fit(train_X, dummy_y_train, batch_size=512, epochs=5, \n",
        "              validation_data=(val_X, dummy_y_val),\n",
        "              callbacks = [cnn_cp]\n",
        "             )"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "207/207 [==============================] - 57s 277ms/step - loss: 0.2398 - accuracy: 0.9342 - f1: 0.9476 - recall: 0.9183 - precision: 0.9789 - val_loss: 0.5040 - val_accuracy: 0.8928 - val_f1: 0.9124 - val_recall: 0.8751 - val_precision: 0.9531\n",
            "Epoch 2/5\n",
            "207/207 [==============================] - 56s 270ms/step - loss: 0.1736 - accuracy: 0.9495 - f1: 0.9601 - recall: 0.9371 - precision: 0.9844 - val_loss: 0.5702 - val_accuracy: 0.8906 - val_f1: 0.9106 - val_recall: 0.8776 - val_precision: 0.9463\n",
            "Epoch 3/5\n",
            "207/207 [==============================] - 55s 267ms/step - loss: 0.1442 - accuracy: 0.9568 - f1: 0.9671 - recall: 0.9473 - precision: 0.9878 - val_loss: 0.6290 - val_accuracy: 0.8901 - val_f1: 0.9063 - val_recall: 0.8773 - val_precision: 0.9375\n",
            "Epoch 4/5\n",
            "207/207 [==============================] - 55s 265ms/step - loss: 0.1313 - accuracy: 0.9602 - f1: 0.9702 - recall: 0.9521 - precision: 0.9891 - val_loss: 0.6761 - val_accuracy: 0.8877 - val_f1: 0.9057 - val_recall: 0.8786 - val_precision: 0.9346\n",
            "Epoch 5/5\n",
            "207/207 [==============================] - 55s 266ms/step - loss: 0.1295 - accuracy: 0.9609 - f1: 0.9709 - recall: 0.9536 - precision: 0.9888 - val_loss: 0.7026 - val_accuracy: 0.8906 - val_f1: 0.9080 - val_recall: 0.8822 - val_precision: 0.9353\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb8f6b0c1d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkmpFZmyUjF8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dependencies = {\n",
        "     'f1': f1,\n",
        "     'recall': recall,\n",
        "     'precision': precision\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qji8xqW2WiS-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cnn_model = load_model(cnn_cp_path, custom_objects=dependencies)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-T-4MO1ZR_S",
        "colab_type": "text"
      },
      "source": [
        "#RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ch0GFZ-ZSzb",
        "colab_type": "code",
        "outputId": "2d842e33-e0f9-4b8e-ae8d-e6d2b85eb4cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "rnn_model = Sequential()\n",
        "rnn_model.add(Embedding(max_features, embed_size))\n",
        "rnn_model.add(Bidirectional(LSTM(128, return_sequences=True, activation='tanh',input_dim=embed_size)))\n",
        "rnn_model.add(Dropout(0.2))\n",
        "rnn_model.add(Bidirectional(LSTM(128, return_sequences=True, activation='tanh')))\n",
        "rnn_model.add(GlobalMaxPool1D())\n",
        "rnn_model.add(Dropout(0.2))\n",
        "rnn_model.add(Dense(512, activation=\"relu\"))\n",
        "rnn_model.add(Dropout(0.2))\n",
        "rnn_model.add(Dense(num_classes, activation='softmax'))\n",
        "rnn_model.summary()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 300)         19247100  \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, None, 512)         1140736   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, None, 512)         0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, None, 512)         1574912   \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 235)               120555    \n",
            "=================================================================\n",
            "Total params: 22,345,959\n",
            "Trainable params: 22,345,959\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1W3XFHXZiVR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', f1, recall, precision])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPtLB7kUrGgE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rnn_cp_path = data_path + 'model_rnn.hdf5'\n",
        "rnn_cp=ModelCheckpoint(rnn_cp_path,monitor='val_f1',save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qK-tgijZk7L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# rnn_model.fit(train_X, dummy_y_train, batch_size=512, epochs=3, \n",
        "#               validation_data=(val_X, dummy_y_val), callbacks = [rnn_cp])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kk3g4PLUumt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rnn_model = load_model(rnn_cp_path, custom_objects=dependencies)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCeuUze_qnC2",
        "colab_type": "text"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jS0Tq-Cqb4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test['sc'] = y_test\n",
        "x_test['lang'] = [class_to_language[y] for y in list(y_test.iloc[:,0])]\n",
        "x_train['sc'] = y_train\n",
        "x_train['lang'] = [class_to_language[y] for y in list(y_train.iloc[:,0])]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wowtwiinqwm0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Be careful! Tokenizer and maxlen is taken from train dataset from 1st part\n",
        "def convert(x, tokenizator, max_vector_len):\n",
        "    train_X = tokenizator.texts_to_sequences(x.sent)\n",
        "    ## Pad the sentences \n",
        "    train_X = pad_sequences(train_X, maxlen=max_vector_len)\n",
        "    return train_X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvOMHL7Nx_eO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def metr(y_true, y_pred): #taken from old keras source code\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return precision, recall, f1_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hs6AXcPcsj1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f1(y_true, y_pred):\n",
        "    y_pred = K.round(y_pred)\n",
        "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
        "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
        "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
        "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
        "\n",
        "    p = tp / (tp + fp + K.epsilon())\n",
        "    r = tp / (tp + fn + K.epsilon())\n",
        "\n",
        "    f1 = 2*p*r / (p+r+K.epsilon())\n",
        "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
        "    return max(p), max(r), max(f1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adUqSHYSc2Ye",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# New metric!\n",
        "def met(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)), axis=0)\n",
        "    false_positives = K.sum(K.round(K.clip((1 - y_true) * y_pred, 0, 1)), axis=0)\n",
        "    true_negatives = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)), axis=0)\n",
        "    false_negatives = K.sum(K.round(K.clip(y_true * (1 - y_pred), 0, 1)), axis=0)\n",
        "    precision = max(true_positives / (true_positives + false_positives  + K.epsilon()))\n",
        "    recall = max(true_positives / (true_positives + false_negatives  + K.epsilon()))\n",
        "    f1 = 2 * precision * recall / (precision + recall + K.epsilon())\n",
        "    return precision, recall, f1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OwT-3obvsIo",
        "colab_type": "text"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P006Z5Sgzeal",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ps = []\n",
        "rs = []\n",
        "fs = []\n",
        "for lan in range(num_classes):\n",
        "    x_t = x_test[x_test['sc'] == lan]\n",
        "    x = convert(x_t, tokenizer, maxlen)\n",
        "    y = np.zeros((x.shape[0], num_classes))\n",
        "    y[:, lan] = 1\n",
        "    y = y.astype('float32')\n",
        "    y_pred = cnn_model.predict(x)\n",
        "    p, r, f = met(y, y_pred)\n",
        "    ps.append(p.numpy())\n",
        "    rs.append(r.numpy())\n",
        "    fs.append(f.numpy())\n",
        "    #print(\"language: \", class_to_language[lan], \"precision: \", p.numpy(), \"recall: \", r.numpy(), \"f1: \", f.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jFoYvQVzg0C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_metrics = pd.DataFrame(\n",
        "    {'precision': ps,\n",
        "     'recall': rs,\n",
        "     'f1': fs\n",
        "    })"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXV6tZ4Dzh4L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "metrics = raw_metrics.rename(class_to_language, axis='index')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zstxcPVgfUig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bad_quality_metrics = metrics[metrics.f1 < 0.7]\n",
        "lab = labels.set_index('Label')\n",
        "bad_quality_labels = lab.loc[bad_quality_metrics.index]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaImgEefHae0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "3bd7446b-545b-4073-ffa8-c6b222f13f06"
      },
      "source": [
        "res = pd.merge(bad_quality_labels.reset_index(), bad_quality_metrics.reset_index()) \\\n",
        ".set_index('index')\n",
        "res"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Wiki Code</th>\n",
              "      <th>ISO 369-3</th>\n",
              "      <th>Language family</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>bod</th>\n",
              "      <td>Tibetan</td>\n",
              "      <td>bo</td>\n",
              "      <td>bod</td>\n",
              "      <td>Sino-Tibetan</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.166</td>\n",
              "      <td>0.284734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hrv</th>\n",
              "      <td>Croatian</td>\n",
              "      <td>hr</td>\n",
              "      <td>hrv</td>\n",
              "      <td>Indo-European</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.522</td>\n",
              "      <td>0.685939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>jpn</th>\n",
              "      <td>Japanese</td>\n",
              "      <td>ja</td>\n",
              "      <td>jpn</td>\n",
              "      <td>Japonic</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.114</td>\n",
              "      <td>0.204668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>khm</th>\n",
              "      <td>Central Khmer</td>\n",
              "      <td>km</td>\n",
              "      <td>khm</td>\n",
              "      <td>Austronesian</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.432</td>\n",
              "      <td>0.603352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lzh</th>\n",
              "      <td>Literary Chinese</td>\n",
              "      <td>zh-classical</td>\n",
              "      <td>lzh</td>\n",
              "      <td>Sino-Tibetan</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tha</th>\n",
              "      <td>Thai</td>\n",
              "      <td>th</td>\n",
              "      <td>tha</td>\n",
              "      <td>Tai-Kadai</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.530</td>\n",
              "      <td>0.692810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>wuu</th>\n",
              "      <td>Wu Chinese</td>\n",
              "      <td>wuu</td>\n",
              "      <td>wuu</td>\n",
              "      <td>Sino-Tibetan</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.030</td>\n",
              "      <td>0.058252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zh-yue</th>\n",
              "      <td>Cantonese</td>\n",
              "      <td>zh-yue</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Sino-Tibetan</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.068</td>\n",
              "      <td>0.127341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zho</th>\n",
              "      <td>Standard Chinese</td>\n",
              "      <td>zh</td>\n",
              "      <td>zho</td>\n",
              "      <td>Sino-Tibetan</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.054</td>\n",
              "      <td>0.102467</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 English     Wiki Code ISO 369-3  ... precision  recall        f1\n",
              "index                                             ...                            \n",
              "bod              Tibetan            bo       bod  ...       1.0   0.166  0.284734\n",
              "hrv             Croatian            hr       hrv  ...       1.0   0.522  0.685939\n",
              "jpn             Japanese            ja       jpn  ...       1.0   0.114  0.204668\n",
              "khm        Central Khmer            km       khm  ...       1.0   0.432  0.603352\n",
              "lzh     Literary Chinese  zh-classical       lzh  ...       0.0   0.000  0.000000\n",
              "tha                 Thai            th       tha  ...       1.0   0.530  0.692810\n",
              "wuu           Wu Chinese           wuu       wuu  ...       1.0   0.030  0.058252\n",
              "zh-yue         Cantonese        zh-yue       NaN  ...       1.0   0.068  0.127341\n",
              "zho     Standard Chinese            zh       zho  ...       1.0   0.054  0.102467\n",
              "\n",
              "[9 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUkII9aS9iK1",
        "colab_type": "code",
        "outputId": "ac207c1c-4c4b-4b44-973d-b02b18116454",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        }
      },
      "source": [
        "print(x_train[x_train.sc == language_to_class['wuu']])\n",
        "print(x_train[x_train.sc == language_to_class['lzh']])"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                     sent   sc\n",
            "19      UNC有得一只历史悠久个'诚信守则'。渠是由学堂个诚信法庭（Honor Court）来执行个...  227\n",
            "276     武器，是人类为达到杀伤或者防御个目的制造个器械。武器从人类文明发展开始就有出现，之后，伴随战...  227\n",
            "387     弗过，太后个信任是一方面，具体西班牙个政治局面又是另外一番情形：贵族对迭个外国人一点也无信任...  227\n",
            "720     从12世纪挨末阶段开始，日本个统治权就转移到日本武士贵族个手里向。到13世纪，出身清和源氏个...  227\n",
            "930     箇种毛病潜伏期一般勒7日天以内，病人一般表现为流感箇浪个症状，像发寒热，咳嗽，少痰，有种辰光...  227\n",
            "...                                                   ...  ...\n",
            "116805  Linux個低成本、強大個定制功能搭良好個移植性能，使得Linux來嵌入式系統方面也得到廣泛...  227\n",
            "116947  余杭區勒拉杭嘉湖平原南端，西依天目山，南瀕錢塘江，是長江三角洲个圓心地。地理座標爲北緯30°...  227\n",
            "117034  北師大是以京師大學堂師範專業做基礎，搭仔由北京個高校匯聚一批勒師範教育領域窮有聲望個名師組建...  227\n",
            "117037  到清中期（約18世紀），傳奇開始衰微，向書齋文學轉化，彈詞卻逐步興盛起來了。出版之錢德蒼編个...  227\n",
            "117257  摩嘉娜夺权计划失败后，带领奄奄一息个莫高絲逃出卡美洛特，徕萨温节夜里，摩嘉娜徕莫高絲个要求之...  227\n",
            "\n",
            "[500 rows x 2 columns]\n",
            "                                                     sent   sc\n",
            "336     武漢市，亦稱以漢，乃中華鄂省之會，亦為七大都市於中華之中原也。方八千四百六十七公里，於西元二...  123\n",
            "420     按黃帝為法，數有十等。及其用也，乃有三焉。十等者，謂「億、兆、京、垓、秭、壤、溝、澗、正、載...  123\n",
            "1254    范蠡浮海出齊，變姓名，自謂鴟夷子皮，耕於海畔，苦身戮力，父子治產。居無幾何，致產數千萬。齊人...  123\n",
            "1414    周迪據臨川反，詔昭達便道征之。迪敗走，徵為護軍將軍，改封邵武縣侯。四年，陳寶應納迪，共寇臨川...  123\n",
            "1549    喇克達長子敬德，康熙十一年(一六七二年)封三等奉恩將軍，四十七年(一七零八年)卒。敬德次子班...  123\n",
            "...                                                   ...  ...\n",
            "116047  士族者，或曰門第、衣冠、世族、門閥、勢族、世家、巨室。蓋謂世居要位之高門也，世族所居不同，中...  123\n",
            "116419  淳化二年秋七月，李繼遷請降，以爲銀州觀察使，賜姓名趙保吉。繼捧至夏州數月，即言繼遷悔過歸款，...  123\n",
            "116596  孟嘗君怨秦，將以齊為韓、魏攻楚，因與韓、魏攻秦，而借兵食於西周。蘇代為西周謂曰：「君以齊為韓...  123\n",
            "116749  陳敏之亂，弘以侃為江夏太守，加鷹揚將軍。侃備威儀，迎母官舍，鄉裡榮之。敏遣其弟恢來寇武昌，侃...  123\n",
            "117497  同年，太后崩。絳侯周勃、陳平諸臣共謀誅呂。朱虛侯章已殺呂產，文帝使人持節勞章。朱虛侯欲奪節信...  123\n",
            "\n",
            "[500 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dH862g-VYj8J",
        "colab_type": "text"
      },
      "source": [
        "# Fix Chinese langs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yltabFr0UYF_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_features_chinese = 10000\n",
        "\n",
        "## Tokenize the sentences\n",
        "tokenizer_chinese = Tokenizer(num_words=max_features_chinese, char_level=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuUBpVDruwFi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "outputId": "0f30e405-ee50-49ca-b46d-61abf17f155f"
      },
      "source": [
        "x_train_bad = x_train.set_index('lang')\n",
        "bad_quality_langs_train = x_train_bad.loc[bad_quality_metrics.index]\n",
        "bad_quality_langs_train"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sent</th>\n",
              "      <th>sc</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lang</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>bod</th>\n",
              "      <td>༡༩༣༥ལོར་ཞང་པོ་དང་ལྷན་དུ་ནན་ཅིང་དུ་སློབ་སྦྱོང་མ...</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bod</th>\n",
              "      <td>བཀའ་རྩ་གསལ་བསྒྲགས་དངོས་ཤོག་གྲངས་ ༡༢ ལ་བཀོད་ཡོད...</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bod</th>\n",
              "      <td>སྤྱི་ལོ་༡༩༥༣ལོའི་ཟླ་བ་༨པར་སྨན་པས་ཁོང་གི་རྐང་པ་...</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bod</th>\n",
              "      <td>ཐ་མལ་དུ་གནས་པའི་མི་དར་མའི་སྙིང་གི་ཕར་ཚད་ནི་དུས...</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bod</th>\n",
              "      <td>ཀློང་རྡོལ་བླ་མ་རིན་པོ་ཆེའི་བརྟག་ཐབས་ནང་སྤོས་ཤེ...</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zho</th>\n",
              "      <td>赛里木湖属于封闭型的断陷湖，是地壳下沉形成洼地，由四周的高山雪水历百万年慢慢汇聚而成。如今主...</td>\n",
              "      <td>234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zho</th>\n",
              "      <td>约瑟夫·维萨里奥诺维奇·泽·朱加什维利生于俄罗斯帝国哥里，毕业于梯弗里斯神学院。成为马克思主...</td>\n",
              "      <td>234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zho</th>\n",
              "      <td>和印度其他地方一样，板球也是孟买最为流行的一项运动。板球比赛通常在遍布全市的操场上进行。后院...</td>\n",
              "      <td>234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zho</th>\n",
              "      <td>1994年，邓斯特还与薇诺娜·瑞德和克萊兒·丹妮絲一起出演了同名原著改编的电影《小妇人》，该...</td>\n",
              "      <td>234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zho</th>\n",
              "      <td>4月8日首度訪泰，在新聞發布會現場超過200名記者爭相採訪，泰國主要的7頻道及報章雜誌等均大...</td>\n",
              "      <td>234</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4500 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   sent   sc\n",
              "lang                                                        \n",
              "bod   ༡༩༣༥ལོར་ཞང་པོ་དང་ལྷན་དུ་ནན་ཅིང་དུ་སློབ་སྦྱོང་མ...   22\n",
              "bod   བཀའ་རྩ་གསལ་བསྒྲགས་དངོས་ཤོག་གྲངས་ ༡༢ ལ་བཀོད་ཡོད...   22\n",
              "bod   སྤྱི་ལོ་༡༩༥༣ལོའི་ཟླ་བ་༨པར་སྨན་པས་ཁོང་གི་རྐང་པ་...   22\n",
              "bod   ཐ་མལ་དུ་གནས་པའི་མི་དར་མའི་སྙིང་གི་ཕར་ཚད་ནི་དུས...   22\n",
              "bod   ཀློང་རྡོལ་བླ་མ་རིན་པོ་ཆེའི་བརྟག་ཐབས་ནང་སྤོས་ཤེ...   22\n",
              "...                                                 ...  ...\n",
              "zho   赛里木湖属于封闭型的断陷湖，是地壳下沉形成洼地，由四周的高山雪水历百万年慢慢汇聚而成。如今主...  234\n",
              "zho   约瑟夫·维萨里奥诺维奇·泽·朱加什维利生于俄罗斯帝国哥里，毕业于梯弗里斯神学院。成为马克思主...  234\n",
              "zho   和印度其他地方一样，板球也是孟买最为流行的一项运动。板球比赛通常在遍布全市的操场上进行。后院...  234\n",
              "zho   1994年，邓斯特还与薇诺娜·瑞德和克萊兒·丹妮絲一起出演了同名原著改编的电影《小妇人》，该...  234\n",
              "zho   4月8日首度訪泰，在新聞發布會現場超過200名記者爭相採訪，泰國主要的7頻道及報章雜誌等均大...  234\n",
              "\n",
              "[4500 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXhcTGMaYZXt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_X_chinese, train_Y_chinese), (val_X_chinese, val_Y_chinese) = \\\n",
        "prepare_data(bad_quality_langs_train, bad_quality_langs_train.sc, tokenizer_chinese, maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IA91PJA_Nvio",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a26fcd30-9e03-48cf-bdb8-b0ad38ee7a00"
      },
      "source": [
        "chinese_labels_dict = {lang:index for index, lang in enumerate(set(train_Y_chinese))}\n",
        "chinese_labels_dict"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{22: 6, 77: 4, 92: 8, 99: 0, 123: 7, 207: 5, 227: 1, 233: 2, 234: 3}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubiHl-tGxu89",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dummy_y_train_chinese = to_categorical([chinese_labels_dict[lan] for lan in train_Y_chinese])\n",
        "dummy_y_val_chinese = to_categorical([chinese_labels_dict[lan] for lan in val_Y_chinese])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1Px5m0yyLUA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "43380ac7-7c0f-4020-f1b8-f5977af1b759"
      },
      "source": [
        "cnn_model_chinese = Sequential()\n",
        "cnn_model_chinese.add(Embedding(max_features, embed_size,input_shape=(maxlen,)))\n",
        "cnn_model_chinese.add(Conv1D(256, 5, activation='relu', input_shape=(embed_size,)))\n",
        "cnn_model_chinese.add(MaxPooling1D(5))\n",
        "cnn_model_chinese.add(Dropout(0.2))\n",
        "cnn_model_chinese.add(Conv1D(256, 5, activation='relu'))\n",
        "cnn_model_chinese.add(MaxPooling1D(5))\n",
        "cnn_model_chinese.add(Flatten())\n",
        "cnn_model_chinese.add(Dense(512, activation=\"relu\"))\n",
        "cnn_model_chinese.add(Dropout(0.2))\n",
        "cnn_model_chinese.add(Dense(len(dummy_y_train_chinese[0]), activation='softmax'))\n",
        "cnn_model_chinese.summary()"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 200, 300)          19247100  \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 196, 256)          384256    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_4 (MaxPooling1 (None, 39, 256)           0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 39, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 35, 256)           327936    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_5 (MaxPooling1 (None, 7, 256)            0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 1792)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 512)               918016    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 9)                 4617      \n",
            "=================================================================\n",
            "Total params: 20,881,925\n",
            "Trainable params: 20,881,925\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlFTZRq8ya9i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn_model_chinese.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', f1, recall, precision])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QiHi0eYrgaU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "d0dbfbb9-ed23-493b-8018-337b391aa85e"
      },
      "source": [
        "cnn_model_chinese.fit(train_X_chinese, dummy_y_train_chinese, batch_size=128, epochs=10, \n",
        "              validation_data=(val_X_chinese, dummy_y_val_chinese))"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "8/8 [==============================] - 2s 237ms/step - loss: 0.0096 - accuracy: 0.9970 - f1: 0.9973 - recall: 0.9958 - precision: 0.9988 - val_loss: 0.2196 - val_accuracy: 0.9489 - val_f1: 0.9477 - val_recall: 0.9467 - val_precision: 0.9488\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 2s 237ms/step - loss: 0.0070 - accuracy: 0.9985 - f1: 0.9981 - recall: 0.9975 - precision: 0.9988 - val_loss: 0.2061 - val_accuracy: 0.9600 - val_f1: 0.9600 - val_recall: 0.9600 - val_precision: 0.9600\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 2s 239ms/step - loss: 0.0047 - accuracy: 0.9995 - f1: 0.9991 - recall: 0.9985 - precision: 0.9998 - val_loss: 0.2146 - val_accuracy: 0.9556 - val_f1: 0.9544 - val_recall: 0.9533 - val_precision: 0.9555\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 2s 233ms/step - loss: 0.0046 - accuracy: 0.9990 - f1: 0.9988 - recall: 0.9983 - precision: 0.9993 - val_loss: 0.2148 - val_accuracy: 0.9556 - val_f1: 0.9556 - val_recall: 0.9556 - val_precision: 0.9556\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 2s 240ms/step - loss: 0.0031 - accuracy: 1.0000 - f1: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.2138 - val_accuracy: 0.9578 - val_f1: 0.9588 - val_recall: 0.9578 - val_precision: 0.9599\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 2s 244ms/step - loss: 0.0027 - accuracy: 0.9998 - f1: 0.9996 - recall: 0.9995 - precision: 0.9997 - val_loss: 0.2099 - val_accuracy: 0.9600 - val_f1: 0.9611 - val_recall: 0.9600 - val_precision: 0.9621\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 2s 238ms/step - loss: 0.0025 - accuracy: 0.9998 - f1: 0.9998 - recall: 0.9998 - precision: 0.9998 - val_loss: 0.2082 - val_accuracy: 0.9600 - val_f1: 0.9588 - val_recall: 0.9578 - val_precision: 0.9599\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 2s 233ms/step - loss: 0.0034 - accuracy: 0.9990 - f1: 0.9990 - recall: 0.9990 - precision: 0.9990 - val_loss: 0.2101 - val_accuracy: 0.9533 - val_f1: 0.9565 - val_recall: 0.9533 - val_precision: 0.9597\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 2s 235ms/step - loss: 0.0018 - accuracy: 1.0000 - f1: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.2107 - val_accuracy: 0.9600 - val_f1: 0.9611 - val_recall: 0.9600 - val_precision: 0.9621\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 2s 240ms/step - loss: 0.0015 - accuracy: 1.0000 - f1: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.2198 - val_accuracy: 0.9600 - val_f1: 0.9600 - val_recall: 0.9600 - val_precision: 0.9600\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb8e91b6da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWwS0BKMsUGO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "c52f78fc-dfb3-4fab-bc9d-e70ff63a3367"
      },
      "source": [
        "ps_chinese = []\n",
        "rs_chinese = []\n",
        "fs_chinese = []\n",
        "short_len = len(set(train_Y_chinese))\n",
        "\n",
        "for lan in set(train_Y_chinese):\n",
        "    x_t = x_test[x_test['sc'] == lan]\n",
        "    x = convert(x_t, tokenizer_chinese, maxlen)\n",
        "    y = np.zeros((x.shape[0], short_len))\n",
        "    y[:, chinese_labels_dict[lan]] = 1\n",
        "    y = y.astype('float32')\n",
        "    y_pred = cnn_model_chinese.predict(x)\n",
        "    p, r, f = met(y, y_pred)\n",
        "    ps_chinese.append(p.numpy())\n",
        "    rs_chinese.append(r.numpy())\n",
        "    fs_chinese.append(f.numpy())\n",
        "    print(\"language: \", class_to_language[lan], \"precision: \", p.numpy(), \"recall: \", r.numpy(), \"f1: \", f.numpy())"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "language:  khm precision:  1.0 recall:  0.966 f1:  0.98270595\n",
            "language:  wuu precision:  1.0 recall:  0.896 f1:  0.94514763\n",
            "language:  zh-yue precision:  1.0 recall:  0.928 f1:  0.96265554\n",
            "language:  zho precision:  1.0 recall:  0.936 f1:  0.9669421\n",
            "language:  hrv precision:  1.0 recall:  0.992 f1:  0.99598384\n",
            "language:  tha precision:  1.0 recall:  0.988 f1:  0.9939637\n",
            "language:  bod precision:  1.0 recall:  0.998 f1:  0.99899894\n",
            "language:  lzh precision:  1.0 recall:  0.994 f1:  0.996991\n",
            "language:  jpn precision:  1.0 recall:  0.998 f1:  0.99899894\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qimQESgMQpVG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}