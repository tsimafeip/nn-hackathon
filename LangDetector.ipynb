{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of hackaton.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpmSbtrCklRB",
        "colab_type": "code",
        "outputId": "7ec08281-f6ae-4a09-e2a6-2cd506804ffe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNLhWWCxYfLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "import scipy\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import logging\n",
        "import multiprocessing\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8IzA7Rx-VzU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Bidirectional, GlobalMaxPooling1D, GlobalMaxPool1D, MaxPooling1D, Flatten, concatenate\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras import initializers, regularizers, constraints, optimizers, layers\n",
        "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HT5BitjziIeX",
        "colab_type": "text"
      },
      "source": [
        "# Task description and Data loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnrgWUgTrwuU",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1vZGIRYYR9G",
        "colab_type": "text"
      },
      "source": [
        "## Hanna's data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFKrCtLZYBcV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import zipfile\n",
        "# with zipfile.ZipFile('./drive/My Drive/hackaton/wili-2018.zip', 'r') as zip_ref:\n",
        "#     zip_ref.extractall('./')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcwIDfWAYOUl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data_path = '/content/drive/My Drive/Colab Notebooks/Hackathon/'\n",
        "# wili_data_path = ''\n",
        "\n",
        "# x_train_path = wili_data_path + 'x_train.txt'\n",
        "# x_test_path = wili_data_path + 'x_test.txt'\n",
        "# y_train_path = wili_data_path + 'y_train.txt'\n",
        "# y_test_path = wili_data_path + 'y_test.txt'\n",
        "# labels_path = wili_data_path + 'labels.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc94smEhjbA_",
        "colab_type": "text"
      },
      "source": [
        "## Download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75potnAshWU4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path = '/content/drive/My Drive/Colab Notebooks/Hackathon/'\n",
        "wili_data_path = data_path + 'wili-2018/'\n",
        "\n",
        "x_train_path = wili_data_path + 'x_train.txt'\n",
        "x_test_path = wili_data_path + 'x_test.txt'\n",
        "y_train_path = wili_data_path + 'y_train.txt'\n",
        "y_test_path = wili_data_path + 'y_test.txt'\n",
        "labels_path = wili_data_path + 'labels.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhsiujWS3QR8",
        "colab_type": "code",
        "outputId": "0dd8fe7d-a747-42b0-bd1b-1f9d977dfc01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "labels = pd.read_csv(labels_path, sep=';')\n",
        "labels = labels.drop(labels=['German', 'Writing system', 'Remarks', 'Synonyms'], axis=1)\n",
        "labels"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>English</th>\n",
              "      <th>Wiki Code</th>\n",
              "      <th>ISO 369-3</th>\n",
              "      <th>Language family</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ace</td>\n",
              "      <td>Achinese</td>\n",
              "      <td>ace</td>\n",
              "      <td>ace</td>\n",
              "      <td>Austronesian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>afr</td>\n",
              "      <td>Afrikaans</td>\n",
              "      <td>af</td>\n",
              "      <td>afr</td>\n",
              "      <td>Indo-European</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>als</td>\n",
              "      <td>Alemannic German</td>\n",
              "      <td>als</td>\n",
              "      <td>gsw</td>\n",
              "      <td>Indo-European</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>amh</td>\n",
              "      <td>Amharic</td>\n",
              "      <td>am</td>\n",
              "      <td>amh</td>\n",
              "      <td>Afro-Asiatic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ang</td>\n",
              "      <td>Old English</td>\n",
              "      <td>ang</td>\n",
              "      <td>ang</td>\n",
              "      <td>Indo-European</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>230</th>\n",
              "      <td>yid</td>\n",
              "      <td>Yiddish</td>\n",
              "      <td>yi</td>\n",
              "      <td>yid</td>\n",
              "      <td>Indo-European</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>231</th>\n",
              "      <td>yor</td>\n",
              "      <td>Yoruba</td>\n",
              "      <td>yo</td>\n",
              "      <td>yor</td>\n",
              "      <td>Niger-Congo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>232</th>\n",
              "      <td>zea</td>\n",
              "      <td>Zeeuws</td>\n",
              "      <td>zea</td>\n",
              "      <td>zea</td>\n",
              "      <td>Indo-European</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>233</th>\n",
              "      <td>zh-yue</td>\n",
              "      <td>Cantonese</td>\n",
              "      <td>zh-yue</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Sino-Tibetan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>234</th>\n",
              "      <td>zho</td>\n",
              "      <td>Standard Chinese</td>\n",
              "      <td>zh</td>\n",
              "      <td>zho</td>\n",
              "      <td>Sino-Tibetan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>235 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Label           English Wiki Code ISO 369-3 Language family\n",
              "0       ace          Achinese       ace       ace    Austronesian\n",
              "1       afr         Afrikaans        af       afr   Indo-European\n",
              "2       als  Alemannic German       als       gsw   Indo-European\n",
              "3       amh           Amharic        am       amh    Afro-Asiatic\n",
              "4       ang      Old English        ang       ang   Indo-European\n",
              "..      ...               ...       ...       ...             ...\n",
              "230     yid           Yiddish        yi       yid   Indo-European\n",
              "231     yor            Yoruba        yo       yor     Niger-Congo\n",
              "232     zea            Zeeuws       zea       zea   Indo-European\n",
              "233  zh-yue         Cantonese    zh-yue       NaN    Sino-Tibetan\n",
              "234     zho  Standard Chinese        zh       zho    Sino-Tibetan\n",
              "\n",
              "[235 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpH6qYnlYrBN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_to_language = labels.Label.astype(str).to_dict()\n",
        "language_to_class = {v: k for k, v in class_to_language.items()}\n",
        "num_classes = len(class_to_language)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDFr3-rKmDdv",
        "colab_type": "code",
        "outputId": "7c830f42-0d9d-49b5-d3e7-655df8f82ca5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(list(language_to_class.items())[:5])\n",
        "num_classes"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('ace', 0), ('afr', 1), ('als', 2), ('amh', 3), ('ang', 4)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "235"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBqkjck1Yc7q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_data():\n",
        "    with open(x_train_path) as f:\n",
        "        mylist = f.read().splitlines() \n",
        "    x_train = pd.DataFrame(mylist, columns=[\"sent\"])\n",
        "    with open(x_test_path) as f:\n",
        "        mylist = f.read().splitlines() \n",
        "    x_test = pd.DataFrame(mylist, columns=[\"sent\"])\n",
        "\n",
        "    with open(y_train_path) as f:\n",
        "        mylist = f.read().splitlines() \n",
        "    y_train = []\n",
        "    for lan in mylist:\n",
        "        y_train.append(language_to_class[lan])\n",
        "    y_train = pd.DataFrame(y_train)\n",
        "    with open(y_test_path) as f:\n",
        "        mylist = f.read().splitlines()\n",
        "\n",
        "    y_test = []\n",
        "    for lan in mylist:\n",
        "        y_test.append(language_to_class[lan])\n",
        "    y_test = pd.DataFrame(y_test)\n",
        "    \n",
        "    return (x_train, y_train), (x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhKRW6V8hhIc",
        "colab_type": "code",
        "outputId": "06650b19-a1dd-426a-af7b-589a11f11ad2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = read_data()\n",
        "\n",
        "print(x_train.head())\n",
        "print(y_train.head())\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                sent\n",
            "0  Klement Gottwaldi surnukeha palsameeriti ning ...\n",
            "1  Sebes, Joseph; Pereira Thomas (1961) (på eng)....\n",
            "2  भारतीय स्वातन्त्र्य आन्दोलन राष्ट्रीय एवम क्षे...\n",
            "3  Après lo cort periòde d'establiment a Basilèa,...\n",
            "4  ถนนเจริญกรุง (อักษรโรมัน: Thanon Charoen Krung...\n",
            "     0\n",
            "0   52\n",
            "1  198\n",
            "2  124\n",
            "3  155\n",
            "4  207\n",
            "(117500, 1)\n",
            "(117500, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zcUciRigFYu",
        "colab_type": "code",
        "outputId": "d57f6e93-6050-40b2-aca0-49a2fdc57265",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "lens = x_train.sent.str.split(' ').str.len().values\n",
        "plt.hist(lens, bins=np.linspace(0,300,20), facecolor='blue', alpha=0.9)\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EupQnkZhikN4",
        "colab_type": "text"
      },
      "source": [
        "# Analysis of possible solutions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4wAGBRDjMRd",
        "colab_type": "text"
      },
      "source": [
        "## Unicode-based"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zd9LZnR3jQS1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNoYz_IwjeY_",
        "colab_type": "text"
      },
      "source": [
        "## Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEr8pklSjQLP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filter_out = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n1234567890'\n",
        "tokenizer = Tokenizer(filters=filter_out, lower=True)\n",
        "tokenizer.fit_on_texts(x_train.sent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xKQt34TAG2-",
        "colab_type": "code",
        "outputId": "0241c2eb-cd20-49f3-8434-a6c297fad011",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# try different values of `count`\n",
        "# show how many words are presenting more than `count` times\n",
        "count = 10\n",
        "frequent_words = [w for w,c in tokenizer.word_counts.items() if c > count]\n",
        "len(frequent_words)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64157"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwDeU_wRph8C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_data(train_x, train_y, tokenizator, max_len_of_vector):\n",
        "    x_tr, x_val, y_tr, y_val = train_test_split(train_x, train_y, test_size=0.1, random_state=1, stratify=train_y.values)\n",
        "   \n",
        "    tokenizator.fit_on_texts(x_tr.sent)\n",
        "\n",
        "    train_X = tokenizator.texts_to_sequences(x_tr.sent)\n",
        "    val_X = tokenizator.texts_to_sequences(x_val.sent)\n",
        "\n",
        "    ## Pad the sentences \n",
        "    train_X = pad_sequences(train_X, maxlen=max_len_of_vector)\n",
        "    val_X = pad_sequences(val_X, maxlen=max_len_of_vector)\n",
        "\n",
        "    return (train_X, y_tr), (val_X, y_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJacuBHhHEng",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embed_size = 300 # how big is each word vector\n",
        "max_features = len(frequent_words) # how many unique words to use (i.e num rows in embedding vector)\n",
        "maxlen = 200 # max number of words in a question to use\n",
        "\n",
        "## Tokenize the sentences\n",
        "tokenizer = Tokenizer(num_words=max_features, filters=filter_out, lower=True)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qW1oK9wfHEnm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_X, train_Y), (val_X, val_Y) = prepare_data(x_train, y_train, tokenizer, maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0iIyf4bIXg_",
        "colab_type": "code",
        "outputId": "e4bd3d4e-e7f8-4940-f0bb-674d33b885ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "lb = LabelEncoder()\n",
        "y = lb.fit_transform(train_Y.values.ravel())\n",
        "dummy_y_train = to_categorical(y)\n",
        "\n",
        "print(len(dummy_y_train))\n",
        "print(len(dummy_y_train[0]))\n",
        "\n",
        "y = lb.fit_transform(val_Y.values.ravel())\n",
        "dummy_y_val = to_categorical(y)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "105750\n",
            "235\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvlMElfzjWui",
        "colab_type": "text"
      },
      "source": [
        "# Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeXXgZJ6miyl",
        "colab_type": "text"
      },
      "source": [
        "## Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixDKC4gekXRu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def combined_metric(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)), axis=0)\n",
        "    false_positives = K.sum(K.round(K.clip((1 - y_true) * y_pred, 0, 1)), axis=0)\n",
        "    true_negatives = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)), axis=0)\n",
        "    false_negatives = K.sum(K.round(K.clip(y_true * (1 - y_pred), 0, 1)), axis=0)\n",
        "    precision = max(true_positives / (true_positives + false_positives  + K.epsilon()))\n",
        "    recall = max(true_positives / (true_positives + false_negatives  + K.epsilon()))\n",
        "    f1 = 2 * precision * recall / (precision + recall + K.epsilon())\n",
        "    return precision, recall, f1\n",
        "\n",
        "def recall(y_true, y_pred):\n",
        "    _, recall, _ = combined_metric(y_true, y_pred)\n",
        "    return recall\n",
        "\n",
        "def precision(y_true, y_pred):\n",
        "    precision, _, _ = combined_metric(y_true, y_pred)\n",
        "    return precision\n",
        "\n",
        "def f1(y_true, y_pred):\n",
        "    _, _, f1 = combined_metric(y_true, y_pred)\n",
        "    return f1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZN3VQiPnwAW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def combined_metric_train(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1 = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return precision, recall, f1\n",
        "\n",
        "def recall_train(y_true, y_pred):\n",
        "    _, recall, _ = combined_metric_train(y_true, y_pred)\n",
        "    return recall\n",
        "\n",
        "def precision_train(y_true, y_pred):\n",
        "    precision, _, _ = combined_metric_train(y_true, y_pred)\n",
        "    return precision\n",
        "\n",
        "def f1_train(y_true, y_pred):\n",
        "    _, _, f1 = combined_metric_train(y_true, y_pred)\n",
        "    return f1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJGHC_CGq8ia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_metrics = [tf.metrics.categorical_accuracy, precision_train, recall_train, f1_train]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtGH8P89gTXf",
        "colab_type": "text"
      },
      "source": [
        "## CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdsE9d9SjdsW",
        "colab_type": "code",
        "outputId": "52e27827-4ec4-4948-9436-0654fe800e76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        }
      },
      "source": [
        "cnn_model = Sequential()\n",
        "cnn_model.add(Embedding(max_features, embed_size, input_shape=(maxlen,)))\n",
        "cnn_model.add(Conv1D(256, 5, activation='relu', input_shape=(embed_size,)))\n",
        "cnn_model.add(MaxPooling1D(5))\n",
        "cnn_model.add(Dropout(0.2))\n",
        "cnn_model.add(Conv1D(256, 5, activation='relu'))\n",
        "cnn_model.add(MaxPooling1D(5))\n",
        "cnn_model.add(Flatten())\n",
        "cnn_model.add(Dense(512, activation=\"relu\"))\n",
        "cnn_model.add(Dropout(0.2))\n",
        "cnn_model.add(Dense(num_classes, activation='softmax'))\n",
        "cnn_model.summary()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 200, 300)          19247100  \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 196, 256)          384256    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 39, 256)           0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 39, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 35, 256)           327936    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, 7, 256)            0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1792)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               918016    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 235)               120555    \n",
            "=================================================================\n",
            "Total params: 20,997,863\n",
            "Trainable params: 20,997,863\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sndko3XlZ806",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=train_metrics)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aa9rf4_Oq6nX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn_cp_path = data_path+'model_cnn.hdf5'\n",
        "cnn_cp=ModelCheckpoint(cnn_cp_path, monitor='val_loss',save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIhz76oFHo_c",
        "colab_type": "code",
        "outputId": "bd6e07d7-b87c-4f1f-aaf1-4a92f5c841a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "cnn_model.fit(train_X, dummy_y_train, batch_size=512, epochs=5, \n",
        "              validation_data=(val_X, dummy_y_val),\n",
        "              callbacks = [cnn_cp])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "207/207 [==============================] - 60s 291ms/step - loss: 3.0122 - categorical_accuracy: 0.3563 - precision_train: 0.6566 - recall_train: 0.2696 - f1_train: 0.3346 - val_loss: 0.6418 - val_categorical_accuracy: 0.8580 - val_precision_train: 0.9593 - val_recall_train: 0.7942 - val_f1_train: 0.8689\n",
            "Epoch 2/5\n",
            "207/207 [==============================] - 59s 283ms/step - loss: 0.4511 - categorical_accuracy: 0.8894 - precision_train: 0.9601 - recall_train: 0.8551 - f1_train: 0.9044 - val_loss: 0.4626 - val_categorical_accuracy: 0.8954 - val_precision_train: 0.9672 - val_recall_train: 0.8672 - val_f1_train: 0.9144\n",
            "Epoch 3/5\n",
            "207/207 [==============================] - 57s 277ms/step - loss: 0.2254 - categorical_accuracy: 0.9374 - precision_train: 0.9806 - recall_train: 0.9215 - f1_train: 0.9501 - val_loss: 0.4983 - val_categorical_accuracy: 0.8920 - val_precision_train: 0.9540 - val_recall_train: 0.8755 - val_f1_train: 0.9130\n",
            "Epoch 4/5\n",
            "207/207 [==============================] - 57s 274ms/step - loss: 0.1669 - categorical_accuracy: 0.9514 - precision_train: 0.9856 - recall_train: 0.9401 - f1_train: 0.9623 - val_loss: 0.5715 - val_categorical_accuracy: 0.8923 - val_precision_train: 0.9452 - val_recall_train: 0.8787 - val_f1_train: 0.9107\n",
            "Epoch 5/5\n",
            "207/207 [==============================] - 56s 272ms/step - loss: 0.1444 - categorical_accuracy: 0.9571 - precision_train: 0.9874 - recall_train: 0.9481 - f1_train: 0.9674 - val_loss: 0.6170 - val_categorical_accuracy: 0.8892 - val_precision_train: 0.9393 - val_recall_train: 0.8776 - val_f1_train: 0.9074\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f34fd3a7320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkmpFZmyUjF8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dependencies = {\n",
        "     'f1': f1_train,\n",
        "     'recall': recall_train,\n",
        "     'precision': precision_train\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qji8xqW2WiS-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cnn_model = load_model(cnn_cp_path, custom_objects=dependencies)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-T-4MO1ZR_S",
        "colab_type": "text"
      },
      "source": [
        "## RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ch0GFZ-ZSzb",
        "colab_type": "code",
        "outputId": "ade9f1d4-edb1-45cd-dc09-ada73f445eb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "rnn_model = Sequential()\n",
        "rnn_model.add(Embedding(max_features, embed_size))\n",
        "rnn_model.add(Bidirectional(LSTM(128, return_sequences=True, activation='tanh',input_dim=embed_size)))\n",
        "rnn_model.add(Dropout(0.2))\n",
        "rnn_model.add(Bidirectional(LSTM(128, return_sequences=True, activation='tanh')))\n",
        "rnn_model.add(GlobalMaxPool1D())\n",
        "rnn_model.add(Dropout(0.2))\n",
        "rnn_model.add(Dense(512, activation=\"relu\"))\n",
        "rnn_model.add(Dropout(0.2))\n",
        "rnn_model.add(Dense(num_classes, activation='softmax'))\n",
        "rnn_model.summary()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, None, 300)         19247100  \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, None, 256)         439296    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, None, 256)         0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, None, 256)         394240    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 235)               120555    \n",
            "=================================================================\n",
            "Total params: 20,332,775\n",
            "Trainable params: 20,332,775\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1W3XFHXZiVR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=train_metrics)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPtLB7kUrGgE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rnn_cp_path = data_path + 'model_rnn.hdf5'\n",
        "rnn_cp=ModelCheckpoint(rnn_cp_path, monitor='val_loss', save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qK-tgijZk7L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# rnn_model.fit(train_X, dummy_y_train, batch_size=512, epochs=3, \n",
        "#               validation_data=(val_X, dummy_y_val), callbacks = [rnn_cp])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kk3g4PLUumt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rnn_model = load_model(rnn_cp_path, custom_objects=dependencies)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OwT-3obvsIo",
        "colab_type": "text"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wowtwiinqwm0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert(x, tokenizator, max_vector_len):\n",
        "    train_X = tokenizator.texts_to_sequences(x.sent)\n",
        "    train_X = pad_sequences(train_X, maxlen=max_vector_len)\n",
        "    return train_X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jS0Tq-Cqb4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test['sc'] = y_test\n",
        "x_test['lang'] = [class_to_language[y] for y in list(y_test.iloc[:,0])]\n",
        "x_train['sc'] = y_train\n",
        "x_train['lang'] = [class_to_language[y] for y in list(y_train.iloc[:,0])]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P006Z5Sgzeal",
        "colab_type": "code",
        "outputId": "b4fa8136-b1c0-4e42-a0f5-8378e9516de2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ps = []\n",
        "rs = []\n",
        "fs = []\n",
        "for lan in tqdm(range(num_classes)):\n",
        "    x_t = x_test[x_test['sc'] == lan]\n",
        "    x = convert(x_t, tokenizer, maxlen)\n",
        "    y = np.zeros((x.shape[0], num_classes))\n",
        "    y[:, lan] = 1\n",
        "    y = y.astype('float32')\n",
        "    y_pred = cnn_model.predict(x)\n",
        "    p, r, f = combined_metric(y, y_pred)\n",
        "    ps.append(p.numpy())\n",
        "    rs.append(r.numpy())\n",
        "    fs.append(f.numpy())\n",
        "    #print(\"language: \", class_to_language[lan], \"precision: \", p.numpy(), \"recall: \", r.numpy(), \"f1: \", f.numpy())"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 235/235 [00:57<00:00,  4.09it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jFoYvQVzg0C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_metrics = pd.DataFrame(\n",
        "    {'precision': ps,\n",
        "     'recall': rs,\n",
        "     'f1': fs\n",
        "    })"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXV6tZ4Dzh4L",
        "colab_type": "code",
        "outputId": "3c64e175-29f7-4b9c-d375-3ee5d64c5b77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "metrics = raw_metrics.rename(class_to_language, axis='index')\n",
        "bad_quality_metrics = metrics[metrics.recall < 0.5]\n",
        "bad_quality_metrics"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>bod</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.160</td>\n",
              "      <td>0.275862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hbs</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.480</td>\n",
              "      <td>0.648649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>jpn</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.120</td>\n",
              "      <td>0.214286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>khm</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.418</td>\n",
              "      <td>0.589563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lzh</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>wuu</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.030</td>\n",
              "      <td>0.058252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zh-yue</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.070</td>\n",
              "      <td>0.130841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zho</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.048</td>\n",
              "      <td>0.091603</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        precision  recall        f1\n",
              "bod           1.0   0.160  0.275862\n",
              "hbs           1.0   0.480  0.648649\n",
              "jpn           1.0   0.120  0.214286\n",
              "khm           1.0   0.418  0.589563\n",
              "lzh           0.0   0.000  0.000000\n",
              "wuu           1.0   0.030  0.058252\n",
              "zh-yue        1.0   0.070  0.130841\n",
              "zho           1.0   0.048  0.091603"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaImgEefHae0",
        "colab_type": "code",
        "outputId": "b8b45624-1913-4266-d2bd-23818694d2db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        }
      },
      "source": [
        "lab = labels.set_index('Label')\n",
        "bad_quality_labels = lab.loc[lab.index.intersection(bad_quality_metrics.index)]\n",
        "res = pd.merge(bad_quality_labels.reset_index(), bad_quality_metrics.reset_index()).set_index('index')\n",
        "res"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Wiki Code</th>\n",
              "      <th>ISO 369-3</th>\n",
              "      <th>Language family</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>bod</th>\n",
              "      <td>Tibetan</td>\n",
              "      <td>bo</td>\n",
              "      <td>bod</td>\n",
              "      <td>Sino-Tibetan</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.160</td>\n",
              "      <td>0.275862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hbs</th>\n",
              "      <td>Serbo-Croatian</td>\n",
              "      <td>sh</td>\n",
              "      <td>hbs</td>\n",
              "      <td>Indo-European</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.480</td>\n",
              "      <td>0.648649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>jpn</th>\n",
              "      <td>Japanese</td>\n",
              "      <td>ja</td>\n",
              "      <td>jpn</td>\n",
              "      <td>Japonic</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.120</td>\n",
              "      <td>0.214286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>khm</th>\n",
              "      <td>Central Khmer</td>\n",
              "      <td>km</td>\n",
              "      <td>khm</td>\n",
              "      <td>Austronesian</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.418</td>\n",
              "      <td>0.589563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lzh</th>\n",
              "      <td>Literary Chinese</td>\n",
              "      <td>zh-classical</td>\n",
              "      <td>lzh</td>\n",
              "      <td>Sino-Tibetan</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>wuu</th>\n",
              "      <td>Wu Chinese</td>\n",
              "      <td>wuu</td>\n",
              "      <td>wuu</td>\n",
              "      <td>Sino-Tibetan</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.030</td>\n",
              "      <td>0.058252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zh-yue</th>\n",
              "      <td>Cantonese</td>\n",
              "      <td>zh-yue</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Sino-Tibetan</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.070</td>\n",
              "      <td>0.130841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zho</th>\n",
              "      <td>Standard Chinese</td>\n",
              "      <td>zh</td>\n",
              "      <td>zho</td>\n",
              "      <td>Sino-Tibetan</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.048</td>\n",
              "      <td>0.091603</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 English     Wiki Code ISO 369-3  ... precision  recall        f1\n",
              "index                                             ...                            \n",
              "bod              Tibetan            bo       bod  ...       1.0   0.160  0.275862\n",
              "hbs       Serbo-Croatian            sh       hbs  ...       1.0   0.480  0.648649\n",
              "jpn             Japanese            ja       jpn  ...       1.0   0.120  0.214286\n",
              "khm        Central Khmer            km       khm  ...       1.0   0.418  0.589563\n",
              "lzh     Literary Chinese  zh-classical       lzh  ...       0.0   0.000  0.000000\n",
              "wuu           Wu Chinese           wuu       wuu  ...       1.0   0.030  0.058252\n",
              "zh-yue         Cantonese        zh-yue       NaN  ...       1.0   0.070  0.130841\n",
              "zho     Standard Chinese            zh       zho  ...       1.0   0.048  0.091603\n",
              "\n",
              "[8 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUkII9aS9iK1",
        "colab_type": "code",
        "outputId": "9f660b5e-1975-4420-d9d4-a113f6a6abfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        }
      },
      "source": [
        "for bad_metric_label in list(bad_quality_metrics.index):\n",
        "  print(f\"{bad_metric_label}: {x_train[x_train.sc == language_to_class[bad_metric_label]].iloc[0].sent}\")"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bod: ༡༩༣༥ལོར་ཞང་པོ་དང་ལྷན་དུ་ནན་ཅིང་དུ་སློབ་སྦྱོང་མནང་བར་ཕེབས་རྩིས་བྱས། ཕྱི་ལོར་ཀྲུང་དབྱང་ཆབ་སྲིད་སློབ་གྲྭས་བཙུགས་པའི་མོང་བོད་སློབ་གྲྭར་སློབ་སྦྱོང་མནང་བ་དང་དེ་དུས་ཅང་ཅེ་ཧྲེ་སློབ་གྲྭའི་ཞའོ་ཀྲང་གི་འགན་བཞེས་ཀྱི་ཡོད། ༡༩༣༧ལོར་རི་འགོག་དམག་འཁྲུག་ལངས་རྐྱེན་སློབ་གྲྭ་དེ་ཨན་ཧུའི་ཅུའུ་ཧ་རི་བོ་ནས་ཧུའུ་ནན་ཀྲེ་ཅང་དུ་སྤོ་དགོས་བྱུང་། དེའི་རིང་ལ་ཁོང་གི《འུ་ཧན་ལ་བསྐྱོད་ལམ》ཞེས་པའི་རྩོམ་ཡིག《ཀྲེ་ཅང་ཉིན་རེའི་ཚགས་པར》སྟེང་འགོད་མནང་བ་རེད། དེ་དུས་ཁོང་དང་གཡོན་ཕྱོགས་ཀྱི་དུས་དེབ། དེ་བཞིན་མི་སྣར་ཐོག་མའི་རྒྱུས་ལོན་བྱུང་། ༡༩༣༨ལོར་སློབ་གྲྭ་དེ་ཁྲུང་ཆིང་དུ་སྤོས། དེ་ནས་ཟུང་ཁོང་གིས་མ་ཁེ་སི་དང་ལི་ཉིང་གི་བརྩམས་ཆོས་མང་དུ་བཀླགས་རྐྱེན་ཁོང་གི་ལྟ་བ་ལི་ཉིང་གི《མི་རིགས་རང་གཙོ་དབང་ཆའི་སྐོར་གླེང་བ》ཞེས་པ་དང་ཉེ་བར་གྱུར། དེའི་ཕྱི་ལོར་ཕུན་དབང་གིས་དཀོན་མཆོག་བཀྲ་ཤིས། ངག་དབང་སྐལ་བཟང་། ཤེས་རབ། མ་རྒྱལ་དོན་གྲུབ་ལ་སོགས་པའི་སློབ་ཕྲུག་དང་མཉམ་དུ༼བོད་རིགས་གུང་ཁྲན་རིང་ལུགས་གསར་བརྗེའི་འགུལ་བསྐྱོད་ཚོགས་ཆུང༽བཙུགས་མནང་བ་དང་། ཧྲུའུ་ཅིའི་འགན་བཞེས། དེ་ནས་ཁྲུང་ཆིང་བཅའ་སྡོད་དམག་སྡེ་བརྒྱད་པའི་དོན་གཅོད་ཁང་དང་གསང་བའི་ཐོག་ནས་འབྲེལ་གཏུག་མནང་། ད་དུང་ཚོགས་ཆུང་དེའི་མིང་ཐོག་ནས་སི་ཏའ་ལིན་དང་མའོ་ཙི་ཏུང་ལ་འཕྲིན་ཡིག་བསྐུར་མནང་མཛད། ཕུན་ཚོགས་དབང་རྒྱལ་གྱིས《རྒྱལ་སྤྱིའི་གླུ》《ཀྲུང་གོའི་རྒྱལ་གླུ》སོགས་བོད་ཡིག་ཏུ་ཐོག་མར་བསྒྱུར། ༡༩༤༠ལོར་སློབ་གྲྭ་ནས་ཕྱིར་འབུད་བྱས། དེ་ནས་ཡེ་ཅན་ཡིང་གི་རོག་སྐྱོར་འོག་མ་ཁེ་སི་དང་ལེ་ཉིང་གི་བརྩམས་ཆོས་མང་དག་ཅིག་ཉོས་ནས་བོད་དུ་ལོག་ཕེབས། ༡༩༤༢ལོར་ཁོར་གིས་དར་རྩེ་མདོ་རུ༼སྐར་མ་མེའི་ཚོགས་པ༽བཙུགས་མནང་བ་དང་། དེའི་ཁོངས་མི་ལ་ངག་དབང་དང་། ཏའོ་ཏང་། དགྲ་འདུལ། ཚང་ཆོས་གྲགས་སོགས་བྱུང་། དེ་ནས་ཚོགས་པ་དེ་གོ་མིན་ཏང་གི་ཤེས་རྟོགས་བྱུང་རྗེས་ཕུན་དབང་དང་ཏའོ་ཏང་ལྷ་སར་ཕེབས་ནས༼གངས་ལྗོངས་བོད་རིགས་གུང་ཁྲན་རིང་ལུགས་གསར་བརྗེའི་ཚོགས་ཆུང༽བཙུགས། ཁོང་ཚོས་བསོད་ཁང·དབང་ཆེན་དགེ་ལེགས་བཀའ་བློན་བརྒྱུད་ནས་བཀའ་ཤག་སྲིད་གཞུང་ལ་གསར་བརྗེའི་ལས་འགུལ་སྤེལ་དགོས་པའི་རེ་བ་ཞུས་ཀྱང་སྟོང་ཟད་དུ་ཕྱིན། ༡༩༤༤ལོར་རྒྱ་གར་དུ་ཕེབས། ༡༩༤༥ལོར་ཕུན་དབང་ཡུན་ནན་བདེ་ཆེན་རྫོང་དུ་ཕེབས་ནས༼ཤར་བོད་མི་དམངས་རང་སྐྱོངས་ལྷན་ཚོགས༽གསར་བཙུགས་མཛད་པས་སྲིད་གཞུང་གིས་འཛིན་བཟུང་བཀའ་རྒྱ་བཏང་། ༡༩༧༤ལོར་ཕུན་དབང་ཆབ་མདོ་ཁུལ་དུ་ཕེབས་ནས་གཡུ་ཐོག·བཀྲ་ཤིས་དོན་གྲུབ་ཀྱིས་རོག་སྐྱོར་འོག་ལྷ་སར་ཕེབས་ཐུབ་པ་བྱུང་། ༡༩༤༩ལོར་ཕུན་དབང་སོགས་ཀྲུང་གོ་གུང་ཁྲན་ཏང་གི་གསང་བའི་ལས་དོན་སྒྲུབ་མཁན་དང་འབྲེལ་བ་ཡོད་པ་ཤེས་རྟོགས་བྱུང་ནས་བཀའ་ཤག་སྲིད་གཞུང་གིས་བོད་ནས་ཕྱིར་འབུད་བྱས། ལོ་དེའི་སྤྱི་ཟླ་༩པར་ཁོང་རྣམས་རྒྱ་གར་བརྒྱུད་ནས་ཁུན་མིང་དུ་ཕེབས། ཁོང་གིས་ས་དེ་གའི་ཀྲུང་གོ་གུང་ཁྲན་ཏང་རྩ་འཛུགས་དང་འབྲེལ་བ་བྱས་མཐར་གུང་ཁྲན་ཏང་ཡོན་ཞིག་ཏུ་གྱུར། དེ་རྗེས་འབའ་ཐང་ལ་ལོག་ཕེབས་ནས༼ཀྲུང་གོ་གུང་ཁྲན་ཏང་ཁམས་བོད་ས་མཚམས་ལས་དོན་ཨུ་ཡོན་ལྷན་ཁང༽༼ཤར་བོད་དམངས་གཙོའི་ན་གཞོན་ལྷན་ཚོགས༽གསར་འཛུགས་མཛད་པ་དང་ཧྲུའུ་ཅིའི་འགན་བཞེས།\n",
            "hbs: U dolini se nalazi glavni i najveći grad Uzbekistana Taškent. Ostali veći gradovi Uzbekistana su Andižan, Fergana i Namangan, u Tadžikistanu je grad Khudžand, a u Kirgistanu Oš.\n",
            "jpn: エノが行きがかりでバスに乗ってしまい、気分が悪くなった際に助けるが、今すぐバスを降りたいと運転手に頼む際、本当のことを言ってしまうと彼女が恥ずかしい思いをすると察して「僕ウンコしたいんです!!」と言ってバスを降りた。エノは内心「私もしたいみたいじゃないの」と思うも、別れ際にエノの髪を「ふわふわのお菓子みたい」と言い、この台詞に憧れていたエノに強い衝撃を与えた。この話を聞いたリコは、以後彼のことを『ウンコ王子』または『ウンコ』というあだ名で呼ぶようになったが、エノは普通に「戸田くん」と呼んでいる。\n",
            "khm: ស្គរអារក្សជាឧបករណ៍ភ្លេងទះ តប់ដោយបាតដៃ។ ស្គរនេះមានឈ្មោះច្រើនគឺ ស្គរដៃ ស្គរអារក្ស ស្គរការ ស្គរដី ស្គរអាយ៉ៃ។ គេយកវាទៅប្រគំក្នុងវង់ភ្លេងអារក្ស វង់ភ្លេងការ វង់ភ្លេងអាយ៉ៃ និងវង់ភ្លេងកំដរពេលរាំលេងកំសាន្ត។\n",
            "lzh: 武漢市，亦稱以漢，乃中華鄂省之會，亦為七大都市於中華之中原也。方八千四百六十七公里，於西元二〇一〇年計口九百七十八萬有奇。大江與漢水會此，分之三鎮，是為武昌、漢陽、漢口也。傳唐人李白至此，題詩曰：「黃鶴樓中吹玉笛，江城五月落梅花」，故亦稱之「江城」。武漢達於晚清，至民國，譽為「東方芝加哥」。經民國至共和國之初而盛。中華民國亦起此也。\n",
            "wuu: UNC有得一只历史悠久个'诚信守则'。渠是由学堂个诚信法庭（Honor Court）来执行个，通过处理各种有关学生个学习帮行为浪个违规，保证了学校帮社区个权益。教授勿能因为学生仔被捉着作弊而通过任何方式处罚学生（譬如讲让迭个学生勿及格），渠必须上报畀学生总检察长。只有当由学生组成个诚信法庭裁决有罪以后，格学生再可以被惩罚。\n",
            "zh-yue: 1998年11月，一位中年女人自創燒炭自殺，將自己同燒烤爐封響沖涼房裏面。由於呢種方法之前，未有先例，相信係女死者以佢化工背景自創。因為咁，呢種自殺方法引起好多報紙大幅報導，令到好多模仿以呢種方式自殺。更適逢1997年後香港經濟低潮，有唔少人失業兼負債纍纍，以呢種方式自尋短見。結果短短兩個月就成為香港第三多人用嘅自殺方法，排響跳樓同吊頸之後。到咗第2001年，呢個方法多人用到變咗第二位。由於各傳媒咁樣繪形繪聲報導，大陸、台灣、日本都有唔少人仿效。\n",
            "zho: 胡赛尼本人和小说的主人公阿米尔一样，都是出生在阿富汗首都喀布尔，少年时代便离开了这个国家。胡赛尼直到2003年小说出版之后才首次回到已经离开27年的祖国。他在苏联入侵时离开了阿富汗，而他的很多童年好友在阿富汗生活艰难，还有一些表亲离开人世，其中一位在童年时代和他一起放风筝的表兄弟就是在逃离阿富汗时死在了油罐车中（这一情节在《追风筝的人》中也有描写），而这位表兄弟的父亲也被人枪杀；因此胡赛尼总是怀有幸存者所特有的一种内疚心态，这种情感在小说中也有体现。很多人因此认为这部小说有些自传色彩。胡赛尼则表示小说中确实有一部分内容是根据自己的经历创作的，他和故事主人公也有很多相似点，但是一些内容被他刻意地模糊处理了。尽管和主人公的经历有诸多的相似点，胡赛尼仍然坚称小说情节确实是虚构的。之后胡赛尼在创作他的第二部小说《灿烂千阳》时把主人公设定为女性，称“这样应该就能一劳永逸地解决人们关于‘自传’的问题了”。\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_V7G2Rmasiwh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample = pd.DataFrame(\n",
        "    {'sent': ['武漢市，亦稱以漢，乃中華鄂省之會，亦為七大都市於中華之中原也。方八千四百六十七公里',\n",
        "              'Produkcja aparatów fotograficznych w kijowskich zakładach Arsenal rozpoczęła się od przeniesienia w 1946 r. z Drezna całej, ledwie uruchomionej po zniszczeniach wojennych linii produkcyjnej aparatów małoobrazkowych Contax, wraz z zatrudnionymi przy niej fachowcami. ',\n",
        "              'З 1944 года дзейнічае Дзяржаўны літаратурны музей Янкі Купалы. У гонар паэта ў 1957 годзе была заснавана Літаратурная прэмія імя Янкі Купалы. З 1995 года сістэматычна праводзяцца штогадовыя Купалаўскія чытанні — прафесійны форум для абмеркавання навуковых дасягненняў і праблем купалазнаўства.'\n",
        "              ],\n",
        "    })"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYWzOhgRr9kP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "b9c9f052-55be-4444-8bda-4826f4ce5c56"
      },
      "source": [
        "x_converted = convert(sample, tokenizer, maxlen)\n",
        "y_predicted = cnn_model.predict(x_converted)\n",
        "y_predicted = y_predicted.argmax(axis=1)\n",
        "\n",
        "for y_pred in y_predicted:\n",
        "  print(class_to_language[y_pred])"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bod\n",
            "pol\n",
            "bel\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dH862g-VYj8J",
        "colab_type": "text"
      },
      "source": [
        "# Fix Chinese langs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yltabFr0UYF_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_features_chinese = 10000\n",
        "\n",
        "## Tokenize the sentences\n",
        "tokenizer_chinese = Tokenizer(num_words=max_features_chinese, char_level=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuUBpVDruwFi",
        "colab_type": "code",
        "outputId": "fb3a3f38-9e77-4220-a008-cbf2724e5ef0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        }
      },
      "source": [
        "x_train_bad = x_train.set_index('lang')\n",
        "bad_quality_langs_train = x_train_bad.loc[bad_quality_metrics.index]\n",
        "bad_quality_langs_train"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sent</th>\n",
              "      <th>sc</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lang</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>bod</th>\n",
              "      <td>༡༩༣༥ལོར་ཞང་པོ་དང་ལྷན་དུ་ནན་ཅིང་དུ་སློབ་སྦྱོང་མ...</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bod</th>\n",
              "      <td>བཀའ་རྩ་གསལ་བསྒྲགས་དངོས་ཤོག་གྲངས་ ༡༢ ལ་བཀོད་ཡོད...</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bod</th>\n",
              "      <td>སྤྱི་ལོ་༡༩༥༣ལོའི་ཟླ་བ་༨པར་སྨན་པས་ཁོང་གི་རྐང་པ་...</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bod</th>\n",
              "      <td>ཐ་མལ་དུ་གནས་པའི་མི་དར་མའི་སྙིང་གི་ཕར་ཚད་ནི་དུས...</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bod</th>\n",
              "      <td>ཀློང་རྡོལ་བླ་མ་རིན་པོ་ཆེའི་བརྟག་ཐབས་ནང་སྤོས་ཤེ...</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zho</th>\n",
              "      <td>赛里木湖属于封闭型的断陷湖，是地壳下沉形成洼地，由四周的高山雪水历百万年慢慢汇聚而成。如今主...</td>\n",
              "      <td>234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zho</th>\n",
              "      <td>约瑟夫·维萨里奥诺维奇·泽·朱加什维利生于俄罗斯帝国哥里，毕业于梯弗里斯神学院。成为马克思主...</td>\n",
              "      <td>234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zho</th>\n",
              "      <td>和印度其他地方一样，板球也是孟买最为流行的一项运动。板球比赛通常在遍布全市的操场上进行。后院...</td>\n",
              "      <td>234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zho</th>\n",
              "      <td>1994年，邓斯特还与薇诺娜·瑞德和克萊兒·丹妮絲一起出演了同名原著改编的电影《小妇人》，该...</td>\n",
              "      <td>234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zho</th>\n",
              "      <td>4月8日首度訪泰，在新聞發布會現場超過200名記者爭相採訪，泰國主要的7頻道及報章雜誌等均大...</td>\n",
              "      <td>234</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   sent   sc\n",
              "lang                                                        \n",
              "bod   ༡༩༣༥ལོར་ཞང་པོ་དང་ལྷན་དུ་ནན་ཅིང་དུ་སློབ་སྦྱོང་མ...   22\n",
              "bod   བཀའ་རྩ་གསལ་བསྒྲགས་དངོས་ཤོག་གྲངས་ ༡༢ ལ་བཀོད་ཡོད...   22\n",
              "bod   སྤྱི་ལོ་༡༩༥༣ལོའི་ཟླ་བ་༨པར་སྨན་པས་ཁོང་གི་རྐང་པ་...   22\n",
              "bod   ཐ་མལ་དུ་གནས་པའི་མི་དར་མའི་སྙིང་གི་ཕར་ཚད་ནི་དུས...   22\n",
              "bod   ཀློང་རྡོལ་བླ་མ་རིན་པོ་ཆེའི་བརྟག་ཐབས་ནང་སྤོས་ཤེ...   22\n",
              "...                                                 ...  ...\n",
              "zho   赛里木湖属于封闭型的断陷湖，是地壳下沉形成洼地，由四周的高山雪水历百万年慢慢汇聚而成。如今主...  234\n",
              "zho   约瑟夫·维萨里奥诺维奇·泽·朱加什维利生于俄罗斯帝国哥里，毕业于梯弗里斯神学院。成为马克思主...  234\n",
              "zho   和印度其他地方一样，板球也是孟买最为流行的一项运动。板球比赛通常在遍布全市的操场上进行。后院...  234\n",
              "zho   1994年，邓斯特还与薇诺娜·瑞德和克萊兒·丹妮絲一起出演了同名原著改编的电影《小妇人》，该...  234\n",
              "zho   4月8日首度訪泰，在新聞發布會現場超過200名記者爭相採訪，泰國主要的7頻道及報章雜誌等均大...  234\n",
              "\n",
              "[4000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXhcTGMaYZXt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_X_chinese, train_Y_chinese), (val_X_chinese, val_Y_chinese) = \\\n",
        "prepare_data(bad_quality_langs_train, bad_quality_langs_train.sc, tokenizer_chinese, maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IA91PJA_Nvio",
        "colab_type": "code",
        "outputId": "4912d51b-2a7a-4a5a-81b9-f2ebb112e2f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "chinese_labels_dict = {lang:index for index, lang in enumerate(set(train_Y_chinese))}\n",
        "chinese_labels_dict"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{22: 5, 73: 2, 92: 7, 99: 0, 123: 6, 227: 1, 233: 4, 234: 3}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubiHl-tGxu89",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dummy_y_train_chinese = to_categorical([chinese_labels_dict[lan] for lan in train_Y_chinese])\n",
        "dummy_y_val_chinese = to_categorical([chinese_labels_dict[lan] for lan in val_Y_chinese])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1Px5m0yyLUA",
        "colab_type": "code",
        "outputId": "2a9873aa-717d-4791-e7ef-f83700026494",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        }
      },
      "source": [
        "cnn_model_chinese = Sequential()\n",
        "cnn_model_chinese.add(Embedding(max_features_chinese, embed_size, input_shape=(maxlen,)))\n",
        "cnn_model_chinese.add(Conv1D(256, 5, activation='relu', input_shape=(embed_size,)))\n",
        "cnn_model_chinese.add(MaxPooling1D(5))\n",
        "cnn_model_chinese.add(Dropout(0.2))\n",
        "cnn_model_chinese.add(Conv1D(256, 5, activation='relu'))\n",
        "cnn_model_chinese.add(MaxPooling1D(5))\n",
        "cnn_model_chinese.add(Flatten())\n",
        "cnn_model_chinese.add(Dense(512, activation=\"relu\"))\n",
        "cnn_model_chinese.add(Dropout(0.2))\n",
        "cnn_model_chinese.add(Dense(len(dummy_y_train_chinese[0]), activation='softmax'))\n",
        "cnn_model_chinese.summary()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 200, 300)          3000000   \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 196, 256)          384256    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_4 (MaxPooling1 (None, 39, 256)           0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 39, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 35, 256)           327936    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_5 (MaxPooling1 (None, 7, 256)            0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 1792)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 512)               918016    \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 8)                 4104      \n",
            "=================================================================\n",
            "Total params: 4,634,312\n",
            "Trainable params: 4,634,312\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlFTZRq8ya9i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn_model_chinese.compile(loss='categorical_crossentropy', optimizer='adam', metrics=train_metrics)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QiHi0eYrgaU",
        "colab_type": "code",
        "outputId": "cfd96cd0-5230-434a-b2cb-9c37704babad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "cnn_model_chinese.fit(train_X_chinese, dummy_y_train_chinese, batch_size=128, epochs=10, \n",
        "              validation_data=(val_X_chinese, dummy_y_val_chinese))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "29/29 [==============================] - 2s 62ms/step - loss: 1.1471 - categorical_accuracy: 0.5719 - precision_train: 0.7226 - recall_train: 0.3995 - f1_train: 0.4886 - val_loss: 0.4230 - val_categorical_accuracy: 0.8450 - val_precision_train: 0.9071 - val_recall_train: 0.8398 - val_f1_train: 0.8719\n",
            "Epoch 2/10\n",
            "29/29 [==============================] - 2s 55ms/step - loss: 0.2436 - categorical_accuracy: 0.9178 - precision_train: 0.9363 - recall_train: 0.9044 - f1_train: 0.9199 - val_loss: 0.1562 - val_categorical_accuracy: 0.9500 - val_precision_train: 0.9723 - val_recall_train: 0.9473 - val_f1_train: 0.9595\n",
            "Epoch 3/10\n",
            "29/29 [==============================] - 2s 55ms/step - loss: 0.0920 - categorical_accuracy: 0.9711 - precision_train: 0.9811 - recall_train: 0.9666 - f1_train: 0.9738 - val_loss: 0.1332 - val_categorical_accuracy: 0.9575 - val_precision_train: 0.9549 - val_recall_train: 0.9512 - val_f1_train: 0.9530\n",
            "Epoch 4/10\n",
            "29/29 [==============================] - 2s 55ms/step - loss: 0.0626 - categorical_accuracy: 0.9800 - precision_train: 0.9881 - recall_train: 0.9776 - f1_train: 0.9828 - val_loss: 0.0990 - val_categorical_accuracy: 0.9625 - val_precision_train: 0.9820 - val_recall_train: 0.9492 - val_f1_train: 0.9652\n",
            "Epoch 5/10\n",
            "29/29 [==============================] - 2s 56ms/step - loss: 0.0391 - categorical_accuracy: 0.9875 - precision_train: 0.9927 - recall_train: 0.9833 - f1_train: 0.9879 - val_loss: 0.1396 - val_categorical_accuracy: 0.9525 - val_precision_train: 0.9761 - val_recall_train: 0.9473 - val_f1_train: 0.9614\n",
            "Epoch 6/10\n",
            "29/29 [==============================] - 2s 57ms/step - loss: 0.0340 - categorical_accuracy: 0.9867 - precision_train: 0.9929 - recall_train: 0.9846 - f1_train: 0.9888 - val_loss: 0.1195 - val_categorical_accuracy: 0.9600 - val_precision_train: 0.9802 - val_recall_train: 0.9531 - val_f1_train: 0.9663\n",
            "Epoch 7/10\n",
            "29/29 [==============================] - 2s 55ms/step - loss: 0.0280 - categorical_accuracy: 0.9908 - precision_train: 0.9946 - recall_train: 0.9876 - f1_train: 0.9911 - val_loss: 0.1205 - val_categorical_accuracy: 0.9600 - val_precision_train: 0.9764 - val_recall_train: 0.9531 - val_f1_train: 0.9645\n",
            "Epoch 8/10\n",
            "29/29 [==============================] - 2s 56ms/step - loss: 0.0289 - categorical_accuracy: 0.9900 - precision_train: 0.9913 - recall_train: 0.9846 - f1_train: 0.9880 - val_loss: 0.1508 - val_categorical_accuracy: 0.9600 - val_precision_train: 0.9762 - val_recall_train: 0.9473 - val_f1_train: 0.9614\n",
            "Epoch 9/10\n",
            "29/29 [==============================] - 2s 56ms/step - loss: 0.0207 - categorical_accuracy: 0.9936 - precision_train: 0.9970 - recall_train: 0.9919 - f1_train: 0.9944 - val_loss: 0.0889 - val_categorical_accuracy: 0.9750 - val_precision_train: 0.9823 - val_recall_train: 0.9766 - val_f1_train: 0.9794\n",
            "Epoch 10/10\n",
            "29/29 [==============================] - 2s 56ms/step - loss: 0.0173 - categorical_accuracy: 0.9936 - precision_train: 0.9951 - recall_train: 0.9914 - f1_train: 0.9932 - val_loss: 0.1248 - val_categorical_accuracy: 0.9650 - val_precision_train: 0.9763 - val_recall_train: 0.9688 - val_f1_train: 0.9725\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f34ed3b4668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWwS0BKMsUGO",
        "colab_type": "code",
        "outputId": "446af307-ba1e-4c19-dba2-cb1c19bded7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "ps_chinese = []\n",
        "rs_chinese = []\n",
        "fs_chinese = []\n",
        "short_len = len(set(train_Y_chinese))\n",
        "\n",
        "for lan in set(train_Y_chinese):\n",
        "    x_t = x_test[x_test['sc'] == lan]\n",
        "    x = convert(x_t, tokenizer_chinese, maxlen)\n",
        "    y = np.zeros((x.shape[0], short_len))\n",
        "    y[:, chinese_labels_dict[lan]] = 1\n",
        "    y = y.astype('float32')\n",
        "    y_pred = cnn_model_chinese.predict(x)\n",
        "    p, r, f = combined_metric(y, y_pred)\n",
        "    ps_chinese.append(p.numpy())\n",
        "    rs_chinese.append(r.numpy())\n",
        "    fs_chinese.append(f.numpy())\n",
        "    print(\"language: \", class_to_language[lan], \"precision: \", p.numpy(), \"recall: \", r.numpy(), \"f1: \", f.numpy())"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "language:  khm precision:  1.0 recall:  0.9 f1:  0.9473683\n",
            "language:  wuu precision:  1.0 recall:  0.902 f1:  0.94847524\n",
            "language:  hbs precision:  1.0 recall:  0.992 f1:  0.99598384\n",
            "language:  zho precision:  1.0 recall:  0.936 f1:  0.9669421\n",
            "language:  zh-yue precision:  1.0 recall:  0.936 f1:  0.9669421\n",
            "language:  bod precision:  1.0 recall:  0.996 f1:  0.9979959\n",
            "language:  lzh precision:  1.0 recall:  0.994 f1:  0.996991\n",
            "language:  jpn precision:  1.0 recall:  0.996 f1:  0.9979959\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JakikCyXZA0m",
        "colab_type": "text"
      },
      "source": [
        "# Final model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwirB4b-rfCX",
        "colab_type": "text"
      },
      "source": [
        "## Data experiments on char level"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AszQrmS7ZeTd",
        "colab": {}
      },
      "source": [
        "filter_out = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n1234567890'\n",
        "## Tokenize the sentences\n",
        "tokenizer = Tokenizer(filters=filter_out, char_level=True)\n",
        "tokenizer.fit_on_texts(x_train.sent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HORVrXGGZDYZ",
        "colab_type": "code",
        "outputId": "e96f41a3-2e5f-4c45-aaab-ab59a5d31670",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# try different values of `count`\n",
        "# show how many words are presenting more than `count` times\n",
        "count = 0\n",
        "frequent_words = [w for w,c in tokenizer.word_counts.items() if c > count]\n",
        "len(frequent_words)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10489"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5VnelMpbh1z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer.fit_on_texts(x_train.sent)\n",
        "\n",
        "train_X = tokenizer.texts_to_sequences(x_train.sent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cppm020qbwi7",
        "colab_type": "code",
        "outputId": "2b4f3a48-08e3-492c-920c-c173e67e49d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "lens = [len(train_X[i]) for i in range(len(train_X))]\n",
        "plt.hist(lens, bins=np.linspace(0,1000,20), facecolor='blue', alpha=0.9)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXvyyaJAcsoE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_data(train_x, train_y, tokenizer_char, tokenizer_word, maxlen_char, maxlen_word):\n",
        "    x_tr, x_val, y_tr, y_val = train_test_split(train_x, train_y, test_size=0.1, random_state=1, stratify=train_y.values)\n",
        "\n",
        "    train_X_char = tokenizer_char.texts_to_sequences(x_tr.sent)\n",
        "    val_X_char = tokenizer_char.texts_to_sequences(x_val.sent)\n",
        "\n",
        "    train_X_word = tokenizer_word.texts_to_sequences(x_tr.sent)\n",
        "    val_X_word = tokenizer_word.texts_to_sequences(x_val.sent)\n",
        "\n",
        "    ## Pad chars\n",
        "    train_X_char = pad_sequences(train_X_char, maxlen=maxlen_char)\n",
        "    val_X_char = pad_sequences(val_X_char, maxlen=maxlen_char)\n",
        "\n",
        "    ## Pad words\n",
        "    train_X_word = pad_sequences(train_X_word, maxlen=maxlen_word)\n",
        "    val_X_word = pad_sequences(val_X_word, maxlen=maxlen_word)\n",
        "\n",
        "    return ((train_X_char, train_X_word), y_tr), ((val_X_char, val_X_word), y_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TA8yhaT7cstt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filter_out = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n1234567890'\n",
        "\n",
        "# for RNN use maxlen_char = 200\n",
        "maxlen_char = 500\n",
        "maxlen_word = 200\n",
        "\n",
        "max_features_words = 64157\n",
        "max_features_chars = 10489\n",
        "\n",
        "## Tokenize words\n",
        "tokenizer_words = Tokenizer(num_words=max_features_words, filters=filter_out, lower=True)  \n",
        "tokenizer_words.fit_on_texts(x_train.sent)\n",
        "\n",
        "## Tokenize chars\n",
        "tokenizer_char = Tokenizer(num_words=max_features_chars, filters=filter_out, char_level=True)\n",
        "tokenizer_char.fit_on_texts(x_train.sent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlPh-tgucsrY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "((train_X_char, train_X_word), train_Y), ((val_X_char, val_X_word), val_Y) = prepare_data(x_train, y_train, tokenizer_char, tokenizer_words, maxlen_char, maxlen_word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oG-2AAm8fnkW"
      },
      "source": [
        "Ниже меняю представление векторов ответов из [1, 23, 10,...] в вектор длины 235 и с 1 на месте соответсвующего языка"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "cc3a9da4-226e-4305-9eef-c33ac1c28193",
        "id": "sZZ5EXTvfnkW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "lb = LabelEncoder()\n",
        "y = lb.fit_transform(train_Y.values)\n",
        "dummy_y_train = to_categorical(y)\n",
        "\n",
        "print(len(dummy_y_train))\n",
        "print(len(dummy_y_train[0]))\n",
        "\n",
        "y = lb.fit_transform(val_Y.values)\n",
        "dummy_y_val = to_categorical(y)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "105750\n",
            "235\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:251: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWqoMTcofr1-",
        "colab_type": "text"
      },
      "source": [
        "## Model with two embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1M7jq0xq86d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embed_size = 20\n",
        "def create_double_cnn():\n",
        "    inp_char = Input(shape=(maxlen_char,))\n",
        "    inp_word = Input(shape=(maxlen_word,))\n",
        "\n",
        "    x1 = Embedding(max_features_chars, embed_size, input_shape=(maxlen_char,))(inp_char)\n",
        "    x2 = Embedding(max_features_words, embed_size, input_shape=(maxlen_word,))(inp_word)\n",
        "\n",
        "    concatted = tf.keras.layers.Concatenate(axis=1)([x1, x2])\n",
        "\n",
        "    lay = Conv1D(256, 5, activation='relu')(concatted)\n",
        "    lay = MaxPooling1D(5)(lay)\n",
        "    lay = Dropout(0.2)(lay)\n",
        "\n",
        "    lay = Conv1D(256, 5, activation='relu')(lay)\n",
        "    lay = MaxPooling1D(5)(lay)\n",
        "    lay = Flatten()(lay)\n",
        "\n",
        "    lay = Dense(512, activation=\"relu\")(lay)\n",
        "    lay = Dropout(0.2)(lay)\n",
        "\n",
        "    lay = Dense(num_classes, activation='softmax')(lay)\n",
        "    return Model(inputs=[inp_char, inp_word], outputs=lay)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWZbr61b7BeF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "double_model = create_double_cnn()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIJ61uEdsONc",
        "colab_type": "code",
        "outputId": "c6304fd6-7411-4ea9-fa42-5307b30700a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        }
      },
      "source": [
        "double_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=train_metrics)\n",
        "double_model.summary()"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 500)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 200)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_4 (Embedding)         (None, 500, 20)      209780      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_5 (Embedding)         (None, 200, 20)      1283140     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 700, 20)      0           embedding_4[0][0]                \n",
            "                                                                 embedding_5[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_6 (Conv1D)               (None, 696, 256)     25856       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_6 (MaxPooling1D)  (None, 139, 256)     0           conv1d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 139, 256)     0           max_pooling1d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_7 (Conv1D)               (None, 135, 256)     327936      dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_7 (MaxPooling1D)  (None, 27, 256)      0           conv1d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 6912)         0           max_pooling1d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 512)          3539456     flatten_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 512)          0           dense_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 235)          120555      dropout_10[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 5,506,723\n",
            "Trainable params: 5,506,723\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nwSTVaDwxydc",
        "colab": {}
      },
      "source": [
        "double_cp_path = data_path+'model_double.hdf5'\n",
        "double_cp=ModelCheckpoint(double_cp_path, monitor='val_loss',save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "467ba4e1-48be-4647-d27a-68a57ec0f6d7",
        "id": "fFkm8zFufy_a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "double_model.fit([train_X_char, train_X_word], dummy_y_train, batch_size=512, epochs=5, \n",
        "              validation_data=([val_X_char, val_X_word], dummy_y_val),\n",
        "               callbacks = [double_cp,  tf.keras.callbacks.TensorBoard(log_dir='./logs')]\n",
        "                )"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "207/207 [==============================] - 20s 94ms/step - loss: 3.0397 - categorical_accuracy: 0.3048 - precision_train: 0.5702 - recall_train: 0.1936 - f1_train: 0.2665 - val_loss: 0.9209 - val_categorical_accuracy: 0.7656 - val_precision_train: 0.9283 - val_recall_train: 0.6359 - val_f1_train: 0.7546\n",
            "Epoch 2/5\n",
            "207/207 [==============================] - 20s 96ms/step - loss: 0.6947 - categorical_accuracy: 0.8183 - precision_train: 0.9155 - recall_train: 0.7459 - f1_train: 0.8210 - val_loss: 0.4825 - val_categorical_accuracy: 0.8861 - val_precision_train: 0.9492 - val_recall_train: 0.8492 - val_f1_train: 0.8963\n",
            "Epoch 3/5\n",
            "207/207 [==============================] - 20s 97ms/step - loss: 0.3591 - categorical_accuracy: 0.9101 - precision_train: 0.9562 - recall_train: 0.8813 - f1_train: 0.9172 - val_loss: 0.4240 - val_categorical_accuracy: 0.9009 - val_precision_train: 0.9480 - val_recall_train: 0.8794 - val_f1_train: 0.9123\n",
            "Epoch 4/5\n",
            "207/207 [==============================] - 20s 96ms/step - loss: 0.2404 - categorical_accuracy: 0.9394 - precision_train: 0.9698 - recall_train: 0.9226 - f1_train: 0.9456 - val_loss: 0.4217 - val_categorical_accuracy: 0.9053 - val_precision_train: 0.9441 - val_recall_train: 0.8917 - val_f1_train: 0.9171\n",
            "Epoch 5/5\n",
            "207/207 [==============================] - 19s 93ms/step - loss: 0.1783 - categorical_accuracy: 0.9543 - precision_train: 0.9768 - recall_train: 0.9425 - f1_train: 0.9593 - val_loss: 0.4301 - val_categorical_accuracy: 0.9096 - val_precision_train: 0.9414 - val_recall_train: 0.8995 - val_f1_train: 0.9199\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f32c169d860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUduXQAscVJY",
        "colab_type": "text"
      },
      "source": [
        "## Download model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Oo1FEQRIcOKp",
        "colab": {}
      },
      "source": [
        "double_model = load_model('./drive/My Drive/hackaton/model_cnn_double.hdf5', custom_objects=dependencies)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfwlUiroRFle",
        "colab_type": "text"
      },
      "source": [
        "## Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0FA7gQNRHG0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJeWUutNRK-r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorboard.plugins import projector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKXI08jURUFW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set up a logs directory, so Tensorboard knows where to look for files\n",
        "log_dir='./logs/imdb-example-chars3/'\n",
        "if not os.path.exists(log_dir):\n",
        "    os.makedirs(log_dir)\n",
        "\n",
        "siz = max_features_chars\n",
        "ks = [tokenizer_char.index_word[i] for i in np.arange(1,siz)]\n",
        "# Save Labels separately on a line-by-line manner.\n",
        "with open(os.path.join(log_dir, 'metadata.tsv'), \"w\") as f:\n",
        "  for subwords in tokenizer_char.word_docs.keys():\n",
        "    f.write(\"{}\\n\".format(subwords))\n",
        "  # Fill in the rest of the labels with \"unknown\"\n",
        "  for unknown in range(1, max_features_chars - len(tokenizer_char.word_docs.keys())):\n",
        "    f.write(\"unknown #{}\\n\".format(unknown))\n",
        "\n",
        "\n",
        "# Save the weights we want to analyse as a variable. Note that the first\n",
        "# value represents any unknown word, which is not in the metadata, so\n",
        "# we will remove that value.\n",
        "weights = tf.Variable(double_model.layers[2].get_weights()[0][1:siz])\n",
        "# Create a checkpoint from embedding, the filename and key are\n",
        "# name of the tensor.\n",
        "checkpoint = tf.train.Checkpoint(embedding=weights)\n",
        "checkpoint.save(os.path.join(log_dir, \"embedding.ckpt\"))\n",
        "\n",
        "# Set up config\n",
        "config = projector.ProjectorConfig()\n",
        "embedding = config.embeddings.add()\n",
        "# The name of the tensor will be suffixed by `/.ATTRIBUTES/VARIABLE_VALUE`\n",
        "embedding.tensor_name = \"embedding/.ATTRIBUTES/VARIABLE_VALUE\"\n",
        "embedding.metadata_path = 'metadata.tsv'\n",
        "projector.visualize_embeddings(log_dir, config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bzAozARVH9d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir ./logs/imdb-example-chars3/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E42wMTdQR5J1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set up a logs directory, so Tensorboard knows where to look for files\n",
        "log_dir='./logs/imdb-example-words/'\n",
        "if not os.path.exists(log_dir):\n",
        "    os.makedirs(log_dir)\n",
        "\n",
        "# Save Labels separately on a line-by-line manner.\n",
        "#ks = list(tokenizer_words.index_word.values())[:20000]\n",
        "siz = 40000\n",
        "ks = [tokenizer_words.index_word[i] for i in np.arange(1,siz)]\n",
        "with open(os.path.join(log_dir, 'metadata.tsv'), \"w\") as f:\n",
        "  for subwords in ks:\n",
        "    f.write(\"{}\\n\".format(subwords))\n",
        "  # Fill in the rest of the labels with \"unknown\"\n",
        "  for unknown in range(1, max_features_words - len(tokenizer_words.word_docs.keys())):\n",
        "    f.write(\"unknown #{}\\n\".format(unknown))\n",
        "\n",
        "\n",
        "# Save the weights we want to analyse as a variable. Note that the first\n",
        "# value represents any unknown word, which is not in the metadata, so\n",
        "# we will remove that value.\n",
        "weights = tf.Variable(double_model.layers[3].get_weights()[0][1:siz])\n",
        "# Create a checkpoint from embedding, the filename and key are\n",
        "# name of the tensor.\n",
        "checkpoint = tf.train.Checkpoint(embedding=weights)\n",
        "checkpoint.save(os.path.join(log_dir, \"embedding.ckpt\"))\n",
        "\n",
        "# Set up config\n",
        "config = projector.ProjectorConfig()\n",
        "embedding = config.embeddings.add()\n",
        "# The name of the tensor will be suffixed by `/.ATTRIBUTES/VARIABLE_VALUE`\n",
        "embedding.tensor_name = \"embedding/.ATTRIBUTES/VARIABLE_VALUE\"\n",
        "embedding.metadata_path = 'metadata.tsv'\n",
        "projector.visualize_embeddings(log_dir, config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPcv7lqyXUib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir ./logs/imdb-example-words/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nU3Grknm3WRK",
        "colab_type": "text"
      },
      "source": [
        "## RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "28HMvK9S3cW9",
        "colab": {}
      },
      "source": [
        "embed_size = 200\n",
        "def create_double_rnn():\n",
        "    inp_char = Input(shape=(maxlen_char,))\n",
        "    inp_word = Input(shape=(maxlen_word,))\n",
        "\n",
        "    x1 = Embedding(max_features_chars, embed_size, input_shape=(maxlen_char,))(inp_char)\n",
        "    x2 = Embedding(max_features_words, embed_size, input_shape=(maxlen_word,))(inp_word)\n",
        "\n",
        "    concatted = tf.keras.layers.Concatenate(axis=1)([x1, x2])\n",
        "\n",
        "    lay = Bidirectional(LSTM(150, return_sequences=True, activation='tanh',input_dim=embed_size))(concatted)\n",
        "    lay = Dropout(0.2)(lay)\n",
        "\n",
        "    lay = Bidirectional(LSTM(150, return_sequences=True, activation='tanh',input_dim=embed_size))(lay)\n",
        "    lay = Dropout(0.2)(lay)\n",
        "    lay = GlobalMaxPool1D()(lay)\n",
        "\n",
        "    lay = Dense(512, activation=\"relu\")(lay)\n",
        "    lay = Dropout(0.2)(lay)\n",
        "\n",
        "    lay = Dense(num_classes, activation='softmax')(lay)\n",
        "    return Model(inputs=[inp_char, inp_word], outputs=lay)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "5af407a6-8779-4b92-cbfa-1b5531a2031e",
        "id": "ubbiWaky3cXB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "source": [
        "double_rnn_model = create_double_rnn()\n",
        "double_rnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=train_metrics)\n",
        "print(double_rnn_model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_15 (InputLayer)           [(None, 200)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_16 (InputLayer)           [(None, 200)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_12 (Embedding)        (None, 200, 200)     2097800     input_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "embedding_13 (Embedding)        (None, 200, 200)     12831400    input_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 400, 200)     0           embedding_12[0][0]               \n",
            "                                                                 embedding_13[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_6 (Bidirectional) (None, 400, 300)     421200      concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 400, 300)     0           bidirectional_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_7 (Bidirectional) (None, 400, 300)     541200      dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 400, 300)     0           bidirectional_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_3 (GlobalM (None, 300)          0           dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_12 (Dense)                (None, 512)          154112      global_max_pooling1d_3[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 512)          0           dense_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_13 (Dense)                (None, 235)          120555      dropout_17[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 16,166,267\n",
            "Trainable params: 16,166,267\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7d78KEhF3cXE",
        "colab": {}
      },
      "source": [
        "double_rnn_cp_path = data_path+'model_rnn_double.hdf5'\n",
        "double_rnn_cp=ModelCheckpoint(double_rnn_cp_path, monitor='val_loss',save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "1af2771a-d965-42be-cae8-e56147f092dd",
        "id": "hUbN_l1V3cXH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        }
      },
      "source": [
        "double_rnn_model.fit([train_X_char, train_X_word], dummy_y_train, batch_size=512, epochs=7, \n",
        "              validation_data=([val_X_char, val_X_word], dummy_y_val),\n",
        "               callbacks = [double_cp]\n",
        "             )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/7\n",
            "207/207 [==============================] - 327s 2s/step - loss: 2.8170 - categorical_accuracy: 0.3641 - f1_met: 0.2020 - precision: 0.6202 - recall: 0.2168 - val_loss: 0.8080 - val_categorical_accuracy: 0.8463 - val_f1_met: 0.6258 - val_precision: 0.9715 - val_recall: 0.6720\n",
            "Epoch 2/7\n",
            "207/207 [==============================] - 323s 2s/step - loss: 0.4632 - categorical_accuracy: 0.8946 - f1_met: 0.7694 - precision: 0.9495 - recall: 0.8552 - val_loss: 0.4192 - val_categorical_accuracy: 0.9133 - val_f1_met: 0.7912 - val_precision: 0.9708 - val_recall: 0.8726\n",
            "Epoch 3/7\n",
            "207/207 [==============================] - 324s 2s/step - loss: 0.2131 - categorical_accuracy: 0.9511 - f1_met: 0.8366 - precision: 0.9747 - recall: 0.9379 - val_loss: 0.3645 - val_categorical_accuracy: 0.9203 - val_f1_met: 0.8071 - val_precision: 0.9627 - val_recall: 0.8990\n",
            "Epoch 4/7\n",
            "207/207 [==============================] - 322s 2s/step - loss: 0.1271 - categorical_accuracy: 0.9697 - f1_met: 0.8565 - precision: 0.9845 - recall: 0.9621 - val_loss: 0.3770 - val_categorical_accuracy: 0.9195 - val_f1_met: 0.8097 - val_precision: 0.9566 - val_recall: 0.9047\n",
            "Epoch 5/7\n",
            "  2/207 [..............................] - ETA: 2:33 - loss: 0.0845 - categorical_accuracy: 0.9814 - f1_met: 0.8541 - precision: 0.9920 - recall: 0.9766"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-87-19df41e783b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m double_rnn_model.fit([train_X_char, train_X_word], dummy_y_train, batch_size=512, epochs=7, \n\u001b[1;32m      2\u001b[0m               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_X_char\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_X_word\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_y_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdouble_cp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m              )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XRmhIRA2ifgE"
      },
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LIXo-d-MifgK",
        "colab": {}
      },
      "source": [
        "x_test['sc'] = y_test\n",
        "x_test['lang'] = [class_to_language[y] for y in list(y_test.iloc[:,0])]\n",
        "x_train['sc'] = y_train\n",
        "x_train['lang'] = [class_to_language[y] for y in list(y_train.iloc[:,0])]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbsUXroCik0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert(x, tokenizer_char, tokenizer_word, maxlen_char, maxlen_word):\n",
        "    X_char = tokenizer_char.texts_to_sequences(x.sent)\n",
        "    X_word = tokenizer_word.texts_to_sequences(x.sent)\n",
        "\n",
        "    ## Pad chars\n",
        "    X_char = pad_sequences(X_char, maxlen=maxlen_char)\n",
        "\n",
        "    ## Pad words\n",
        "    X_word = pad_sequences(X_word, maxlen=maxlen_word)\n",
        "\n",
        "    return (X_char, X_word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eXHS2UEkifgX"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g20c21Q-ns24",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_char, x_word = convert(x_test, tokenizer_char, tokenizer_words, maxlen_char, maxlen_word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXvca94Vn7mx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = lb.fit_transform(y_test.values)\n",
        "dummy_y_test = to_categorical(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViVAmYQMns7L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_rnn = double_rnn_model.predict([x_char, x_word])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dA8vNiBMok1F",
        "colab": {}
      },
      "source": [
        "p, r, f = met(dummy_y_test, y_pred_rnn)\n",
        "raw_metrics_rnn = pd.DataFrame(\n",
        "    {'precision': p,\n",
        "     'recall': r,\n",
        "     'f1': f\n",
        "    })\n",
        "metrics_rnn = raw_metrics_rnn.rename(class_to_language, axis='index')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lewvapp4ns-j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_cnn = double_model.predict([x_char, x_word])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gT5N-zsBok1P",
        "colab": {}
      },
      "source": [
        "p, r, f = met(dummy_y_test, y_pred_cnn)\n",
        "raw_metrics_cnn = pd.DataFrame(\n",
        "    {'precision': p,\n",
        "     'recall': r,\n",
        "     'f1': f\n",
        "    })\n",
        "metrics_cnn = raw_metrics_cnn.rename(class_to_language, axis='index')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "97011b1b-6bc3-4928-c0f4-2d2a0aaf9839",
        "id": "8NPx1FlIok1R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        }
      },
      "source": [
        "metrics_rnn[metrics_rnn.f1 < 0.8]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>be-tarask</th>\n",
              "      <td>0.841379</td>\n",
              "      <td>0.732</td>\n",
              "      <td>0.782888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bos</th>\n",
              "      <td>0.629747</td>\n",
              "      <td>0.398</td>\n",
              "      <td>0.487745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cbk</th>\n",
              "      <td>0.881868</td>\n",
              "      <td>0.642</td>\n",
              "      <td>0.743056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>deu</th>\n",
              "      <td>0.876513</td>\n",
              "      <td>0.724</td>\n",
              "      <td>0.792990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>eng</th>\n",
              "      <td>0.672000</td>\n",
              "      <td>0.336</td>\n",
              "      <td>0.448000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fra</th>\n",
              "      <td>0.863415</td>\n",
              "      <td>0.708</td>\n",
              "      <td>0.778022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hbs</th>\n",
              "      <td>0.489458</td>\n",
              "      <td>0.650</td>\n",
              "      <td>0.558419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hrv</th>\n",
              "      <td>0.648148</td>\n",
              "      <td>0.420</td>\n",
              "      <td>0.509709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ind</th>\n",
              "      <td>0.857471</td>\n",
              "      <td>0.746</td>\n",
              "      <td>0.797861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>map-bms</th>\n",
              "      <td>0.959302</td>\n",
              "      <td>0.660</td>\n",
              "      <td>0.781991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pcd</th>\n",
              "      <td>0.944615</td>\n",
              "      <td>0.614</td>\n",
              "      <td>0.744242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rus</th>\n",
              "      <td>0.842593</td>\n",
              "      <td>0.728</td>\n",
              "      <td>0.781116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>spa</th>\n",
              "      <td>0.634109</td>\n",
              "      <td>0.818</td>\n",
              "      <td>0.714410</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           precision  recall        f1\n",
              "be-tarask   0.841379   0.732  0.782888\n",
              "bos         0.629747   0.398  0.487745\n",
              "cbk         0.881868   0.642  0.743056\n",
              "deu         0.876513   0.724  0.792990\n",
              "eng         0.672000   0.336  0.448000\n",
              "fra         0.863415   0.708  0.778022\n",
              "hbs         0.489458   0.650  0.558419\n",
              "hrv         0.648148   0.420  0.509709\n",
              "ind         0.857471   0.746  0.797861\n",
              "map-bms     0.959302   0.660  0.781991\n",
              "pcd         0.944615   0.614  0.744242\n",
              "rus         0.842593   0.728  0.781116\n",
              "spa         0.634109   0.818  0.714410"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_4vq2x09TcD",
        "colab_type": "code",
        "outputId": "ba496c83-6891-4988-b72a-67d0b382a616",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "metrics_rnn[metrics_rnn.f1 > 0.95].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(116, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O677cW306pID",
        "colab_type": "code",
        "outputId": "63cba974-e4ab-4c56-98f1-0d4828d272ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "metrics_cnn[metrics_cnn.f1 < 0.7]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>bos</th>\n",
              "      <td>0.551402</td>\n",
              "      <td>0.590</td>\n",
              "      <td>0.570048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>eng</th>\n",
              "      <td>0.607921</td>\n",
              "      <td>0.614</td>\n",
              "      <td>0.610945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hbs</th>\n",
              "      <td>0.566667</td>\n",
              "      <td>0.374</td>\n",
              "      <td>0.450602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hrv</th>\n",
              "      <td>0.545692</td>\n",
              "      <td>0.418</td>\n",
              "      <td>0.473386</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     precision  recall        f1\n",
              "bos   0.551402   0.590  0.570048\n",
              "eng   0.607921   0.614  0.610945\n",
              "hbs   0.566667   0.374  0.450602\n",
              "hrv   0.545692   0.418  0.473386"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 293
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZNJ0JpJ9Wid",
        "colab_type": "code",
        "outputId": "9d4f42e4-c5df-4b86-f537-ea10eebcd88d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "metrics_cnn[metrics_cnn.f1 > 0.95].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(120, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clcmJUe-zXo3",
        "colab_type": "text"
      },
      "source": [
        "# Handy example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQZTpyljpG4R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my = pd.DataFrame(\n",
        "    {'sent': ['English is a West Germanic language that was first spoken in early medieval England and eventually became a global lingua franca.[4][5] It is named after the Angles, one of the ancient Germanic peoples that migrated to the area of Great Britain that later took their name, England. Both names derive from Anglia, ',\n",
        "              'язык англо-фризской подгруппы западной группы германской ветви индоевропейской языковой семьи. Английский язык — важнейший международный язык[4], что является следствием колониальной политики Британской империи в XIX веке и мирового влияния США в XX—XXI веках. Существует значительное разнообразие диалектов и говоров английского языка.',\n",
        "              'Produkcja aparatów fotograficznych w kijowskich zakładach Arsenal rozpoczęła się od przeniesienia w 1946 r. z Drezna całej, ledwie uruchomionej po zniszczeniach wojennych linii produkcyjnej aparatów małoobrazkowych Contax, wraz z zatrudnionymi przy niej fachowcami. ',\n",
        "              'З 1944 года дзейнічае Дзяржаўны літаратурны музей Янкі Купалы. У гонар паэта ў 1957 годзе была заснавана Літаратурная прэмія імя Янкі Купалы. З 1995 года сістэматычна праводзяцца штогадовыя Купалаўскія чытанні — прафесійны форум для абмеркавання навуковых дасягненняў і праблем купалазнаўства.'\n",
        "              ],\n",
        "    })"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaQacjIxzfP2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_char, x_word = convert(my, tokenizer_char, tokenizer_words, maxlen_char, maxlen_word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1vdlKvpz6rs",
        "colab_type": "code",
        "outputId": "1ba7a91c-8500-46b3-f95d-15bbca31c137",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ys = double_model.predict([x_char, x_word])\n",
        "ys.argmax(axis=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 50, 177, 168,  18])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RkJ4yjnnrwv",
        "colab_type": "code",
        "outputId": "29a6d487-b5ee-46c4-dae1-3756ccbaaeab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ys = double_rnn_model.predict([x_char, x_word])\n",
        "ys.argmax(axis=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 50,  10, 168,  18])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csZ668ko9ENQ",
        "colab_type": "code",
        "outputId": "a616f94b-2f01-4715-d537-907d3a0ea37e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "class_to_language[10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ava'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUQrR-s29G5I",
        "colab_type": "code",
        "outputId": "4c82edf4-7801-441a-cf88-0fddf1855086",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "class_to_language[228]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'xho'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 299
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gnA4ZEn0v2d",
        "colab_type": "code",
        "outputId": "0d2be843-9d29-43f6-977e-0fd97b5f22ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "class_to_language[50]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'eng'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 236
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uo6mDP6GzmDX",
        "colab_type": "code",
        "outputId": "b7e5b8d9-1c88-4110-a8bd-246f85202765",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "class_to_language[177]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'rus'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 237
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6UjGQGmzrs0",
        "colab_type": "code",
        "outputId": "c7fe0aed-7f10-43de-8d60-bc7e977e2d60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "class_to_language[168]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'pol'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 238
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6n7eluk1zyIS",
        "colab_type": "code",
        "outputId": "2a491c12-155e-4b71-e12e-502006fa27f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "class_to_language[18]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'bel'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 239
        }
      ]
    }
  ]
}