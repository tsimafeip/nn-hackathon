{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of hackaton.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpmSbtrCklRB",
        "colab_type": "code",
        "outputId": "65639546-7c53-44fc-b43c-46aa10c9f734",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNLhWWCxYfLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "import scipy\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import logging\n",
        "import multiprocessing\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8IzA7Rx-VzU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Bidirectional, GlobalMaxPooling1D, GlobalMaxPool1D, MaxPooling1D, Flatten, concatenate\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras import initializers, regularizers, constraints, optimizers, layers\n",
        "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1vZGIRYYR9G",
        "colab_type": "text"
      },
      "source": [
        "# Hanna's data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFKrCtLZYBcV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import zipfile\n",
        "# with zipfile.ZipFile('./drive/My Drive/hackaton/wili-2018.zip', 'r') as zip_ref:\n",
        "#     zip_ref.extractall('./')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcwIDfWAYOUl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data_path = '/content/drive/My Drive/Colab Notebooks/Hackathon/'\n",
        "# wili_data_path = ''\n",
        "\n",
        "# x_train_path = wili_data_path + 'x_train.txt'\n",
        "# x_test_path = wili_data_path + 'x_test.txt'\n",
        "# y_train_path = wili_data_path + 'y_train.txt'\n",
        "# y_test_path = wili_data_path + 'y_test.txt'\n",
        "# labels_path = wili_data_path + 'labels.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc94smEhjbA_",
        "colab_type": "text"
      },
      "source": [
        "# Download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75potnAshWU4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path = '/content/drive/My Drive/Colab Notebooks/Hackathon/'\n",
        "wili_data_path = data_path + 'wili-2018/'\n",
        "\n",
        "x_train_path = wili_data_path + 'x_train.txt'\n",
        "x_test_path = wili_data_path + 'x_test.txt'\n",
        "y_train_path = wili_data_path + 'y_train.txt'\n",
        "y_test_path = wili_data_path + 'y_test.txt'\n",
        "labels_path = wili_data_path + 'labels.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhsiujWS3QR8",
        "colab_type": "code",
        "outputId": "ae6b26cc-d4d3-4ccd-d23d-86804c9f8d58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "labels = pd.read_csv(labels_path, sep=';')\n",
        "labels = labels.drop(labels=['German', 'Writing system', 'Remarks', 'Synonyms'], axis=1)\n",
        "labels"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>English</th>\n",
              "      <th>Wiki Code</th>\n",
              "      <th>ISO 369-3</th>\n",
              "      <th>Language family</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ace</td>\n",
              "      <td>Achinese</td>\n",
              "      <td>ace</td>\n",
              "      <td>ace</td>\n",
              "      <td>Austronesian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>afr</td>\n",
              "      <td>Afrikaans</td>\n",
              "      <td>af</td>\n",
              "      <td>afr</td>\n",
              "      <td>Indo-European</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>als</td>\n",
              "      <td>Alemannic German</td>\n",
              "      <td>als</td>\n",
              "      <td>gsw</td>\n",
              "      <td>Indo-European</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>amh</td>\n",
              "      <td>Amharic</td>\n",
              "      <td>am</td>\n",
              "      <td>amh</td>\n",
              "      <td>Afro-Asiatic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ang</td>\n",
              "      <td>Old English</td>\n",
              "      <td>ang</td>\n",
              "      <td>ang</td>\n",
              "      <td>Indo-European</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>230</th>\n",
              "      <td>yid</td>\n",
              "      <td>Yiddish</td>\n",
              "      <td>yi</td>\n",
              "      <td>yid</td>\n",
              "      <td>Indo-European</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>231</th>\n",
              "      <td>yor</td>\n",
              "      <td>Yoruba</td>\n",
              "      <td>yo</td>\n",
              "      <td>yor</td>\n",
              "      <td>Niger-Congo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>232</th>\n",
              "      <td>zea</td>\n",
              "      <td>Zeeuws</td>\n",
              "      <td>zea</td>\n",
              "      <td>zea</td>\n",
              "      <td>Indo-European</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>233</th>\n",
              "      <td>zh-yue</td>\n",
              "      <td>Cantonese</td>\n",
              "      <td>zh-yue</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Sino-Tibetan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>234</th>\n",
              "      <td>zho</td>\n",
              "      <td>Standard Chinese</td>\n",
              "      <td>zh</td>\n",
              "      <td>zho</td>\n",
              "      <td>Sino-Tibetan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>235 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Label           English Wiki Code ISO 369-3 Language family\n",
              "0       ace          Achinese       ace       ace    Austronesian\n",
              "1       afr         Afrikaans        af       afr   Indo-European\n",
              "2       als  Alemannic German       als       gsw   Indo-European\n",
              "3       amh           Amharic        am       amh    Afro-Asiatic\n",
              "4       ang      Old English        ang       ang   Indo-European\n",
              "..      ...               ...       ...       ...             ...\n",
              "230     yid           Yiddish        yi       yid   Indo-European\n",
              "231     yor            Yoruba        yo       yor     Niger-Congo\n",
              "232     zea            Zeeuws       zea       zea   Indo-European\n",
              "233  zh-yue         Cantonese    zh-yue       NaN    Sino-Tibetan\n",
              "234     zho  Standard Chinese        zh       zho    Sino-Tibetan\n",
              "\n",
              "[235 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpH6qYnlYrBN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_to_language = labels.Label.astype(str).to_dict()\n",
        "language_to_class = {v: k for k, v in class_to_language.items()}\n",
        "num_classes = len(class_to_language)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDFr3-rKmDdv",
        "colab_type": "code",
        "outputId": "4825f94f-06da-485a-d4c6-843d37704e58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(list(language_to_class.items())[:5])\n",
        "num_classes"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('ace', 0), ('afr', 1), ('als', 2), ('amh', 3), ('ang', 4)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "235"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBqkjck1Yc7q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_data():\n",
        "    with open(x_train_path) as f:\n",
        "        mylist = f.read().splitlines() \n",
        "    x_train = pd.DataFrame(mylist, columns=[\"sent\"])\n",
        "    with open(x_test_path) as f:\n",
        "        mylist = f.read().splitlines() \n",
        "    x_test = pd.DataFrame(mylist, columns=[\"sent\"])\n",
        "\n",
        "    with open(y_train_path) as f:\n",
        "        mylist = f.read().splitlines() \n",
        "    y_train = []\n",
        "    for lan in mylist:\n",
        "        y_train.append(language_to_class[lan])\n",
        "    y_train = pd.DataFrame(y_train)\n",
        "    with open(y_test_path) as f:\n",
        "        mylist = f.read().splitlines()\n",
        "\n",
        "    y_test = []\n",
        "    for lan in mylist:\n",
        "        y_test.append(language_to_class[lan])\n",
        "    y_test = pd.DataFrame(y_test)\n",
        "    \n",
        "    return (x_train, y_train), (x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhKRW6V8hhIc",
        "colab_type": "code",
        "outputId": "dd1ae54b-9c9a-4e42-8e4a-60e72c59e25a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = read_data()\n",
        "\n",
        "print(x_train.head())\n",
        "print(y_train.head())\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                sent\n",
            "0  Klement Gottwaldi surnukeha palsameeriti ning ...\n",
            "1  Sebes, Joseph; Pereira Thomas (1961) (på eng)....\n",
            "2  भारतीय स्वातन्त्र्य आन्दोलन राष्ट्रीय एवम क्षे...\n",
            "3  Après lo cort periòde d'establiment a Basilèa,...\n",
            "4  ถนนเจริญกรุง (อักษรโรมัน: Thanon Charoen Krung...\n",
            "     0\n",
            "0   52\n",
            "1  198\n",
            "2  124\n",
            "3  155\n",
            "4  207\n",
            "(117500, 1)\n",
            "(117500, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zcUciRigFYu",
        "colab_type": "code",
        "outputId": "af506a98-67ed-462e-9ea5-214ad7eb7835",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "lens = x_train.sent.str.split(' ').str.len().values\n",
        "plt.hist(lens, bins=np.linspace(0,1000,20), facecolor='blue', alpha=0.9)\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xdCSiHnhlX1",
        "colab_type": "text"
      },
      "source": [
        "# Experiment on small dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFTqOQmChknq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# small_dataset = pd.read_csv(data_path + 'kaggle_dataset/dataset.csv')\n",
        "# small_dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwtWy38ehtGO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X=small_dataset['Text']\n",
        "# y=small_dataset['language']\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# print(len(X_train))\n",
        "# print(len(X_test))\n",
        "# print(len(y_train))\n",
        "# print(len(y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNoYz_IwjeY_",
        "colab_type": "text"
      },
      "source": [
        "# Embedding **data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEr8pklSjQLP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filter_out = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n1234567890'\n",
        "tokenizer = Tokenizer(filters=filter_out, lower=True)\n",
        "tokenizer.fit_on_texts(x_train.sent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5jxVwDcftcn",
        "colab_type": "text"
      },
      "source": [
        "Выбираю какое количество слов оставить. Если оставлять все, то будет 1500000, что слишком много. Можно поменять `count` и оно покажет сколько слов встречается больше, чем `count` раз"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xKQt34TAG2-",
        "colab_type": "code",
        "outputId": "713c201c-ef0d-42aa-9d11-c07c5acf3965",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# try different values of `count`\n",
        "# show how many words are presenting more than `count` times\n",
        "count = 10\n",
        "frequent_words = [w for w,c in tokenizer.word_counts.items() if c > count]\n",
        "len(frequent_words)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64157"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwDeU_wRph8C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_data(train_x, train_y, tokenizator, max_len_of_vector):\n",
        "    x_tr, x_val, y_tr, y_val = train_test_split(train_x, train_y, test_size=0.1, random_state=1, stratify=train_y.values)\n",
        "   \n",
        "    tokenizator.fit_on_texts(x_tr.sent)\n",
        "\n",
        "    train_X = tokenizator.texts_to_sequences(x_tr.sent)\n",
        "    val_X = tokenizator.texts_to_sequences(x_val.sent)\n",
        "\n",
        "    ## Pad the sentences \n",
        "    train_X = pad_sequences(train_X, maxlen=max_len_of_vector)\n",
        "    val_X = pad_sequences(val_X, maxlen=max_len_of_vector)\n",
        "\n",
        "    return (train_X, y_tr), (val_X, y_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJacuBHhHEng",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embed_size = 300 # how big is each word vector\n",
        "max_features = len(frequent_words) # how many unique words to use (i.e num rows in embedding vector)\n",
        "maxlen = 200 # max number of words in a question to use\n",
        "\n",
        "## Tokenize the sentences\n",
        "tokenizer = Tokenizer(num_words=max_features, filters=filter_out, lower=True)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qW1oK9wfHEnm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_X, train_Y), (val_X, val_Y) = prepare_data(x_train, y_train, tokenizer, maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxyyqzKsgF9K",
        "colab_type": "text"
      },
      "source": [
        "Проверила, что в тренировочном и валидационном датасетах встречаются все классы. Балансировка регулируется вот этим параметром: stratify=y_train.values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1iJF7cyU5iK",
        "colab_type": "code",
        "outputId": "0e2796e5-74ff-40f6-ffaa-9fa0044504d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(set(val_Y.values.reshape(1, -1)[0]))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "235"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPITYtR8UqNx",
        "colab_type": "code",
        "outputId": "bd6109d0-bee2-49da-e883-fa693349294c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(set(train_Y.values.reshape(1, -1)[0]))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "235"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYuurOSQgYUl",
        "colab_type": "text"
      },
      "source": [
        "Ниже меняю представление векторов ответов из [1, 23, 10,...] в вектор длины 235 и с 1 на месте соответсвующего языка"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0iIyf4bIXg_",
        "colab_type": "code",
        "outputId": "1f4327f6-3687-48f1-c57f-c8a171273c2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "lb = LabelEncoder()\n",
        "y = lb.fit_transform(train_Y.values.ravel())\n",
        "dummy_y_train = to_categorical(y)\n",
        "print(len(dummy_y_train))\n",
        "print(len(dummy_y_train[0]))"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "105750\n",
            "235\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCBYAruyIxUm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = lb.fit_transform(val_Y.values.ravel())\n",
        "dummy_y_val = to_categorical(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeXXgZJ6miyl",
        "colab_type": "text"
      },
      "source": [
        "# Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vp4rfHfplm6O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f1(y_true, y_pred): #taken from old keras source code\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return f1_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dzi3zyNsmNIR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def recall(y_true, y_pred): #taken from old keras source code\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    return true_positives / (possible_positives + K.epsilon())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JX13CaozmRhy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def precision(y_true, y_pred): #taken from old keras source code\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    return true_positives / (predicted_positives + K.epsilon())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtGH8P89gTXf",
        "colab_type": "text"
      },
      "source": [
        "#CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdsE9d9SjdsW",
        "colab_type": "code",
        "outputId": "ecca5700-ecb7-47aa-e69e-bf4fa056c698",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        }
      },
      "source": [
        "cnn_model = Sequential()\n",
        "cnn_model.add(Embedding(max_features, embed_size,input_shape=(maxlen,)))\n",
        "cnn_model.add(Conv1D(256, 5, activation='relu', input_shape=(embed_size,)))\n",
        "cnn_model.add(MaxPooling1D(5))\n",
        "cnn_model.add(Dropout(0.2))\n",
        "cnn_model.add(Conv1D(256, 5, activation='relu'))\n",
        "cnn_model.add(MaxPooling1D(5))\n",
        "cnn_model.add(Flatten())\n",
        "cnn_model.add(Dense(512, activation=\"relu\"))\n",
        "cnn_model.add(Dropout(0.2))\n",
        "cnn_model.add(Dense(num_classes, activation='softmax'))\n",
        "cnn_model.summary()"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 200, 300)          19247100  \n",
            "_________________________________________________________________\n",
            "conv1d_6 (Conv1D)            (None, 196, 256)          384256    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_6 (MaxPooling1 (None, 39, 256)           0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 39, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_7 (Conv1D)            (None, 35, 256)           327936    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_7 (MaxPooling1 (None, 7, 256)            0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 1792)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 512)               918016    \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 235)               120555    \n",
            "=================================================================\n",
            "Total params: 20,997,863\n",
            "Trainable params: 20,997,863\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sndko3XlZ806",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', f1, recall, precision])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aa9rf4_Oq6nX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn_cp_path = data_path+'model_cnn.hdf5'\n",
        "cnn_cp=ModelCheckpoint(cnn_cp_path, monitor='val_loss',save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIhz76oFHo_c",
        "colab_type": "code",
        "outputId": "1fa8e4e9-2d58-445b-c5ad-b58133c0fa86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "cnn_model.fit(train_X, dummy_y_train, batch_size=512, epochs=5, \n",
        "              validation_data=(val_X, dummy_y_val),\n",
        "              callbacks = [cnn_cp]\n",
        "             )"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "207/207 [==============================] - 58s 280ms/step - loss: 3.1751 - accuracy: 0.3184 - f1: 0.2923 - recall: 0.2292 - precision: 0.5978 - val_loss: 0.7057 - val_accuracy: 0.8453 - val_f1: 0.8557 - val_recall: 0.7733 - val_precision: 0.9580\n",
            "Epoch 2/5\n",
            "207/207 [==============================] - 58s 279ms/step - loss: 0.5014 - accuracy: 0.8758 - f1: 0.8917 - recall: 0.8372 - precision: 0.9542 - val_loss: 0.4880 - val_accuracy: 0.8851 - val_f1: 0.9063 - val_recall: 0.8568 - val_precision: 0.9618\n",
            "Epoch 3/5\n",
            "207/207 [==============================] - 56s 272ms/step - loss: 0.2458 - accuracy: 0.9333 - f1: 0.9464 - recall: 0.9162 - precision: 0.9788 - val_loss: 0.5086 - val_accuracy: 0.8945 - val_f1: 0.9148 - val_recall: 0.8770 - val_precision: 0.9563\n",
            "Epoch 4/5\n",
            "207/207 [==============================] - 56s 271ms/step - loss: 0.1726 - accuracy: 0.9502 - f1: 0.9614 - recall: 0.9385 - precision: 0.9854 - val_loss: 0.5578 - val_accuracy: 0.8943 - val_f1: 0.9137 - val_recall: 0.8802 - val_precision: 0.9500\n",
            "Epoch 5/5\n",
            "207/207 [==============================] - 56s 270ms/step - loss: 0.1429 - accuracy: 0.9575 - f1: 0.9676 - recall: 0.9482 - precision: 0.9878 - val_loss: 0.6260 - val_accuracy: 0.8911 - val_f1: 0.9099 - val_recall: 0.8791 - val_precision: 0.9430\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb8e5e4e668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkmpFZmyUjF8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dependencies = {\n",
        "     'f1': f1,\n",
        "     'recall': recall,\n",
        "     'precision': precision\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qji8xqW2WiS-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cnn_model = load_model(cnn_cp_path, custom_objects=dependencies)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-T-4MO1ZR_S",
        "colab_type": "text"
      },
      "source": [
        "#RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ch0GFZ-ZSzb",
        "colab_type": "code",
        "outputId": "2d842e33-e0f9-4b8e-ae8d-e6d2b85eb4cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "rnn_model = Sequential()\n",
        "rnn_model.add(Embedding(max_features, embed_size))\n",
        "rnn_model.add(Bidirectional(LSTM(128, return_sequences=True, activation='tanh',input_dim=embed_size)))\n",
        "rnn_model.add(Dropout(0.2))\n",
        "rnn_model.add(Bidirectional(LSTM(128, return_sequences=True, activation='tanh')))\n",
        "rnn_model.add(GlobalMaxPool1D())\n",
        "rnn_model.add(Dropout(0.2))\n",
        "rnn_model.add(Dense(512, activation=\"relu\"))\n",
        "rnn_model.add(Dropout(0.2))\n",
        "rnn_model.add(Dense(num_classes, activation='softmax'))\n",
        "rnn_model.summary()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 300)         19247100  \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, None, 512)         1140736   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, None, 512)         0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, None, 512)         1574912   \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 235)               120555    \n",
            "=================================================================\n",
            "Total params: 22,345,959\n",
            "Trainable params: 22,345,959\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1W3XFHXZiVR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', f1, recall, precision])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPtLB7kUrGgE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rnn_cp_path = data_path + 'model_rnn.hdf5'\n",
        "rnn_cp=ModelCheckpoint(rnn_cp_path,monitor='val_f1',save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qK-tgijZk7L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# rnn_model.fit(train_X, dummy_y_train, batch_size=512, epochs=3, \n",
        "#               validation_data=(val_X, dummy_y_val), callbacks = [rnn_cp])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kk3g4PLUumt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rnn_model = load_model(rnn_cp_path, custom_objects=dependencies)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCeuUze_qnC2",
        "colab_type": "text"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jS0Tq-Cqb4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test['sc'] = y_test\n",
        "x_test['lang'] = [class_to_language[y] for y in list(y_test.iloc[:,0])]\n",
        "x_train['sc'] = y_train\n",
        "x_train['lang'] = [class_to_language[y] for y in list(y_train.iloc[:,0])]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wowtwiinqwm0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Be careful! Tokenizer and maxlen is taken from train dataset from 1st part\n",
        "def convert(x, tokenizator, max_vector_len):\n",
        "    train_X = tokenizator.texts_to_sequences(x.sent)\n",
        "    ## Pad the sentences \n",
        "    train_X = pad_sequences(train_X, maxlen=max_vector_len)\n",
        "    return train_X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvOMHL7Nx_eO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def metr(y_true, y_pred): #taken from old keras source code\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return precision, recall, f1_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hs6AXcPcsj1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f1(y_true, y_pred):\n",
        "    y_pred = K.round(y_pred)\n",
        "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
        "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
        "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
        "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
        "\n",
        "    p = tp / (tp + fp + K.epsilon())\n",
        "    r = tp / (tp + fn + K.epsilon())\n",
        "\n",
        "    f1 = 2*p*r / (p+r+K.epsilon())\n",
        "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
        "    return max(p), max(r), max(f1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adUqSHYSc2Ye",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# New metric!\n",
        "def met(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)), axis=0)\n",
        "    false_positives = K.sum(K.round(K.clip((1 - y_true) * y_pred, 0, 1)), axis=0)\n",
        "    true_negatives = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)), axis=0)\n",
        "    false_negatives = K.sum(K.round(K.clip(y_true * (1 - y_pred), 0, 1)), axis=0)\n",
        "    precision = max(true_positives / (true_positives + false_positives  + K.epsilon()))\n",
        "    recall = max(true_positives / (true_positives + false_negatives  + K.epsilon()))\n",
        "    f1 = 2 * precision * recall / (precision + recall + K.epsilon())\n",
        "    return precision, recall, f1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OwT-3obvsIo",
        "colab_type": "text"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P006Z5Sgzeal",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7a6a2e2e-88c4-452b-e9c9-75f7db9b679d"
      },
      "source": [
        "ps = []\n",
        "rs = []\n",
        "fs = []\n",
        "for lan in tqdm(range(num_classes)):\n",
        "    x_t = x_test[x_test['sc'] == lan]\n",
        "    x = convert(x_t, tokenizer, maxlen)\n",
        "    y = np.zeros((x.shape[0], num_classes))\n",
        "    y[:, lan] = 1\n",
        "    y = y.astype('float32')\n",
        "    y_pred = cnn_model.predict(x)\n",
        "    p, r, f = met(y, y_pred)\n",
        "    ps.append(p.numpy())\n",
        "    rs.append(r.numpy())\n",
        "    fs.append(f.numpy())\n",
        "    #print(\"language: \", class_to_language[lan], \"precision: \", p.numpy(), \"recall: \", r.numpy(), \"f1: \", f.numpy())"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 235/235 [00:58<00:00,  4.02it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jFoYvQVzg0C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_metrics = pd.DataFrame(\n",
        "    {'precision': ps,\n",
        "     'recall': rs,\n",
        "     'f1': fs\n",
        "    })"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXV6tZ4Dzh4L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "cfed69f4-7ed6-423a-d1f5-918cf820211f"
      },
      "source": [
        "metrics = raw_metrics.rename(class_to_language, axis='index')\n",
        "bad_quality_metrics = metrics[metrics.f1 < 0.7]\n",
        "bad_quality_metrics"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ace</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.006</td>\n",
              "      <td>0.011928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>afr</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.060</td>\n",
              "      <td>0.113208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>als</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>amh</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.006</td>\n",
              "      <td>0.011928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ang</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>yid</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.003992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>yor</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.032</td>\n",
              "      <td>0.062016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zea</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.280</td>\n",
              "      <td>0.437500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zh-yue</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zho</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>235 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        precision  recall        f1\n",
              "ace           1.0   0.006  0.011928\n",
              "afr           1.0   0.060  0.113208\n",
              "als           0.0   0.000  0.000000\n",
              "amh           1.0   0.006  0.011928\n",
              "ang           0.0   0.000  0.000000\n",
              "...           ...     ...       ...\n",
              "yid           1.0   0.002  0.003992\n",
              "yor           1.0   0.032  0.062016\n",
              "zea           1.0   0.280  0.437500\n",
              "zh-yue        0.0   0.000  0.000000\n",
              "zho           0.0   0.000  0.000000\n",
              "\n",
              "[235 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zstxcPVgfUig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lab = labels.set_index('Label')\n",
        "bad_quality_labels = lab.loc[lab.index.intersection(bad_quality_metrics.index)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaImgEefHae0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "outputId": "14590ea2-631c-4c00-f440-186677a42149"
      },
      "source": [
        "res = pd.merge(bad_quality_labels.reset_index(), bad_quality_metrics.reset_index()).set_index('index')\n",
        "res"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Wiki Code</th>\n",
              "      <th>ISO 369-3</th>\n",
              "      <th>Language family</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ace</th>\n",
              "      <td>Achinese</td>\n",
              "      <td>ace</td>\n",
              "      <td>ace</td>\n",
              "      <td>Austronesian</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.006</td>\n",
              "      <td>0.011928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>afr</th>\n",
              "      <td>Afrikaans</td>\n",
              "      <td>af</td>\n",
              "      <td>afr</td>\n",
              "      <td>Indo-European</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.060</td>\n",
              "      <td>0.113208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>als</th>\n",
              "      <td>Alemannic German</td>\n",
              "      <td>als</td>\n",
              "      <td>gsw</td>\n",
              "      <td>Indo-European</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>amh</th>\n",
              "      <td>Amharic</td>\n",
              "      <td>am</td>\n",
              "      <td>amh</td>\n",
              "      <td>Afro-Asiatic</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.006</td>\n",
              "      <td>0.011928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ang</th>\n",
              "      <td>Old English</td>\n",
              "      <td>ang</td>\n",
              "      <td>ang</td>\n",
              "      <td>Indo-European</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>yid</th>\n",
              "      <td>Yiddish</td>\n",
              "      <td>yi</td>\n",
              "      <td>yid</td>\n",
              "      <td>Indo-European</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.003992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>yor</th>\n",
              "      <td>Yoruba</td>\n",
              "      <td>yo</td>\n",
              "      <td>yor</td>\n",
              "      <td>Niger-Congo</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.032</td>\n",
              "      <td>0.062016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zea</th>\n",
              "      <td>Zeeuws</td>\n",
              "      <td>zea</td>\n",
              "      <td>zea</td>\n",
              "      <td>Indo-European</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.280</td>\n",
              "      <td>0.437500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zh-yue</th>\n",
              "      <td>Cantonese</td>\n",
              "      <td>zh-yue</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Sino-Tibetan</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zho</th>\n",
              "      <td>Standard Chinese</td>\n",
              "      <td>zh</td>\n",
              "      <td>zho</td>\n",
              "      <td>Sino-Tibetan</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>234 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 English Wiki Code ISO 369-3  ... precision  recall        f1\n",
              "index                                         ...                            \n",
              "ace             Achinese       ace       ace  ...       1.0   0.006  0.011928\n",
              "afr            Afrikaans        af       afr  ...       1.0   0.060  0.113208\n",
              "als     Alemannic German       als       gsw  ...       0.0   0.000  0.000000\n",
              "amh              Amharic        am       amh  ...       1.0   0.006  0.011928\n",
              "ang         Old English        ang       ang  ...       0.0   0.000  0.000000\n",
              "...                  ...       ...       ...  ...       ...     ...       ...\n",
              "yid              Yiddish        yi       yid  ...       1.0   0.002  0.003992\n",
              "yor               Yoruba        yo       yor  ...       1.0   0.032  0.062016\n",
              "zea               Zeeuws       zea       zea  ...       1.0   0.280  0.437500\n",
              "zh-yue         Cantonese    zh-yue       NaN  ...       0.0   0.000  0.000000\n",
              "zho     Standard Chinese        zh       zho  ...       0.0   0.000  0.000000\n",
              "\n",
              "[234 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUkII9aS9iK1",
        "colab_type": "code",
        "outputId": "a205b2bd-8a69-410b-8e72-3b4865cfadfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        }
      },
      "source": [
        "print(x_train[x_train.sc == language_to_class['bod']].iloc[0].sent)\n",
        "print(x_train[x_train.sc == language_to_class['hrv']].iloc[0].sent)\n",
        "print(x_train[x_train.sc == language_to_class['jpn']].iloc[0].sent)\n",
        "print(x_train[x_train.sc == language_to_class['khm']].iloc[0].sent)\n",
        "print(x_train[x_train.sc == language_to_class['lzh']].iloc[0].sent)\n",
        "print(x_train[x_train.sc == language_to_class['tha']].iloc[0].sent)\n",
        "print(x_train[x_train.sc == language_to_class['wuu']].iloc[0].sent)\n",
        "print(x_train[x_train.sc == language_to_class['zho']].iloc[0].sent)\n",
        "print(x_train[x_train.sc == language_to_class['zh-yue']].iloc[0].sent)"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "༡༩༣༥ལོར་ཞང་པོ་དང་ལྷན་དུ་ནན་ཅིང་དུ་སློབ་སྦྱོང་མནང་བར་ཕེབས་རྩིས་བྱས། ཕྱི་ལོར་ཀྲུང་དབྱང་ཆབ་སྲིད་སློབ་གྲྭས་བཙུགས་པའི་མོང་བོད་སློབ་གྲྭར་སློབ་སྦྱོང་མནང་བ་དང་དེ་དུས་ཅང་ཅེ་ཧྲེ་སློབ་གྲྭའི་ཞའོ་ཀྲང་གི་འགན་བཞེས་ཀྱི་ཡོད། ༡༩༣༧ལོར་རི་འགོག་དམག་འཁྲུག་ལངས་རྐྱེན་སློབ་གྲྭ་དེ་ཨན་ཧུའི་ཅུའུ་ཧ་རི་བོ་ནས་ཧུའུ་ནན་ཀྲེ་ཅང་དུ་སྤོ་དགོས་བྱུང་། དེའི་རིང་ལ་ཁོང་གི《འུ་ཧན་ལ་བསྐྱོད་ལམ》ཞེས་པའི་རྩོམ་ཡིག《ཀྲེ་ཅང་ཉིན་རེའི་ཚགས་པར》སྟེང་འགོད་མནང་བ་རེད། དེ་དུས་ཁོང་དང་གཡོན་ཕྱོགས་ཀྱི་དུས་དེབ། དེ་བཞིན་མི་སྣར་ཐོག་མའི་རྒྱུས་ལོན་བྱུང་། ༡༩༣༨ལོར་སློབ་གྲྭ་དེ་ཁྲུང་ཆིང་དུ་སྤོས། དེ་ནས་ཟུང་ཁོང་གིས་མ་ཁེ་སི་དང་ལི་ཉིང་གི་བརྩམས་ཆོས་མང་དུ་བཀླགས་རྐྱེན་ཁོང་གི་ལྟ་བ་ལི་ཉིང་གི《མི་རིགས་རང་གཙོ་དབང་ཆའི་སྐོར་གླེང་བ》ཞེས་པ་དང་ཉེ་བར་གྱུར། དེའི་ཕྱི་ལོར་ཕུན་དབང་གིས་དཀོན་མཆོག་བཀྲ་ཤིས། ངག་དབང་སྐལ་བཟང་། ཤེས་རབ། མ་རྒྱལ་དོན་གྲུབ་ལ་སོགས་པའི་སློབ་ཕྲུག་དང་མཉམ་དུ༼བོད་རིགས་གུང་ཁྲན་རིང་ལུགས་གསར་བརྗེའི་འགུལ་བསྐྱོད་ཚོགས་ཆུང༽བཙུགས་མནང་བ་དང་། ཧྲུའུ་ཅིའི་འགན་བཞེས། དེ་ནས་ཁྲུང་ཆིང་བཅའ་སྡོད་དམག་སྡེ་བརྒྱད་པའི་དོན་གཅོད་ཁང་དང་གསང་བའི་ཐོག་ནས་འབྲེལ་གཏུག་མནང་། ད་དུང་ཚོགས་ཆུང་དེའི་མིང་ཐོག་ནས་སི་ཏའ་ལིན་དང་མའོ་ཙི་ཏུང་ལ་འཕྲིན་ཡིག་བསྐུར་མནང་མཛད། ཕུན་ཚོགས་དབང་རྒྱལ་གྱིས《རྒྱལ་སྤྱིའི་གླུ》《ཀྲུང་གོའི་རྒྱལ་གླུ》སོགས་བོད་ཡིག་ཏུ་ཐོག་མར་བསྒྱུར། ༡༩༤༠ལོར་སློབ་གྲྭ་ནས་ཕྱིར་འབུད་བྱས། དེ་ནས་ཡེ་ཅན་ཡིང་གི་རོག་སྐྱོར་འོག་མ་ཁེ་སི་དང་ལེ་ཉིང་གི་བརྩམས་ཆོས་མང་དག་ཅིག་ཉོས་ནས་བོད་དུ་ལོག་ཕེབས། ༡༩༤༢ལོར་ཁོར་གིས་དར་རྩེ་མདོ་རུ༼སྐར་མ་མེའི་ཚོགས་པ༽བཙུགས་མནང་བ་དང་། དེའི་ཁོངས་མི་ལ་ངག་དབང་དང་། ཏའོ་ཏང་། དགྲ་འདུལ། ཚང་ཆོས་གྲགས་སོགས་བྱུང་། དེ་ནས་ཚོགས་པ་དེ་གོ་མིན་ཏང་གི་ཤེས་རྟོགས་བྱུང་རྗེས་ཕུན་དབང་དང་ཏའོ་ཏང་ལྷ་སར་ཕེབས་ནས༼གངས་ལྗོངས་བོད་རིགས་གུང་ཁྲན་རིང་ལུགས་གསར་བརྗེའི་ཚོགས་ཆུང༽བཙུགས། ཁོང་ཚོས་བསོད་ཁང·དབང་ཆེན་དགེ་ལེགས་བཀའ་བློན་བརྒྱུད་ནས་བཀའ་ཤག་སྲིད་གཞུང་ལ་གསར་བརྗེའི་ལས་འགུལ་སྤེལ་དགོས་པའི་རེ་བ་ཞུས་ཀྱང་སྟོང་ཟད་དུ་ཕྱིན། ༡༩༤༤ལོར་རྒྱ་གར་དུ་ཕེབས། ༡༩༤༥ལོར་ཕུན་དབང་ཡུན་ནན་བདེ་ཆེན་རྫོང་དུ་ཕེབས་ནས༼ཤར་བོད་མི་དམངས་རང་སྐྱོངས་ལྷན་ཚོགས༽གསར་བཙུགས་མཛད་པས་སྲིད་གཞུང་གིས་འཛིན་བཟུང་བཀའ་རྒྱ་བཏང་། ༡༩༧༤ལོར་ཕུན་དབང་ཆབ་མདོ་ཁུལ་དུ་ཕེབས་ནས་གཡུ་ཐོག·བཀྲ་ཤིས་དོན་གྲུབ་ཀྱིས་རོག་སྐྱོར་འོག་ལྷ་སར་ཕེབས་ཐུབ་པ་བྱུང་། ༡༩༤༩ལོར་ཕུན་དབང་སོགས་ཀྲུང་གོ་གུང་ཁྲན་ཏང་གི་གསང་བའི་ལས་དོན་སྒྲུབ་མཁན་དང་འབྲེལ་བ་ཡོད་པ་ཤེས་རྟོགས་བྱུང་ནས་བཀའ་ཤག་སྲིད་གཞུང་གིས་བོད་ནས་ཕྱིར་འབུད་བྱས། ལོ་དེའི་སྤྱི་ཟླ་༩པར་ཁོང་རྣམས་རྒྱ་གར་བརྒྱུད་ནས་ཁུན་མིང་དུ་ཕེབས། ཁོང་གིས་ས་དེ་གའི་ཀྲུང་གོ་གུང་ཁྲན་ཏང་རྩ་འཛུགས་དང་འབྲེལ་བ་བྱས་མཐར་གུང་ཁྲན་ཏང་ཡོན་ཞིག་ཏུ་གྱུར། དེ་རྗེས་འབའ་ཐང་ལ་ལོག་ཕེབས་ནས༼ཀྲུང་གོ་གུང་ཁྲན་ཏང་ཁམས་བོད་ས་མཚམས་ལས་དོན་ཨུ་ཡོན་ལྷན་ཁང༽༼ཤར་བོད་དམངས་གཙོའི་ན་གཞོན་ལྷན་ཚོགས༽གསར་འཛུགས་མཛད་པ་དང་ཧྲུའུ་ཅིའི་འགན་བཞེས།\n",
            "Oružani napad Sila Osovine na Jugoslaviju 6. travnja 1941. bio je iznenadan, a ona je tada kao institucija nestala slomom njene vojne sile. Talijanska okupacijska vojska došla je na Rab 17. travnja, a ubrzo zatim formiran je poseban oblik okupatorske vlasti - Civilni komesarijat. Rimskim ugovorom 18. svibnja 1941. godine, zaključenim između Mussolinija i Pavelića, Rab je anektiran fašističkoj Italiji. Sredinom i krajem ljeta 1943. godine utjecaj partizana na otoku stalno jača. Nakon kapitulacije Italije, do tada ilegalni partizanski NOO preuzimaju cjelokupnu upravnu i sudsku vlast na otoku. Njemačke jedinice zaposjele su Rab u drugoj polovici mjeseca ožujka 1944. godine. Kasnije je otok ustupljen NDH. Partizanska vlast (NOO) ponovno je uspostavljena nakon dolaska partizanskih jedinica i zaposjedanja otoka 12. travnja 1945. godine. Od tada do slobodnih izbora 1990. godine Rab je u sastavu SFRJ, a nakon slobodnih izbora, u sastavu neovisne i slobodne Republike Hrvatske.\n",
            "エノが行きがかりでバスに乗ってしまい、気分が悪くなった際に助けるが、今すぐバスを降りたいと運転手に頼む際、本当のことを言ってしまうと彼女が恥ずかしい思いをすると察して「僕ウンコしたいんです!!」と言ってバスを降りた。エノは内心「私もしたいみたいじゃないの」と思うも、別れ際にエノの髪を「ふわふわのお菓子みたい」と言い、この台詞に憧れていたエノに強い衝撃を与えた。この話を聞いたリコは、以後彼のことを『ウンコ王子』または『ウンコ』というあだ名で呼ぶようになったが、エノは普通に「戸田くん」と呼んでいる。\n",
            "ស្គរអារក្សជាឧបករណ៍ភ្លេងទះ តប់ដោយបាតដៃ។ ស្គរនេះមានឈ្មោះច្រើនគឺ ស្គរដៃ ស្គរអារក្ស ស្គរការ ស្គរដី ស្គរអាយ៉ៃ។ គេយកវាទៅប្រគំក្នុងវង់ភ្លេងអារក្ស វង់ភ្លេងការ វង់ភ្លេងអាយ៉ៃ និងវង់ភ្លេងកំដរពេលរាំលេងកំសាន្ត។\n",
            "武漢市，亦稱以漢，乃中華鄂省之會，亦為七大都市於中華之中原也。方八千四百六十七公里，於西元二〇一〇年計口九百七十八萬有奇。大江與漢水會此，分之三鎮，是為武昌、漢陽、漢口也。傳唐人李白至此，題詩曰：「黃鶴樓中吹玉笛，江城五月落梅花」，故亦稱之「江城」。武漢達於晚清，至民國，譽為「東方芝加哥」。經民國至共和國之初而盛。中華民國亦起此也。\n",
            "ถนนเจริญกรุง (อักษรโรมัน: Thanon Charoen Krung) เริ่มตั้งแต่ถนนสนามไชยถึงแม่น้ำเจ้าพระยาที่ถนนตก กรุงเทพมหานคร เป็นถนนรุ่นแรกที่ใช้เทคนิคการสร้างแบบตะวันตก ปัจจุบันผ่านพื้นที่เขตพระนคร เขตป้อมปราบศัตรูพ่าย เขตสัมพันธวงศ์ เขตบางรัก เขตสาทร และเขตบางคอแหลม\n",
            "UNC有得一只历史悠久个'诚信守则'。渠是由学堂个诚信法庭（Honor Court）来执行个，通过处理各种有关学生个学习帮行为浪个违规，保证了学校帮社区个权益。教授勿能因为学生仔被捉着作弊而通过任何方式处罚学生（譬如讲让迭个学生勿及格），渠必须上报畀学生总检察长。只有当由学生组成个诚信法庭裁决有罪以后，格学生再可以被惩罚。\n",
            "胡赛尼本人和小说的主人公阿米尔一样，都是出生在阿富汗首都喀布尔，少年时代便离开了这个国家。胡赛尼直到2003年小说出版之后才首次回到已经离开27年的祖国。他在苏联入侵时离开了阿富汗，而他的很多童年好友在阿富汗生活艰难，还有一些表亲离开人世，其中一位在童年时代和他一起放风筝的表兄弟就是在逃离阿富汗时死在了油罐车中（这一情节在《追风筝的人》中也有描写），而这位表兄弟的父亲也被人枪杀；因此胡赛尼总是怀有幸存者所特有的一种内疚心态，这种情感在小说中也有体现。很多人因此认为这部小说有些自传色彩。胡赛尼则表示小说中确实有一部分内容是根据自己的经历创作的，他和故事主人公也有很多相似点，但是一些内容被他刻意地模糊处理了。尽管和主人公的经历有诸多的相似点，胡赛尼仍然坚称小说情节确实是虚构的。之后胡赛尼在创作他的第二部小说《灿烂千阳》时把主人公设定为女性，称“这样应该就能一劳永逸地解决人们关于‘自传’的问题了”。\n",
            "1998年11月，一位中年女人自創燒炭自殺，將自己同燒烤爐封響沖涼房裏面。由於呢種方法之前，未有先例，相信係女死者以佢化工背景自創。因為咁，呢種自殺方法引起好多報紙大幅報導，令到好多模仿以呢種方式自殺。更適逢1997年後香港經濟低潮，有唔少人失業兼負債纍纍，以呢種方式自尋短見。結果短短兩個月就成為香港第三多人用嘅自殺方法，排響跳樓同吊頸之後。到咗第2001年，呢個方法多人用到變咗第二位。由於各傳媒咁樣繪形繪聲報導，大陸、台灣、日本都有唔少人仿效。\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dH862g-VYj8J",
        "colab_type": "text"
      },
      "source": [
        "# Fix Chinese langs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yltabFr0UYF_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_features_chinese = 10000\n",
        "\n",
        "## Tokenize the sentences\n",
        "tokenizer_chinese = Tokenizer(num_words=max_features_chinese, char_level=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuUBpVDruwFi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "outputId": "0f30e405-ee50-49ca-b46d-61abf17f155f"
      },
      "source": [
        "x_train_bad = x_train.set_index('lang')\n",
        "bad_quality_langs_train = x_train_bad.loc[bad_quality_metrics.index]\n",
        "bad_quality_langs_train"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sent</th>\n",
              "      <th>sc</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lang</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>bod</th>\n",
              "      <td>༡༩༣༥ལོར་ཞང་པོ་དང་ལྷན་དུ་ནན་ཅིང་དུ་སློབ་སྦྱོང་མ...</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bod</th>\n",
              "      <td>བཀའ་རྩ་གསལ་བསྒྲགས་དངོས་ཤོག་གྲངས་ ༡༢ ལ་བཀོད་ཡོད...</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bod</th>\n",
              "      <td>སྤྱི་ལོ་༡༩༥༣ལོའི་ཟླ་བ་༨པར་སྨན་པས་ཁོང་གི་རྐང་པ་...</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bod</th>\n",
              "      <td>ཐ་མལ་དུ་གནས་པའི་མི་དར་མའི་སྙིང་གི་ཕར་ཚད་ནི་དུས...</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bod</th>\n",
              "      <td>ཀློང་རྡོལ་བླ་མ་རིན་པོ་ཆེའི་བརྟག་ཐབས་ནང་སྤོས་ཤེ...</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zho</th>\n",
              "      <td>赛里木湖属于封闭型的断陷湖，是地壳下沉形成洼地，由四周的高山雪水历百万年慢慢汇聚而成。如今主...</td>\n",
              "      <td>234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zho</th>\n",
              "      <td>约瑟夫·维萨里奥诺维奇·泽·朱加什维利生于俄罗斯帝国哥里，毕业于梯弗里斯神学院。成为马克思主...</td>\n",
              "      <td>234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zho</th>\n",
              "      <td>和印度其他地方一样，板球也是孟买最为流行的一项运动。板球比赛通常在遍布全市的操场上进行。后院...</td>\n",
              "      <td>234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zho</th>\n",
              "      <td>1994年，邓斯特还与薇诺娜·瑞德和克萊兒·丹妮絲一起出演了同名原著改编的电影《小妇人》，该...</td>\n",
              "      <td>234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zho</th>\n",
              "      <td>4月8日首度訪泰，在新聞發布會現場超過200名記者爭相採訪，泰國主要的7頻道及報章雜誌等均大...</td>\n",
              "      <td>234</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4500 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   sent   sc\n",
              "lang                                                        \n",
              "bod   ༡༩༣༥ལོར་ཞང་པོ་དང་ལྷན་དུ་ནན་ཅིང་དུ་སློབ་སྦྱོང་མ...   22\n",
              "bod   བཀའ་རྩ་གསལ་བསྒྲགས་དངོས་ཤོག་གྲངས་ ༡༢ ལ་བཀོད་ཡོད...   22\n",
              "bod   སྤྱི་ལོ་༡༩༥༣ལོའི་ཟླ་བ་༨པར་སྨན་པས་ཁོང་གི་རྐང་པ་...   22\n",
              "bod   ཐ་མལ་དུ་གནས་པའི་མི་དར་མའི་སྙིང་གི་ཕར་ཚད་ནི་དུས...   22\n",
              "bod   ཀློང་རྡོལ་བླ་མ་རིན་པོ་ཆེའི་བརྟག་ཐབས་ནང་སྤོས་ཤེ...   22\n",
              "...                                                 ...  ...\n",
              "zho   赛里木湖属于封闭型的断陷湖，是地壳下沉形成洼地，由四周的高山雪水历百万年慢慢汇聚而成。如今主...  234\n",
              "zho   约瑟夫·维萨里奥诺维奇·泽·朱加什维利生于俄罗斯帝国哥里，毕业于梯弗里斯神学院。成为马克思主...  234\n",
              "zho   和印度其他地方一样，板球也是孟买最为流行的一项运动。板球比赛通常在遍布全市的操场上进行。后院...  234\n",
              "zho   1994年，邓斯特还与薇诺娜·瑞德和克萊兒·丹妮絲一起出演了同名原著改编的电影《小妇人》，该...  234\n",
              "zho   4月8日首度訪泰，在新聞發布會現場超過200名記者爭相採訪，泰國主要的7頻道及報章雜誌等均大...  234\n",
              "\n",
              "[4500 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXhcTGMaYZXt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_X_chinese, train_Y_chinese), (val_X_chinese, val_Y_chinese) = \\\n",
        "prepare_data(bad_quality_langs_train, bad_quality_langs_train.sc, tokenizer_chinese, maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IA91PJA_Nvio",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a26fcd30-9e03-48cf-bdb8-b0ad38ee7a00"
      },
      "source": [
        "chinese_labels_dict = {lang:index for index, lang in enumerate(set(train_Y_chinese))}\n",
        "chinese_labels_dict"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{22: 6, 77: 4, 92: 8, 99: 0, 123: 7, 207: 5, 227: 1, 233: 2, 234: 3}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubiHl-tGxu89",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dummy_y_train_chinese = to_categorical([chinese_labels_dict[lan] for lan in train_Y_chinese])\n",
        "dummy_y_val_chinese = to_categorical([chinese_labels_dict[lan] for lan in val_Y_chinese])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1Px5m0yyLUA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "43380ac7-7c0f-4020-f1b8-f5977af1b759"
      },
      "source": [
        "cnn_model_chinese = Sequential()\n",
        "cnn_model_chinese.add(Embedding(max_features, embed_size,input_shape=(maxlen,)))\n",
        "cnn_model_chinese.add(Conv1D(256, 5, activation='relu', input_shape=(embed_size,)))\n",
        "cnn_model_chinese.add(MaxPooling1D(5))\n",
        "cnn_model_chinese.add(Dropout(0.2))\n",
        "cnn_model_chinese.add(Conv1D(256, 5, activation='relu'))\n",
        "cnn_model_chinese.add(MaxPooling1D(5))\n",
        "cnn_model_chinese.add(Flatten())\n",
        "cnn_model_chinese.add(Dense(512, activation=\"relu\"))\n",
        "cnn_model_chinese.add(Dropout(0.2))\n",
        "cnn_model_chinese.add(Dense(len(dummy_y_train_chinese[0]), activation='softmax'))\n",
        "cnn_model_chinese.summary()"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 200, 300)          19247100  \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 196, 256)          384256    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_4 (MaxPooling1 (None, 39, 256)           0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 39, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 35, 256)           327936    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_5 (MaxPooling1 (None, 7, 256)            0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 1792)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 512)               918016    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 9)                 4617      \n",
            "=================================================================\n",
            "Total params: 20,881,925\n",
            "Trainable params: 20,881,925\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlFTZRq8ya9i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn_model_chinese.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', f1, recall, precision])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QiHi0eYrgaU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "d0dbfbb9-ed23-493b-8018-337b391aa85e"
      },
      "source": [
        "cnn_model_chinese.fit(train_X_chinese, dummy_y_train_chinese, batch_size=128, epochs=10, \n",
        "              validation_data=(val_X_chinese, dummy_y_val_chinese))"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "8/8 [==============================] - 2s 237ms/step - loss: 0.0096 - accuracy: 0.9970 - f1: 0.9973 - recall: 0.9958 - precision: 0.9988 - val_loss: 0.2196 - val_accuracy: 0.9489 - val_f1: 0.9477 - val_recall: 0.9467 - val_precision: 0.9488\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 2s 237ms/step - loss: 0.0070 - accuracy: 0.9985 - f1: 0.9981 - recall: 0.9975 - precision: 0.9988 - val_loss: 0.2061 - val_accuracy: 0.9600 - val_f1: 0.9600 - val_recall: 0.9600 - val_precision: 0.9600\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 2s 239ms/step - loss: 0.0047 - accuracy: 0.9995 - f1: 0.9991 - recall: 0.9985 - precision: 0.9998 - val_loss: 0.2146 - val_accuracy: 0.9556 - val_f1: 0.9544 - val_recall: 0.9533 - val_precision: 0.9555\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 2s 233ms/step - loss: 0.0046 - accuracy: 0.9990 - f1: 0.9988 - recall: 0.9983 - precision: 0.9993 - val_loss: 0.2148 - val_accuracy: 0.9556 - val_f1: 0.9556 - val_recall: 0.9556 - val_precision: 0.9556\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 2s 240ms/step - loss: 0.0031 - accuracy: 1.0000 - f1: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.2138 - val_accuracy: 0.9578 - val_f1: 0.9588 - val_recall: 0.9578 - val_precision: 0.9599\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 2s 244ms/step - loss: 0.0027 - accuracy: 0.9998 - f1: 0.9996 - recall: 0.9995 - precision: 0.9997 - val_loss: 0.2099 - val_accuracy: 0.9600 - val_f1: 0.9611 - val_recall: 0.9600 - val_precision: 0.9621\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 2s 238ms/step - loss: 0.0025 - accuracy: 0.9998 - f1: 0.9998 - recall: 0.9998 - precision: 0.9998 - val_loss: 0.2082 - val_accuracy: 0.9600 - val_f1: 0.9588 - val_recall: 0.9578 - val_precision: 0.9599\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 2s 233ms/step - loss: 0.0034 - accuracy: 0.9990 - f1: 0.9990 - recall: 0.9990 - precision: 0.9990 - val_loss: 0.2101 - val_accuracy: 0.9533 - val_f1: 0.9565 - val_recall: 0.9533 - val_precision: 0.9597\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 2s 235ms/step - loss: 0.0018 - accuracy: 1.0000 - f1: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.2107 - val_accuracy: 0.9600 - val_f1: 0.9611 - val_recall: 0.9600 - val_precision: 0.9621\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 2s 240ms/step - loss: 0.0015 - accuracy: 1.0000 - f1: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.2198 - val_accuracy: 0.9600 - val_f1: 0.9600 - val_recall: 0.9600 - val_precision: 0.9600\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb8e91b6da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWwS0BKMsUGO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "c52f78fc-dfb3-4fab-bc9d-e70ff63a3367"
      },
      "source": [
        "ps_chinese = []\n",
        "rs_chinese = []\n",
        "fs_chinese = []\n",
        "short_len = len(set(train_Y_chinese))\n",
        "\n",
        "for lan in set(train_Y_chinese):\n",
        "    x_t = x_test[x_test['sc'] == lan]\n",
        "    x = convert(x_t, tokenizer_chinese, maxlen)\n",
        "    y = np.zeros((x.shape[0], short_len))\n",
        "    y[:, chinese_labels_dict[lan]] = 1\n",
        "    y = y.astype('float32')\n",
        "    y_pred = cnn_model_chinese.predict(x)\n",
        "    p, r, f = met(y, y_pred)\n",
        "    ps_chinese.append(p.numpy())\n",
        "    rs_chinese.append(r.numpy())\n",
        "    fs_chinese.append(f.numpy())\n",
        "    print(\"language: \", class_to_language[lan], \"precision: \", p.numpy(), \"recall: \", r.numpy(), \"f1: \", f.numpy())"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "language:  khm precision:  1.0 recall:  0.966 f1:  0.98270595\n",
            "language:  wuu precision:  1.0 recall:  0.896 f1:  0.94514763\n",
            "language:  zh-yue precision:  1.0 recall:  0.928 f1:  0.96265554\n",
            "language:  zho precision:  1.0 recall:  0.936 f1:  0.9669421\n",
            "language:  hrv precision:  1.0 recall:  0.992 f1:  0.99598384\n",
            "language:  tha precision:  1.0 recall:  0.988 f1:  0.9939637\n",
            "language:  bod precision:  1.0 recall:  0.998 f1:  0.99899894\n",
            "language:  lzh precision:  1.0 recall:  0.994 f1:  0.996991\n",
            "language:  jpn precision:  1.0 recall:  0.998 f1:  0.99899894\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qimQESgMQpVG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}