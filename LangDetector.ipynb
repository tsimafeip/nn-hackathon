{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of hackaton.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpmSbtrCklRB",
        "colab_type": "code",
        "outputId": "a29eea6c-1605-4786-f3f3-67b839d15768",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNLhWWCxYfLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "import scipy\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import logging\n",
        "import multiprocessing\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8IzA7Rx-VzU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Bidirectional, GlobalMaxPooling1D, GlobalMaxPool1D, MaxPooling1D, Flatten, concatenate\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras import initializers, regularizers, constraints, optimizers, layers\n",
        "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1vZGIRYYR9G",
        "colab_type": "text"
      },
      "source": [
        "# Hanna's data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFKrCtLZYBcV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('./drive/My Drive/hackaton/wili-2018.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('./')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcwIDfWAYOUl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path = '/content/drive/My Drive/Colab Notebooks/Hackathon/'\n",
        "wili_data_path = ''\n",
        "\n",
        "x_train_path = wili_data_path + 'x_train.txt'\n",
        "x_test_path = wili_data_path + 'x_test.txt'\n",
        "y_train_path = wili_data_path + 'y_train.txt'\n",
        "y_test_path = wili_data_path + 'y_test.txt'\n",
        "labels_path = wili_data_path + 'labels.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc94smEhjbA_",
        "colab_type": "text"
      },
      "source": [
        "# Download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75potnAshWU4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path = '/content/drive/My Drive/Colab Notebooks/Hackathon/'\n",
        "wili_data_path = data_path + 'wili-2018/'\n",
        "\n",
        "x_train_path = wili_data_path + 'x_train.txt'\n",
        "x_test_path = wili_data_path + 'x_test.txt'\n",
        "y_train_path = wili_data_path + 'y_train.txt'\n",
        "y_test_path = wili_data_path + 'y_test.txt'\n",
        "labels_path = wili_data_path + 'labels.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhsiujWS3QR8",
        "colab_type": "code",
        "outputId": "b808d56b-af9e-4226-db17-dc403d34b1d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "labels = pd.read_csv(labels_path, sep=';')\n",
        "labels = labels.drop(labels=['German', 'Writing system', 'Remarks', 'Synonyms'], axis=1)\n",
        "labels"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>English</th>\n",
              "      <th>Wiki Code</th>\n",
              "      <th>ISO 369-3</th>\n",
              "      <th>Language family</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ace</td>\n",
              "      <td>Achinese</td>\n",
              "      <td>ace</td>\n",
              "      <td>ace</td>\n",
              "      <td>Austronesian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>afr</td>\n",
              "      <td>Afrikaans</td>\n",
              "      <td>af</td>\n",
              "      <td>afr</td>\n",
              "      <td>Indo-European</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>als</td>\n",
              "      <td>Alemannic German</td>\n",
              "      <td>als</td>\n",
              "      <td>gsw</td>\n",
              "      <td>Indo-European</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>amh</td>\n",
              "      <td>Amharic</td>\n",
              "      <td>am</td>\n",
              "      <td>amh</td>\n",
              "      <td>Afro-Asiatic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ang</td>\n",
              "      <td>Old English</td>\n",
              "      <td>ang</td>\n",
              "      <td>ang</td>\n",
              "      <td>Indo-European</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>230</th>\n",
              "      <td>yid</td>\n",
              "      <td>Yiddish</td>\n",
              "      <td>yi</td>\n",
              "      <td>yid</td>\n",
              "      <td>Indo-European</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>231</th>\n",
              "      <td>yor</td>\n",
              "      <td>Yoruba</td>\n",
              "      <td>yo</td>\n",
              "      <td>yor</td>\n",
              "      <td>Niger-Congo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>232</th>\n",
              "      <td>zea</td>\n",
              "      <td>Zeeuws</td>\n",
              "      <td>zea</td>\n",
              "      <td>zea</td>\n",
              "      <td>Indo-European</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>233</th>\n",
              "      <td>zh-yue</td>\n",
              "      <td>Cantonese</td>\n",
              "      <td>zh-yue</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Sino-Tibetan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>234</th>\n",
              "      <td>zho</td>\n",
              "      <td>Standard Chinese</td>\n",
              "      <td>zh</td>\n",
              "      <td>zho</td>\n",
              "      <td>Sino-Tibetan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>235 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Label           English Wiki Code ISO 369-3 Language family\n",
              "0       ace          Achinese       ace       ace    Austronesian\n",
              "1       afr         Afrikaans        af       afr   Indo-European\n",
              "2       als  Alemannic German       als       gsw   Indo-European\n",
              "3       amh           Amharic        am       amh    Afro-Asiatic\n",
              "4       ang      Old English        ang       ang   Indo-European\n",
              "..      ...               ...       ...       ...             ...\n",
              "230     yid           Yiddish        yi       yid   Indo-European\n",
              "231     yor            Yoruba        yo       yor     Niger-Congo\n",
              "232     zea            Zeeuws       zea       zea   Indo-European\n",
              "233  zh-yue         Cantonese    zh-yue       NaN    Sino-Tibetan\n",
              "234     zho  Standard Chinese        zh       zho    Sino-Tibetan\n",
              "\n",
              "[235 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpH6qYnlYrBN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_to_language = labels.Label.astype(str).to_dict()\n",
        "language_to_class = {v: k for k, v in class_to_language.items()}\n",
        "num_classes = len(class_to_language)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDFr3-rKmDdv",
        "colab_type": "code",
        "outputId": "5d515033-af6d-43d1-afc1-f937de9e93c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(list(language_to_class.items())[:5])\n",
        "num_classes"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('ace', 0), ('afr', 1), ('als', 2), ('amh', 3), ('ang', 4)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "235"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBqkjck1Yc7q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_data():\n",
        "    with open(x_train_path) as f:\n",
        "        mylist = f.read().splitlines() \n",
        "    x_train = pd.DataFrame(mylist, columns=[\"sent\"])\n",
        "    with open(x_test_path) as f:\n",
        "        mylist = f.read().splitlines() \n",
        "    x_test = pd.DataFrame(mylist, columns=[\"sent\"])\n",
        "\n",
        "    with open(y_train_path) as f:\n",
        "        mylist = f.read().splitlines() \n",
        "    y_train = []\n",
        "    for lan in mylist:\n",
        "        y_train.append(language_to_class[lan])\n",
        "    y_train = pd.DataFrame(y_train)\n",
        "    with open(y_test_path) as f:\n",
        "        mylist = f.read().splitlines()\n",
        "\n",
        "    y_test = []\n",
        "    for lan in mylist:\n",
        "        y_test.append(language_to_class[lan])\n",
        "    y_test = pd.DataFrame(y_test)\n",
        "    \n",
        "    return (x_train, y_train), (x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhKRW6V8hhIc",
        "colab_type": "code",
        "outputId": "25583ba5-7d6b-4f95-9bb7-74d1e26bdaec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = read_data()\n",
        "\n",
        "print(x_train.head())\n",
        "print(y_train.head())\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                sent\n",
            "0  Klement Gottwaldi surnukeha palsameeriti ning ...\n",
            "1  Sebes, Joseph; Pereira Thomas (1961) (på eng)....\n",
            "2  भारतीय स्वातन्त्र्य आन्दोलन राष्ट्रीय एवम क्षे...\n",
            "3  Après lo cort periòde d'establiment a Basilèa,...\n",
            "4  ถนนเจริญกรุง (อักษรโรมัน: Thanon Charoen Krung...\n",
            "     0\n",
            "0   52\n",
            "1  198\n",
            "2  124\n",
            "3  155\n",
            "4  207\n",
            "(117500, 1)\n",
            "(117500, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zcUciRigFYu",
        "colab_type": "code",
        "outputId": "af506a98-67ed-462e-9ea5-214ad7eb7835",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "lens = x_train.sent.str.split(' ').str.len().values\n",
        "plt.hist(lens, bins=np.linspace(0,1000,20), facecolor='blue', alpha=0.9)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xdCSiHnhlX1",
        "colab_type": "text"
      },
      "source": [
        "# Experiment on small dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFTqOQmChknq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# small_dataset = pd.read_csv(data_path + 'kaggle_dataset/dataset.csv')\n",
        "# small_dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwtWy38ehtGO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X=small_dataset['Text']\n",
        "# y=small_dataset['language']\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# print(len(X_train))\n",
        "# print(len(X_test))\n",
        "# print(len(y_train))\n",
        "# print(len(y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNoYz_IwjeY_",
        "colab_type": "text"
      },
      "source": [
        "# Embedding **data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEr8pklSjQLP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filter_out = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n1234567890'\n",
        "tokenizer = Tokenizer(filters=filter_out, lower=True)\n",
        "tokenizer.fit_on_texts(x_train.sent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5jxVwDcftcn",
        "colab_type": "text"
      },
      "source": [
        "Выбираю какое количество слов оставить. Если оставлять все, то будет 1500000, что слишком много. Можно поменять `count` и оно покажет сколько слов встречается больше, чем `count` раз"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xKQt34TAG2-",
        "colab_type": "code",
        "outputId": "713c201c-ef0d-42aa-9d11-c07c5acf3965",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# try different values of `count`\n",
        "# show how many words are presenting more than `count` times\n",
        "count = 10\n",
        "frequent_words = [w for w,c in tokenizer.word_counts.items() if c > count]\n",
        "len(frequent_words)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64157"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwDeU_wRph8C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_data(train_x, train_y, tokenizator, max_len_of_vector):\n",
        "    x_tr, x_val, y_tr, y_val = train_test_split(train_x, train_y, test_size=0.1, random_state=1, stratify=train_y.values)\n",
        "   \n",
        "    tokenizator.fit_on_texts(x_tr.sent)\n",
        "\n",
        "    train_X = tokenizator.texts_to_sequences(x_tr.sent)\n",
        "    val_X = tokenizator.texts_to_sequences(x_val.sent)\n",
        "\n",
        "    ## Pad the sentences \n",
        "    train_X = pad_sequences(train_X, maxlen=max_len_of_vector)\n",
        "    val_X = pad_sequences(val_X, maxlen=max_len_of_vector)\n",
        "\n",
        "    return (train_X, y_tr), (val_X, y_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJacuBHhHEng",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embed_size = 300 # how big is each word vector\n",
        "max_features = len(frequent_words) # how many unique words to use (i.e num rows in embedding vector)\n",
        "maxlen = 200 # max number of words in a question to use\n",
        "\n",
        "## Tokenize the sentences\n",
        "tokenizer = Tokenizer(num_words=max_features, filters=filter_out, lower=True)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qW1oK9wfHEnm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_X, train_Y), (val_X, val_Y) = prepare_data(x_train, y_train, tokenizer, maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxyyqzKsgF9K",
        "colab_type": "text"
      },
      "source": [
        "Проверила, что в тренировочном и валидационном датасетах встречаются все классы. Балансировка регулируется вот этим параметром: stratify=y_train.values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1iJF7cyU5iK",
        "colab_type": "code",
        "outputId": "0e2796e5-74ff-40f6-ffaa-9fa0044504d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(set(val_Y.values.reshape(1, -1)[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "235"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPITYtR8UqNx",
        "colab_type": "code",
        "outputId": "bd6109d0-bee2-49da-e883-fa693349294c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(set(train_Y.values.reshape(1, -1)[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "235"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYuurOSQgYUl",
        "colab_type": "text"
      },
      "source": [
        "Ниже меняю представление векторов ответов из [1, 23, 10,...] в вектор длины 235 и с 1 на месте соответсвующего языка"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0iIyf4bIXg_",
        "colab_type": "code",
        "outputId": "1f4327f6-3687-48f1-c57f-c8a171273c2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "lb = LabelEncoder()\n",
        "y = lb.fit_transform(train_Y.values.ravel())\n",
        "dummy_y_train = to_categorical(y)\n",
        "print(len(dummy_y_train))\n",
        "print(len(dummy_y_train[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "105750\n",
            "235\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCBYAruyIxUm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = lb.fit_transform(val_Y.values.ravel())\n",
        "dummy_y_val = to_categorical(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeXXgZJ6miyl",
        "colab_type": "text"
      },
      "source": [
        "# Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vp4rfHfplm6O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f1(y_true, y_pred): #taken from old keras source code\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return f1_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dzi3zyNsmNIR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def recall(y_true, y_pred): #taken from old keras source code\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    return true_positives / (possible_positives + K.epsilon())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JX13CaozmRhy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def precision(y_true, y_pred): #taken from old keras source code\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    return true_positives / (predicted_positives + K.epsilon())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtGH8P89gTXf",
        "colab_type": "text"
      },
      "source": [
        "#CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdsE9d9SjdsW",
        "colab_type": "code",
        "outputId": "ecca5700-ecb7-47aa-e69e-bf4fa056c698",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        }
      },
      "source": [
        "cnn_model = Sequential()\n",
        "cnn_model.add(Embedding(max_features, embed_size,input_shape=(maxlen,)))\n",
        "cnn_model.add(Conv1D(256, 5, activation='relu', input_shape=(embed_size,)))\n",
        "cnn_model.add(MaxPooling1D(5))\n",
        "cnn_model.add(Dropout(0.2))\n",
        "cnn_model.add(Conv1D(256, 5, activation='relu'))\n",
        "cnn_model.add(MaxPooling1D(5))\n",
        "cnn_model.add(Flatten())\n",
        "cnn_model.add(Dense(512, activation=\"relu\"))\n",
        "cnn_model.add(Dropout(0.2))\n",
        "cnn_model.add(Dense(num_classes, activation='softmax'))\n",
        "cnn_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 200, 300)          19247100  \n",
            "_________________________________________________________________\n",
            "conv1d_6 (Conv1D)            (None, 196, 256)          384256    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_6 (MaxPooling1 (None, 39, 256)           0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 39, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_7 (Conv1D)            (None, 35, 256)           327936    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_7 (MaxPooling1 (None, 7, 256)            0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 1792)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 512)               918016    \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 235)               120555    \n",
            "=================================================================\n",
            "Total params: 20,997,863\n",
            "Trainable params: 20,997,863\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sndko3XlZ806",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', f1, recall, precision])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aa9rf4_Oq6nX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn_cp_path = data_path+'model_cnn.hdf5'\n",
        "cnn_cp=ModelCheckpoint(cnn_cp_path, monitor='val_loss',save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIhz76oFHo_c",
        "colab_type": "code",
        "outputId": "1fa8e4e9-2d58-445b-c5ad-b58133c0fa86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "cnn_model.fit(train_X, dummy_y_train, batch_size=512, epochs=5, \n",
        "              validation_data=(val_X, dummy_y_val),\n",
        "              callbacks = [cnn_cp]\n",
        "             )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "207/207 [==============================] - 58s 280ms/step - loss: 3.1751 - accuracy: 0.3184 - f1: 0.2923 - recall: 0.2292 - precision: 0.5978 - val_loss: 0.7057 - val_accuracy: 0.8453 - val_f1: 0.8557 - val_recall: 0.7733 - val_precision: 0.9580\n",
            "Epoch 2/5\n",
            "207/207 [==============================] - 58s 279ms/step - loss: 0.5014 - accuracy: 0.8758 - f1: 0.8917 - recall: 0.8372 - precision: 0.9542 - val_loss: 0.4880 - val_accuracy: 0.8851 - val_f1: 0.9063 - val_recall: 0.8568 - val_precision: 0.9618\n",
            "Epoch 3/5\n",
            "207/207 [==============================] - 56s 272ms/step - loss: 0.2458 - accuracy: 0.9333 - f1: 0.9464 - recall: 0.9162 - precision: 0.9788 - val_loss: 0.5086 - val_accuracy: 0.8945 - val_f1: 0.9148 - val_recall: 0.8770 - val_precision: 0.9563\n",
            "Epoch 4/5\n",
            "207/207 [==============================] - 56s 271ms/step - loss: 0.1726 - accuracy: 0.9502 - f1: 0.9614 - recall: 0.9385 - precision: 0.9854 - val_loss: 0.5578 - val_accuracy: 0.8943 - val_f1: 0.9137 - val_recall: 0.8802 - val_precision: 0.9500\n",
            "Epoch 5/5\n",
            "207/207 [==============================] - 56s 270ms/step - loss: 0.1429 - accuracy: 0.9575 - f1: 0.9676 - recall: 0.9482 - precision: 0.9878 - val_loss: 0.6260 - val_accuracy: 0.8911 - val_f1: 0.9099 - val_recall: 0.8791 - val_precision: 0.9430\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb8e5e4e668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkmpFZmyUjF8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dependencies = {\n",
        "     'f1': f1,\n",
        "     'recall': recall,\n",
        "     'precision': precision\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qji8xqW2WiS-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cnn_model = load_model(cnn_cp_path, custom_objects=dependencies)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-T-4MO1ZR_S",
        "colab_type": "text"
      },
      "source": [
        "#RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ch0GFZ-ZSzb",
        "colab_type": "code",
        "outputId": "2d842e33-e0f9-4b8e-ae8d-e6d2b85eb4cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "rnn_model = Sequential()\n",
        "rnn_model.add(Embedding(max_features, embed_size))\n",
        "rnn_model.add(Bidirectional(LSTM(128, return_sequences=True, activation='tanh',input_dim=embed_size)))\n",
        "rnn_model.add(Dropout(0.2))\n",
        "rnn_model.add(Bidirectional(LSTM(128, return_sequences=True, activation='tanh')))\n",
        "rnn_model.add(GlobalMaxPool1D())\n",
        "rnn_model.add(Dropout(0.2))\n",
        "rnn_model.add(Dense(512, activation=\"relu\"))\n",
        "rnn_model.add(Dropout(0.2))\n",
        "rnn_model.add(Dense(num_classes, activation='softmax'))\n",
        "rnn_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 300)         19247100  \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, None, 512)         1140736   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, None, 512)         0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, None, 512)         1574912   \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 235)               120555    \n",
            "=================================================================\n",
            "Total params: 22,345,959\n",
            "Trainable params: 22,345,959\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1W3XFHXZiVR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', f1, recall, precision])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPtLB7kUrGgE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rnn_cp_path = data_path + 'model_rnn.hdf5'\n",
        "rnn_cp=ModelCheckpoint(rnn_cp_path,monitor='val_f1',save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qK-tgijZk7L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# rnn_model.fit(train_X, dummy_y_train, batch_size=512, epochs=3, \n",
        "#               validation_data=(val_X, dummy_y_val), callbacks = [rnn_cp])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kk3g4PLUumt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rnn_model = load_model(rnn_cp_path, custom_objects=dependencies)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCeuUze_qnC2",
        "colab_type": "text"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jS0Tq-Cqb4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test['sc'] = y_test\n",
        "x_test['lang'] = [class_to_language[y] for y in list(y_test.iloc[:,0])]\n",
        "x_train['sc'] = y_train\n",
        "x_train['lang'] = [class_to_language[y] for y in list(y_train.iloc[:,0])]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wowtwiinqwm0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Be careful! Tokenizer and maxlen is taken from train dataset from 1st part\n",
        "def convert(x, tokenizator, max_vector_len):\n",
        "    train_X = tokenizator.texts_to_sequences(x.sent)\n",
        "    ## Pad the sentences \n",
        "    train_X = pad_sequences(train_X, maxlen=max_vector_len)\n",
        "    return train_X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvOMHL7Nx_eO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def metr(y_true, y_pred): #taken from old keras source code\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return precision, recall, f1_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hs6AXcPcsj1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f1(y_true, y_pred):\n",
        "    y_pred = K.round(y_pred)\n",
        "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
        "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
        "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
        "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
        "\n",
        "    p = tp / (tp + fp + K.epsilon())\n",
        "    r = tp / (tp + fn + K.epsilon())\n",
        "\n",
        "    f1 = 2*p*r / (p+r+K.epsilon())\n",
        "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
        "    return max(p), max(r), max(f1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adUqSHYSc2Ye",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# New metric!\n",
        "def met(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)), axis=0)\n",
        "    false_positives = K.sum(K.round(K.clip((1 - y_true) * y_pred, 0, 1)), axis=0)\n",
        "    true_negatives = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)), axis=0)\n",
        "    false_negatives = K.sum(K.round(K.clip(y_true * (1 - y_pred), 0, 1)), axis=0)\n",
        "    precision = max(true_positives / (true_positives + false_positives  + K.epsilon()))\n",
        "    recall = max(true_positives / (true_positives + false_negatives  + K.epsilon()))\n",
        "    f1 = 2 * precision * recall / (precision + recall + K.epsilon())\n",
        "    return precision, recall, f1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OwT-3obvsIo",
        "colab_type": "text"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P006Z5Sgzeal",
        "colab_type": "code",
        "outputId": "7a6a2e2e-88c4-452b-e9c9-75f7db9b679d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ps = []\n",
        "rs = []\n",
        "fs = []\n",
        "for lan in tqdm(range(num_classes)):\n",
        "    x_t = x_test[x_test['sc'] == lan]\n",
        "    x = convert(x_t, tokenizer, maxlen)\n",
        "    y = np.zeros((x.shape[0], num_classes))\n",
        "    y[:, lan] = 1\n",
        "    y = y.astype('float32')\n",
        "    y_pred = cnn_model.predict(x)\n",
        "    p, r, f = met(y, y_pred)\n",
        "    ps.append(p.numpy())\n",
        "    rs.append(r.numpy())\n",
        "    fs.append(f.numpy())\n",
        "    #print(\"language: \", class_to_language[lan], \"precision: \", p.numpy(), \"recall: \", r.numpy(), \"f1: \", f.numpy())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 235/235 [00:58<00:00,  4.02it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jFoYvQVzg0C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_metrics = pd.DataFrame(\n",
        "    {'precision': ps,\n",
        "     'recall': rs,\n",
        "     'f1': fs\n",
        "    })"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXV6tZ4Dzh4L",
        "colab_type": "code",
        "outputId": "cfed69f4-7ed6-423a-d1f5-918cf820211f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "metrics = raw_metrics.rename(class_to_language, axis='index')\n",
        "bad_quality_metrics = metrics[metrics.f1 < 0.7]\n",
        "bad_quality_metrics"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ace</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.006</td>\n",
              "      <td>0.011928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>afr</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.060</td>\n",
              "      <td>0.113208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>als</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>amh</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.006</td>\n",
              "      <td>0.011928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ang</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>yid</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.003992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>yor</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.032</td>\n",
              "      <td>0.062016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zea</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.280</td>\n",
              "      <td>0.437500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zh-yue</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zho</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>235 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        precision  recall        f1\n",
              "ace           1.0   0.006  0.011928\n",
              "afr           1.0   0.060  0.113208\n",
              "als           0.0   0.000  0.000000\n",
              "amh           1.0   0.006  0.011928\n",
              "ang           0.0   0.000  0.000000\n",
              "...           ...     ...       ...\n",
              "yid           1.0   0.002  0.003992\n",
              "yor           1.0   0.032  0.062016\n",
              "zea           1.0   0.280  0.437500\n",
              "zh-yue        0.0   0.000  0.000000\n",
              "zho           0.0   0.000  0.000000\n",
              "\n",
              "[235 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zstxcPVgfUig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lab = labels.set_index('Label')\n",
        "bad_quality_labels = lab.loc[lab.index.intersection(bad_quality_metrics.index)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaImgEefHae0",
        "colab_type": "code",
        "outputId": "14590ea2-631c-4c00-f440-186677a42149",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        }
      },
      "source": [
        "res = pd.merge(bad_quality_labels.reset_index(), bad_quality_metrics.reset_index()).set_index('index')\n",
        "res"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Wiki Code</th>\n",
              "      <th>ISO 369-3</th>\n",
              "      <th>Language family</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ace</th>\n",
              "      <td>Achinese</td>\n",
              "      <td>ace</td>\n",
              "      <td>ace</td>\n",
              "      <td>Austronesian</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.006</td>\n",
              "      <td>0.011928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>afr</th>\n",
              "      <td>Afrikaans</td>\n",
              "      <td>af</td>\n",
              "      <td>afr</td>\n",
              "      <td>Indo-European</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.060</td>\n",
              "      <td>0.113208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>als</th>\n",
              "      <td>Alemannic German</td>\n",
              "      <td>als</td>\n",
              "      <td>gsw</td>\n",
              "      <td>Indo-European</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>amh</th>\n",
              "      <td>Amharic</td>\n",
              "      <td>am</td>\n",
              "      <td>amh</td>\n",
              "      <td>Afro-Asiatic</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.006</td>\n",
              "      <td>0.011928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ang</th>\n",
              "      <td>Old English</td>\n",
              "      <td>ang</td>\n",
              "      <td>ang</td>\n",
              "      <td>Indo-European</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>yid</th>\n",
              "      <td>Yiddish</td>\n",
              "      <td>yi</td>\n",
              "      <td>yid</td>\n",
              "      <td>Indo-European</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.003992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>yor</th>\n",
              "      <td>Yoruba</td>\n",
              "      <td>yo</td>\n",
              "      <td>yor</td>\n",
              "      <td>Niger-Congo</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.032</td>\n",
              "      <td>0.062016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zea</th>\n",
              "      <td>Zeeuws</td>\n",
              "      <td>zea</td>\n",
              "      <td>zea</td>\n",
              "      <td>Indo-European</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.280</td>\n",
              "      <td>0.437500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zh-yue</th>\n",
              "      <td>Cantonese</td>\n",
              "      <td>zh-yue</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Sino-Tibetan</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zho</th>\n",
              "      <td>Standard Chinese</td>\n",
              "      <td>zh</td>\n",
              "      <td>zho</td>\n",
              "      <td>Sino-Tibetan</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>234 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 English Wiki Code ISO 369-3  ... precision  recall        f1\n",
              "index                                         ...                            \n",
              "ace             Achinese       ace       ace  ...       1.0   0.006  0.011928\n",
              "afr            Afrikaans        af       afr  ...       1.0   0.060  0.113208\n",
              "als     Alemannic German       als       gsw  ...       0.0   0.000  0.000000\n",
              "amh              Amharic        am       amh  ...       1.0   0.006  0.011928\n",
              "ang         Old English        ang       ang  ...       0.0   0.000  0.000000\n",
              "...                  ...       ...       ...  ...       ...     ...       ...\n",
              "yid              Yiddish        yi       yid  ...       1.0   0.002  0.003992\n",
              "yor               Yoruba        yo       yor  ...       1.0   0.032  0.062016\n",
              "zea               Zeeuws       zea       zea  ...       1.0   0.280  0.437500\n",
              "zh-yue         Cantonese    zh-yue       NaN  ...       0.0   0.000  0.000000\n",
              "zho     Standard Chinese        zh       zho  ...       0.0   0.000  0.000000\n",
              "\n",
              "[234 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUkII9aS9iK1",
        "colab_type": "code",
        "outputId": "a205b2bd-8a69-410b-8e72-3b4865cfadfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        }
      },
      "source": [
        "print(x_train[x_train.sc == language_to_class['bod']].iloc[0].sent)\n",
        "print(x_train[x_train.sc == language_to_class['hrv']].iloc[0].sent)\n",
        "print(x_train[x_train.sc == language_to_class['jpn']].iloc[0].sent)\n",
        "print(x_train[x_train.sc == language_to_class['khm']].iloc[0].sent)\n",
        "print(x_train[x_train.sc == language_to_class['lzh']].iloc[0].sent)\n",
        "print(x_train[x_train.sc == language_to_class['tha']].iloc[0].sent)\n",
        "print(x_train[x_train.sc == language_to_class['wuu']].iloc[0].sent)\n",
        "print(x_train[x_train.sc == language_to_class['zho']].iloc[0].sent)\n",
        "print(x_train[x_train.sc == language_to_class['zh-yue']].iloc[0].sent)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "༡༩༣༥ལོར་ཞང་པོ་དང་ལྷན་དུ་ནན་ཅིང་དུ་སློབ་སྦྱོང་མནང་བར་ཕེབས་རྩིས་བྱས། ཕྱི་ལོར་ཀྲུང་དབྱང་ཆབ་སྲིད་སློབ་གྲྭས་བཙུགས་པའི་མོང་བོད་སློབ་གྲྭར་སློབ་སྦྱོང་མནང་བ་དང་དེ་དུས་ཅང་ཅེ་ཧྲེ་སློབ་གྲྭའི་ཞའོ་ཀྲང་གི་འགན་བཞེས་ཀྱི་ཡོད། ༡༩༣༧ལོར་རི་འགོག་དམག་འཁྲུག་ལངས་རྐྱེན་སློབ་གྲྭ་དེ་ཨན་ཧུའི་ཅུའུ་ཧ་རི་བོ་ནས་ཧུའུ་ནན་ཀྲེ་ཅང་དུ་སྤོ་དགོས་བྱུང་། དེའི་རིང་ལ་ཁོང་གི《འུ་ཧན་ལ་བསྐྱོད་ལམ》ཞེས་པའི་རྩོམ་ཡིག《ཀྲེ་ཅང་ཉིན་རེའི་ཚགས་པར》སྟེང་འགོད་མནང་བ་རེད། དེ་དུས་ཁོང་དང་གཡོན་ཕྱོགས་ཀྱི་དུས་དེབ། དེ་བཞིན་མི་སྣར་ཐོག་མའི་རྒྱུས་ལོན་བྱུང་། ༡༩༣༨ལོར་སློབ་གྲྭ་དེ་ཁྲུང་ཆིང་དུ་སྤོས། དེ་ནས་ཟུང་ཁོང་གིས་མ་ཁེ་སི་དང་ལི་ཉིང་གི་བརྩམས་ཆོས་མང་དུ་བཀླགས་རྐྱེན་ཁོང་གི་ལྟ་བ་ལི་ཉིང་གི《མི་རིགས་རང་གཙོ་དབང་ཆའི་སྐོར་གླེང་བ》ཞེས་པ་དང་ཉེ་བར་གྱུར། དེའི་ཕྱི་ལོར་ཕུན་དབང་གིས་དཀོན་མཆོག་བཀྲ་ཤིས། ངག་དབང་སྐལ་བཟང་། ཤེས་རབ། མ་རྒྱལ་དོན་གྲུབ་ལ་སོགས་པའི་སློབ་ཕྲུག་དང་མཉམ་དུ༼བོད་རིགས་གུང་ཁྲན་རིང་ལུགས་གསར་བརྗེའི་འགུལ་བསྐྱོད་ཚོགས་ཆུང༽བཙུགས་མནང་བ་དང་། ཧྲུའུ་ཅིའི་འགན་བཞེས། དེ་ནས་ཁྲུང་ཆིང་བཅའ་སྡོད་དམག་སྡེ་བརྒྱད་པའི་དོན་གཅོད་ཁང་དང་གསང་བའི་ཐོག་ནས་འབྲེལ་གཏུག་མནང་། ད་དུང་ཚོགས་ཆུང་དེའི་མིང་ཐོག་ནས་སི་ཏའ་ལིན་དང་མའོ་ཙི་ཏུང་ལ་འཕྲིན་ཡིག་བསྐུར་མནང་མཛད། ཕུན་ཚོགས་དབང་རྒྱལ་གྱིས《རྒྱལ་སྤྱིའི་གླུ》《ཀྲུང་གོའི་རྒྱལ་གླུ》སོགས་བོད་ཡིག་ཏུ་ཐོག་མར་བསྒྱུར། ༡༩༤༠ལོར་སློབ་གྲྭ་ནས་ཕྱིར་འབུད་བྱས། དེ་ནས་ཡེ་ཅན་ཡིང་གི་རོག་སྐྱོར་འོག་མ་ཁེ་སི་དང་ལེ་ཉིང་གི་བརྩམས་ཆོས་མང་དག་ཅིག་ཉོས་ནས་བོད་དུ་ལོག་ཕེབས། ༡༩༤༢ལོར་ཁོར་གིས་དར་རྩེ་མདོ་རུ༼སྐར་མ་མེའི་ཚོགས་པ༽བཙུགས་མནང་བ་དང་། དེའི་ཁོངས་མི་ལ་ངག་དབང་དང་། ཏའོ་ཏང་། དགྲ་འདུལ། ཚང་ཆོས་གྲགས་སོགས་བྱུང་། དེ་ནས་ཚོགས་པ་དེ་གོ་མིན་ཏང་གི་ཤེས་རྟོགས་བྱུང་རྗེས་ཕུན་དབང་དང་ཏའོ་ཏང་ལྷ་སར་ཕེབས་ནས༼གངས་ལྗོངས་བོད་རིགས་གུང་ཁྲན་རིང་ལུགས་གསར་བརྗེའི་ཚོགས་ཆུང༽བཙུགས། ཁོང་ཚོས་བསོད་ཁང·དབང་ཆེན་དགེ་ལེགས་བཀའ་བློན་བརྒྱུད་ནས་བཀའ་ཤག་སྲིད་གཞུང་ལ་གསར་བརྗེའི་ལས་འགུལ་སྤེལ་དགོས་པའི་རེ་བ་ཞུས་ཀྱང་སྟོང་ཟད་དུ་ཕྱིན། ༡༩༤༤ལོར་རྒྱ་གར་དུ་ཕེབས། ༡༩༤༥ལོར་ཕུན་དབང་ཡུན་ནན་བདེ་ཆེན་རྫོང་དུ་ཕེབས་ནས༼ཤར་བོད་མི་དམངས་རང་སྐྱོངས་ལྷན་ཚོགས༽གསར་བཙུགས་མཛད་པས་སྲིད་གཞུང་གིས་འཛིན་བཟུང་བཀའ་རྒྱ་བཏང་། ༡༩༧༤ལོར་ཕུན་དབང་ཆབ་མདོ་ཁུལ་དུ་ཕེབས་ནས་གཡུ་ཐོག·བཀྲ་ཤིས་དོན་གྲུབ་ཀྱིས་རོག་སྐྱོར་འོག་ལྷ་སར་ཕེབས་ཐུབ་པ་བྱུང་། ༡༩༤༩ལོར་ཕུན་དབང་སོགས་ཀྲུང་གོ་གུང་ཁྲན་ཏང་གི་གསང་བའི་ལས་དོན་སྒྲུབ་མཁན་དང་འབྲེལ་བ་ཡོད་པ་ཤེས་རྟོགས་བྱུང་ནས་བཀའ་ཤག་སྲིད་གཞུང་གིས་བོད་ནས་ཕྱིར་འབུད་བྱས། ལོ་དེའི་སྤྱི་ཟླ་༩པར་ཁོང་རྣམས་རྒྱ་གར་བརྒྱུད་ནས་ཁུན་མིང་དུ་ཕེབས། ཁོང་གིས་ས་དེ་གའི་ཀྲུང་གོ་གུང་ཁྲན་ཏང་རྩ་འཛུགས་དང་འབྲེལ་བ་བྱས་མཐར་གུང་ཁྲན་ཏང་ཡོན་ཞིག་ཏུ་གྱུར། དེ་རྗེས་འབའ་ཐང་ལ་ལོག་ཕེབས་ནས༼ཀྲུང་གོ་གུང་ཁྲན་ཏང་ཁམས་བོད་ས་མཚམས་ལས་དོན་ཨུ་ཡོན་ལྷན་ཁང༽༼ཤར་བོད་དམངས་གཙོའི་ན་གཞོན་ལྷན་ཚོགས༽གསར་འཛུགས་མཛད་པ་དང་ཧྲུའུ་ཅིའི་འགན་བཞེས།\n",
            "Oružani napad Sila Osovine na Jugoslaviju 6. travnja 1941. bio je iznenadan, a ona je tada kao institucija nestala slomom njene vojne sile. Talijanska okupacijska vojska došla je na Rab 17. travnja, a ubrzo zatim formiran je poseban oblik okupatorske vlasti - Civilni komesarijat. Rimskim ugovorom 18. svibnja 1941. godine, zaključenim između Mussolinija i Pavelića, Rab je anektiran fašističkoj Italiji. Sredinom i krajem ljeta 1943. godine utjecaj partizana na otoku stalno jača. Nakon kapitulacije Italije, do tada ilegalni partizanski NOO preuzimaju cjelokupnu upravnu i sudsku vlast na otoku. Njemačke jedinice zaposjele su Rab u drugoj polovici mjeseca ožujka 1944. godine. Kasnije je otok ustupljen NDH. Partizanska vlast (NOO) ponovno je uspostavljena nakon dolaska partizanskih jedinica i zaposjedanja otoka 12. travnja 1945. godine. Od tada do slobodnih izbora 1990. godine Rab je u sastavu SFRJ, a nakon slobodnih izbora, u sastavu neovisne i slobodne Republike Hrvatske.\n",
            "エノが行きがかりでバスに乗ってしまい、気分が悪くなった際に助けるが、今すぐバスを降りたいと運転手に頼む際、本当のことを言ってしまうと彼女が恥ずかしい思いをすると察して「僕ウンコしたいんです!!」と言ってバスを降りた。エノは内心「私もしたいみたいじゃないの」と思うも、別れ際にエノの髪を「ふわふわのお菓子みたい」と言い、この台詞に憧れていたエノに強い衝撃を与えた。この話を聞いたリコは、以後彼のことを『ウンコ王子』または『ウンコ』というあだ名で呼ぶようになったが、エノは普通に「戸田くん」と呼んでいる。\n",
            "ស្គរអារក្សជាឧបករណ៍ភ្លេងទះ តប់ដោយបាតដៃ។ ស្គរនេះមានឈ្មោះច្រើនគឺ ស្គរដៃ ស្គរអារក្ស ស្គរការ ស្គរដី ស្គរអាយ៉ៃ។ គេយកវាទៅប្រគំក្នុងវង់ភ្លេងអារក្ស វង់ភ្លេងការ វង់ភ្លេងអាយ៉ៃ និងវង់ភ្លេងកំដរពេលរាំលេងកំសាន្ត។\n",
            "武漢市，亦稱以漢，乃中華鄂省之會，亦為七大都市於中華之中原也。方八千四百六十七公里，於西元二〇一〇年計口九百七十八萬有奇。大江與漢水會此，分之三鎮，是為武昌、漢陽、漢口也。傳唐人李白至此，題詩曰：「黃鶴樓中吹玉笛，江城五月落梅花」，故亦稱之「江城」。武漢達於晚清，至民國，譽為「東方芝加哥」。經民國至共和國之初而盛。中華民國亦起此也。\n",
            "ถนนเจริญกรุง (อักษรโรมัน: Thanon Charoen Krung) เริ่มตั้งแต่ถนนสนามไชยถึงแม่น้ำเจ้าพระยาที่ถนนตก กรุงเทพมหานคร เป็นถนนรุ่นแรกที่ใช้เทคนิคการสร้างแบบตะวันตก ปัจจุบันผ่านพื้นที่เขตพระนคร เขตป้อมปราบศัตรูพ่าย เขตสัมพันธวงศ์ เขตบางรัก เขตสาทร และเขตบางคอแหลม\n",
            "UNC有得一只历史悠久个'诚信守则'。渠是由学堂个诚信法庭（Honor Court）来执行个，通过处理各种有关学生个学习帮行为浪个违规，保证了学校帮社区个权益。教授勿能因为学生仔被捉着作弊而通过任何方式处罚学生（譬如讲让迭个学生勿及格），渠必须上报畀学生总检察长。只有当由学生组成个诚信法庭裁决有罪以后，格学生再可以被惩罚。\n",
            "胡赛尼本人和小说的主人公阿米尔一样，都是出生在阿富汗首都喀布尔，少年时代便离开了这个国家。胡赛尼直到2003年小说出版之后才首次回到已经离开27年的祖国。他在苏联入侵时离开了阿富汗，而他的很多童年好友在阿富汗生活艰难，还有一些表亲离开人世，其中一位在童年时代和他一起放风筝的表兄弟就是在逃离阿富汗时死在了油罐车中（这一情节在《追风筝的人》中也有描写），而这位表兄弟的父亲也被人枪杀；因此胡赛尼总是怀有幸存者所特有的一种内疚心态，这种情感在小说中也有体现。很多人因此认为这部小说有些自传色彩。胡赛尼则表示小说中确实有一部分内容是根据自己的经历创作的，他和故事主人公也有很多相似点，但是一些内容被他刻意地模糊处理了。尽管和主人公的经历有诸多的相似点，胡赛尼仍然坚称小说情节确实是虚构的。之后胡赛尼在创作他的第二部小说《灿烂千阳》时把主人公设定为女性，称“这样应该就能一劳永逸地解决人们关于‘自传’的问题了”。\n",
            "1998年11月，一位中年女人自創燒炭自殺，將自己同燒烤爐封響沖涼房裏面。由於呢種方法之前，未有先例，相信係女死者以佢化工背景自創。因為咁，呢種自殺方法引起好多報紙大幅報導，令到好多模仿以呢種方式自殺。更適逢1997年後香港經濟低潮，有唔少人失業兼負債纍纍，以呢種方式自尋短見。結果短短兩個月就成為香港第三多人用嘅自殺方法，排響跳樓同吊頸之後。到咗第2001年，呢個方法多人用到變咗第二位。由於各傳媒咁樣繪形繪聲報導，大陸、台灣、日本都有唔少人仿效。\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dH862g-VYj8J",
        "colab_type": "text"
      },
      "source": [
        "# Fix Chinese langs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yltabFr0UYF_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_features_chinese = 10000\n",
        "\n",
        "## Tokenize the sentences\n",
        "tokenizer_chinese = Tokenizer(num_words=max_features_chinese, char_level=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuUBpVDruwFi",
        "colab_type": "code",
        "outputId": "0f30e405-ee50-49ca-b46d-61abf17f155f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        }
      },
      "source": [
        "x_train_bad = x_train.set_index('lang')\n",
        "bad_quality_langs_train = x_train_bad.loc[bad_quality_metrics.index]\n",
        "bad_quality_langs_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sent</th>\n",
              "      <th>sc</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lang</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>bod</th>\n",
              "      <td>༡༩༣༥ལོར་ཞང་པོ་དང་ལྷན་དུ་ནན་ཅིང་དུ་སློབ་སྦྱོང་མ...</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bod</th>\n",
              "      <td>བཀའ་རྩ་གསལ་བསྒྲགས་དངོས་ཤོག་གྲངས་ ༡༢ ལ་བཀོད་ཡོད...</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bod</th>\n",
              "      <td>སྤྱི་ལོ་༡༩༥༣ལོའི་ཟླ་བ་༨པར་སྨན་པས་ཁོང་གི་རྐང་པ་...</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bod</th>\n",
              "      <td>ཐ་མལ་དུ་གནས་པའི་མི་དར་མའི་སྙིང་གི་ཕར་ཚད་ནི་དུས...</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bod</th>\n",
              "      <td>ཀློང་རྡོལ་བླ་མ་རིན་པོ་ཆེའི་བརྟག་ཐབས་ནང་སྤོས་ཤེ...</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zho</th>\n",
              "      <td>赛里木湖属于封闭型的断陷湖，是地壳下沉形成洼地，由四周的高山雪水历百万年慢慢汇聚而成。如今主...</td>\n",
              "      <td>234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zho</th>\n",
              "      <td>约瑟夫·维萨里奥诺维奇·泽·朱加什维利生于俄罗斯帝国哥里，毕业于梯弗里斯神学院。成为马克思主...</td>\n",
              "      <td>234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zho</th>\n",
              "      <td>和印度其他地方一样，板球也是孟买最为流行的一项运动。板球比赛通常在遍布全市的操场上进行。后院...</td>\n",
              "      <td>234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zho</th>\n",
              "      <td>1994年，邓斯特还与薇诺娜·瑞德和克萊兒·丹妮絲一起出演了同名原著改编的电影《小妇人》，该...</td>\n",
              "      <td>234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zho</th>\n",
              "      <td>4月8日首度訪泰，在新聞發布會現場超過200名記者爭相採訪，泰國主要的7頻道及報章雜誌等均大...</td>\n",
              "      <td>234</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4500 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   sent   sc\n",
              "lang                                                        \n",
              "bod   ༡༩༣༥ལོར་ཞང་པོ་དང་ལྷན་དུ་ནན་ཅིང་དུ་སློབ་སྦྱོང་མ...   22\n",
              "bod   བཀའ་རྩ་གསལ་བསྒྲགས་དངོས་ཤོག་གྲངས་ ༡༢ ལ་བཀོད་ཡོད...   22\n",
              "bod   སྤྱི་ལོ་༡༩༥༣ལོའི་ཟླ་བ་༨པར་སྨན་པས་ཁོང་གི་རྐང་པ་...   22\n",
              "bod   ཐ་མལ་དུ་གནས་པའི་མི་དར་མའི་སྙིང་གི་ཕར་ཚད་ནི་དུས...   22\n",
              "bod   ཀློང་རྡོལ་བླ་མ་རིན་པོ་ཆེའི་བརྟག་ཐབས་ནང་སྤོས་ཤེ...   22\n",
              "...                                                 ...  ...\n",
              "zho   赛里木湖属于封闭型的断陷湖，是地壳下沉形成洼地，由四周的高山雪水历百万年慢慢汇聚而成。如今主...  234\n",
              "zho   约瑟夫·维萨里奥诺维奇·泽·朱加什维利生于俄罗斯帝国哥里，毕业于梯弗里斯神学院。成为马克思主...  234\n",
              "zho   和印度其他地方一样，板球也是孟买最为流行的一项运动。板球比赛通常在遍布全市的操场上进行。后院...  234\n",
              "zho   1994年，邓斯特还与薇诺娜·瑞德和克萊兒·丹妮絲一起出演了同名原著改编的电影《小妇人》，该...  234\n",
              "zho   4月8日首度訪泰，在新聞發布會現場超過200名記者爭相採訪，泰國主要的7頻道及報章雜誌等均大...  234\n",
              "\n",
              "[4500 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXhcTGMaYZXt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_X_chinese, train_Y_chinese), (val_X_chinese, val_Y_chinese) = \\\n",
        "prepare_data(bad_quality_langs_train, bad_quality_langs_train.sc, tokenizer_chinese, maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IA91PJA_Nvio",
        "colab_type": "code",
        "outputId": "a26fcd30-9e03-48cf-bdb8-b0ad38ee7a00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "chinese_labels_dict = {lang:index for index, lang in enumerate(set(train_Y_chinese))}\n",
        "chinese_labels_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{22: 6, 77: 4, 92: 8, 99: 0, 123: 7, 207: 5, 227: 1, 233: 2, 234: 3}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubiHl-tGxu89",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dummy_y_train_chinese = to_categorical([chinese_labels_dict[lan] for lan in train_Y_chinese])\n",
        "dummy_y_val_chinese = to_categorical([chinese_labels_dict[lan] for lan in val_Y_chinese])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1Px5m0yyLUA",
        "colab_type": "code",
        "outputId": "43380ac7-7c0f-4020-f1b8-f5977af1b759",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        }
      },
      "source": [
        "cnn_model_chinese = Sequential()\n",
        "cnn_model_chinese.add(Embedding(max_features, embed_size,input_shape=(maxlen,)))\n",
        "cnn_model_chinese.add(Conv1D(256, 5, activation='relu', input_shape=(embed_size,)))\n",
        "cnn_model_chinese.add(MaxPooling1D(5))\n",
        "cnn_model_chinese.add(Dropout(0.2))\n",
        "cnn_model_chinese.add(Conv1D(256, 5, activation='relu'))\n",
        "cnn_model_chinese.add(MaxPooling1D(5))\n",
        "cnn_model_chinese.add(Flatten())\n",
        "cnn_model_chinese.add(Dense(512, activation=\"relu\"))\n",
        "cnn_model_chinese.add(Dropout(0.2))\n",
        "cnn_model_chinese.add(Dense(len(dummy_y_train_chinese[0]), activation='softmax'))\n",
        "cnn_model_chinese.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 200, 300)          19247100  \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 196, 256)          384256    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_4 (MaxPooling1 (None, 39, 256)           0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 39, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 35, 256)           327936    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_5 (MaxPooling1 (None, 7, 256)            0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 1792)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 512)               918016    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 9)                 4617      \n",
            "=================================================================\n",
            "Total params: 20,881,925\n",
            "Trainable params: 20,881,925\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlFTZRq8ya9i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn_model_chinese.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', f1, recall, precision])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QiHi0eYrgaU",
        "colab_type": "code",
        "outputId": "d0dbfbb9-ed23-493b-8018-337b391aa85e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "cnn_model_chinese.fit(train_X_chinese, dummy_y_train_chinese, batch_size=128, epochs=10, \n",
        "              validation_data=(val_X_chinese, dummy_y_val_chinese))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "8/8 [==============================] - 2s 237ms/step - loss: 0.0096 - accuracy: 0.9970 - f1: 0.9973 - recall: 0.9958 - precision: 0.9988 - val_loss: 0.2196 - val_accuracy: 0.9489 - val_f1: 0.9477 - val_recall: 0.9467 - val_precision: 0.9488\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 2s 237ms/step - loss: 0.0070 - accuracy: 0.9985 - f1: 0.9981 - recall: 0.9975 - precision: 0.9988 - val_loss: 0.2061 - val_accuracy: 0.9600 - val_f1: 0.9600 - val_recall: 0.9600 - val_precision: 0.9600\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 2s 239ms/step - loss: 0.0047 - accuracy: 0.9995 - f1: 0.9991 - recall: 0.9985 - precision: 0.9998 - val_loss: 0.2146 - val_accuracy: 0.9556 - val_f1: 0.9544 - val_recall: 0.9533 - val_precision: 0.9555\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 2s 233ms/step - loss: 0.0046 - accuracy: 0.9990 - f1: 0.9988 - recall: 0.9983 - precision: 0.9993 - val_loss: 0.2148 - val_accuracy: 0.9556 - val_f1: 0.9556 - val_recall: 0.9556 - val_precision: 0.9556\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 2s 240ms/step - loss: 0.0031 - accuracy: 1.0000 - f1: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.2138 - val_accuracy: 0.9578 - val_f1: 0.9588 - val_recall: 0.9578 - val_precision: 0.9599\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 2s 244ms/step - loss: 0.0027 - accuracy: 0.9998 - f1: 0.9996 - recall: 0.9995 - precision: 0.9997 - val_loss: 0.2099 - val_accuracy: 0.9600 - val_f1: 0.9611 - val_recall: 0.9600 - val_precision: 0.9621\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 2s 238ms/step - loss: 0.0025 - accuracy: 0.9998 - f1: 0.9998 - recall: 0.9998 - precision: 0.9998 - val_loss: 0.2082 - val_accuracy: 0.9600 - val_f1: 0.9588 - val_recall: 0.9578 - val_precision: 0.9599\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 2s 233ms/step - loss: 0.0034 - accuracy: 0.9990 - f1: 0.9990 - recall: 0.9990 - precision: 0.9990 - val_loss: 0.2101 - val_accuracy: 0.9533 - val_f1: 0.9565 - val_recall: 0.9533 - val_precision: 0.9597\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 2s 235ms/step - loss: 0.0018 - accuracy: 1.0000 - f1: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.2107 - val_accuracy: 0.9600 - val_f1: 0.9611 - val_recall: 0.9600 - val_precision: 0.9621\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 2s 240ms/step - loss: 0.0015 - accuracy: 1.0000 - f1: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.2198 - val_accuracy: 0.9600 - val_f1: 0.9600 - val_recall: 0.9600 - val_precision: 0.9600\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb8e91b6da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWwS0BKMsUGO",
        "colab_type": "code",
        "outputId": "c52f78fc-dfb3-4fab-bc9d-e70ff63a3367",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "ps_chinese = []\n",
        "rs_chinese = []\n",
        "fs_chinese = []\n",
        "short_len = len(set(train_Y_chinese))\n",
        "\n",
        "for lan in set(train_Y_chinese):\n",
        "    x_t = x_test[x_test['sc'] == lan]\n",
        "    x = convert(x_t, tokenizer_chinese, maxlen)\n",
        "    y = np.zeros((x.shape[0], short_len))\n",
        "    y[:, chinese_labels_dict[lan]] = 1\n",
        "    y = y.astype('float32')\n",
        "    y_pred = cnn_model_chinese.predict(x)\n",
        "    p, r, f = met(y, y_pred)\n",
        "    ps_chinese.append(p.numpy())\n",
        "    rs_chinese.append(r.numpy())\n",
        "    fs_chinese.append(f.numpy())\n",
        "    print(\"language: \", class_to_language[lan], \"precision: \", p.numpy(), \"recall: \", r.numpy(), \"f1: \", f.numpy())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "language:  khm precision:  1.0 recall:  0.966 f1:  0.98270595\n",
            "language:  wuu precision:  1.0 recall:  0.896 f1:  0.94514763\n",
            "language:  zh-yue precision:  1.0 recall:  0.928 f1:  0.96265554\n",
            "language:  zho precision:  1.0 recall:  0.936 f1:  0.9669421\n",
            "language:  hrv precision:  1.0 recall:  0.992 f1:  0.99598384\n",
            "language:  tha precision:  1.0 recall:  0.988 f1:  0.9939637\n",
            "language:  bod precision:  1.0 recall:  0.998 f1:  0.99899894\n",
            "language:  lzh precision:  1.0 recall:  0.994 f1:  0.996991\n",
            "language:  jpn precision:  1.0 recall:  0.998 f1:  0.99899894\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qimQESgMQpVG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JakikCyXZA0m",
        "colab_type": "text"
      },
      "source": [
        "#Hanna's try for merging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AszQrmS7ZeTd",
        "colab": {}
      },
      "source": [
        "filter_out = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n1234567890'\n",
        "## Tokenize the sentences\n",
        "tokenizer = Tokenizer(filters=filter_out, char_level=True)\n",
        "tokenizer.fit_on_texts(x_train.sent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HORVrXGGZDYZ",
        "colab_type": "code",
        "outputId": "3f541299-5ceb-46a1-d897-d87d75abf726",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# try different values of `count`\n",
        "# show how many words are presenting more than `count` times\n",
        "count = 0\n",
        "frequent_words = [w for w,c in tokenizer.word_counts.items() if c > count]\n",
        "len(frequent_words)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10489"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5VnelMpbh1z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer.fit_on_texts(x_train.sent)\n",
        "\n",
        "train_X = tokenizer.texts_to_sequences(x_train.sent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cppm020qbwi7",
        "colab_type": "code",
        "outputId": "52c0fe5b-3480-4ba6-e8af-c015239f554e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "lens = [len(train_X[i]) for i in range(len(train_X))]\n",
        "plt.hist(lens, bins=np.linspace(0,1000,20), facecolor='blue', alpha=0.9)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVPnHv12cujE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXvyyaJAcsoE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_data(train_x, train_y, tokenizer_char, tokenizer_word, maxlen_char, maxlen_word):\n",
        "    x_tr, x_val, y_tr, y_val = train_test_split(train_x, train_y, test_size=0.1, random_state=1, stratify=train_y.values)\n",
        "\n",
        "    train_X_char = tokenizer_char.texts_to_sequences(x_tr.sent)\n",
        "    val_X_char = tokenizer_char.texts_to_sequences(x_val.sent)\n",
        "\n",
        "    train_X_word = tokenizer_word.texts_to_sequences(x_tr.sent)\n",
        "    val_X_word = tokenizer_word.texts_to_sequences(x_val.sent)\n",
        "\n",
        "    ## Pad chars\n",
        "    train_X_char = pad_sequences(train_X_char, maxlen=maxlen_char)\n",
        "    val_X_char = pad_sequences(val_X_char, maxlen=maxlen_char)\n",
        "\n",
        "    ## Pad words\n",
        "    train_X_word = pad_sequences(train_X_word, maxlen=maxlen_word)\n",
        "    val_X_word = pad_sequences(val_X_word, maxlen=maxlen_word)\n",
        "\n",
        "    return ((train_X_char, train_X_word), y_tr), ((val_X_char, val_X_word), y_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TA8yhaT7cstt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filter_out = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n1234567890'\n",
        "\n",
        "maxlen_char = 500\n",
        "maxlen_word = 200\n",
        "\n",
        "max_features_words = 64157\n",
        "max_features_chars = 10489\n",
        "\n",
        "## Tokenize words\n",
        "tokenizer_words = Tokenizer(num_words=max_features_words, filters=filter_out, lower=True)  \n",
        "tokenizer_words.fit_on_texts(x_train.sent)\n",
        "\n",
        "## Tokenize chars\n",
        "tokenizer_char = Tokenizer(num_words=max_features_chars, filters=filter_out, char_level=True)\n",
        "tokenizer_char.fit_on_texts(x_train.sent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlPh-tgucsrY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "((train_X_char, train_X_word), train_Y), ((val_X_char, val_X_word), val_Y) = prepare_data(x_train, y_train, tokenizer_char, tokenizer_words, maxlen_char, maxlen_word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a7c43bfa-ef86-4d96-c07b-9426929a90d9",
        "id": "P_Ra_ggYfnkP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(set(val_Y.values.reshape(1, -1)[0]))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "235"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "3a5d307c-ea47-412c-ff7b-f199e9862094",
        "id": "6WdpDN9vfnkU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(set(train_Y.values.reshape(1, -1)[0]))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "235"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oG-2AAm8fnkW"
      },
      "source": [
        "Ниже меняю представление векторов ответов из [1, 23, 10,...] в вектор длины 235 и с 1 на месте соответсвующего языка"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d025249b-12ce-4648-b325-5686f2028e6b",
        "id": "sZZ5EXTvfnkW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "lb = LabelEncoder()\n",
        "y = lb.fit_transform(train_Y.values)\n",
        "dummy_y_train = to_categorical(y)\n",
        "print(len(dummy_y_train))\n",
        "print(len(dummy_y_train[0]))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "105750\n",
            "235\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:251: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0a3a3b57-3497-4cf7-e87a-35a2f4535b1b",
        "id": "hmbJkbgGfnka",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "y = lb.fit_transform(val_Y.values)\n",
        "dummy_y_val = to_categorical(y)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:251: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWqoMTcofr1-",
        "colab_type": "text"
      },
      "source": [
        "# Model with two embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1M7jq0xq86d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embed_size = 300\n",
        "def create_double_cnn():\n",
        "    inp_char = Input(shape=(maxlen_char,))\n",
        "    inp_word = Input(shape=(maxlen_word,))\n",
        "\n",
        "    x1 = Embedding(max_features_chars, embed_size, input_shape=(maxlen_char,))(inp_char)\n",
        "    x2 = Embedding(max_features_words, embed_size, input_shape=(maxlen_word,))(inp_word)\n",
        "\n",
        "    concatted = tf.keras.layers.Concatenate(axis=1)([x1, x2])\n",
        "\n",
        "    lay = Conv1D(256, 5, activation='relu')(concatted)\n",
        "    lay = MaxPooling1D(5)(lay)\n",
        "    lay = Dropout(0.2)(lay)\n",
        "\n",
        "    lay = Conv1D(256, 5, activation='relu')(lay)\n",
        "    lay = MaxPooling1D(5)(lay)\n",
        "    lay = Flatten()(lay)\n",
        "\n",
        "    lay = Dense(512, activation=\"relu\")(lay)\n",
        "    lay = Dropout(0.2)(lay)\n",
        "\n",
        "    lay = Dense(num_classes, activation='softmax')(lay)\n",
        "    return Model(inputs=[inp_char, inp_word], outputs=lay)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWZbr61b7BeF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "double_model = create_double_cnn()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIJ61uEdsONc",
        "colab_type": "code",
        "outputId": "ab93febf-a9cb-4df7-a1c4-7ba3f21eaa60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        }
      },
      "source": [
        "\n",
        "double_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf.metrics.categorical_accuracy, f1, precision, recall])\n",
        "print(double_model.summary())"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            [(None, 500)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_8 (InputLayer)            [(None, 200)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_4 (Embedding)         (None, 500, 300)     3146700     input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_5 (Embedding)         (None, 200, 300)     19247100    input_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 700, 300)     0           embedding_4[0][0]                \n",
            "                                                                 embedding_5[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4 (Conv1D)               (None, 696, 256)     384256      concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_4 (MaxPooling1D)  (None, 139, 256)     0           conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 139, 256)     0           max_pooling1d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_5 (Conv1D)               (None, 135, 256)     327936      dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_5 (MaxPooling1D)  (None, 27, 256)      0           conv1d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 6912)         0           max_pooling1d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 512)          3539456     flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 512)          0           dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 235)          120555      dropout_5[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 26,766,003\n",
            "Trainable params: 26,766,003\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nwSTVaDwxydc",
        "colab": {}
      },
      "source": [
        "double_cp_path = data_path+'model_double.hdf5'\n",
        "double_cp=ModelCheckpoint(double_cp_path, monitor='val_loss',save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9e7bc1d7-de25-41ed-8b0a-fbe20e18f85f",
        "id": "fFkm8zFufy_a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "double_model.fit([train_X_char, train_X_word], dummy_y_train, batch_size=512, epochs=5, \n",
        "              validation_data=([val_X_char, val_X_word], dummy_y_val),\n",
        "               callbacks = [double_cp]\n",
        "             )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "207/207 [==============================] - 193s 932ms/step - loss: 2.4694 - categorical_accuracy: 0.4443 - f1: 0.4305 - precision: 0.6856 - recall: 0.3567 - val_loss: 0.5025 - val_categorical_accuracy: 0.8803 - val_f1: 0.8886 - val_precision: 0.9529 - val_recall: 0.8326\n",
            "Epoch 2/5\n",
            "207/207 [==============================] - 193s 934ms/step - loss: 0.3772 - categorical_accuracy: 0.9061 - f1: 0.9136 - precision: 0.9530 - recall: 0.8775 - val_loss: 0.3327 - val_categorical_accuracy: 0.9226 - val_f1: 0.9320 - val_precision: 0.9611 - val_recall: 0.9047\n",
            "Epoch 3/5\n",
            " 38/207 [====>.........................] - ETA: 2:29 - loss: 0.1873 - categorical_accuracy: 0.9551 - f1: 0.9587 - precision: 0.9794 - recall: 0.9389"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nU3Grknm3WRK",
        "colab_type": "text"
      },
      "source": [
        "# RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "28HMvK9S3cW9",
        "colab": {}
      },
      "source": [
        "def create_double_rnn():\n",
        "    inp_char = Input(shape=(maxlen_char,))\n",
        "    inp_word = Input(shape=(maxlen_word,))\n",
        "\n",
        "    x1 = Embedding(max_features_chars, embed_size, input_shape=(maxlen_char,))(inp_char)\n",
        "    x2 = Embedding(max_features_words, embed_size, input_shape=(maxlen_word,))(inp_word)\n",
        "\n",
        "    concatted = tf.keras.layers.Concatenate(axis=1)([x1, x2])\n",
        "\n",
        "    lay = Bidirectional(LSTM(150, return_sequences=True, activation='tanh',input_dim=embed_size))(concatted)\n",
        "    lay = Dropout(0.2)(lay)\n",
        "\n",
        "    lay = Bidirectional(LSTM(150, return_sequences=True, activation='tanh',input_dim=embed_size))(lay)\n",
        "    lay = Dropout(0.2)(lay)\n",
        "    lay = GlobalMaxPool1D()(lay)\n",
        "\n",
        "    lay = Dense(512, activation=\"relu\")(lay)\n",
        "    lay = Dropout(0.2)(lay)\n",
        "\n",
        "    lay = Dense(num_classes, activation='softmax')(lay)\n",
        "    return Model(inputs=[inp_char, inp_word], outputs=lay)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ubbiWaky3cXB",
        "colab": {}
      },
      "source": [
        "double_rnn_model = create_double_rnn()\n",
        "double_rnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf.metrics.categorical_accuracy, f1_met, precision, recall])\n",
        "print(double_rnn_model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7d78KEhF3cXE",
        "colab": {}
      },
      "source": [
        "double_rnn_cp_path = data_path+'model_rnn_double.hdf5'\n",
        "double_rnn_cp=ModelCheckpoint(double_rnn_cp_path, monitor='val_loss',save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "5032cb12-ebfa-4c21-d16b-fd528ffac57a",
        "id": "hUbN_l1V3cXH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "double_rnn_model.fit([train_X_char, train_X_word], dummy_y_train, batch_size=512, epochs=7, \n",
        "              validation_data=([val_X_char, val_X_word], dummy_y_val),\n",
        "               callbacks = [double_cp]\n",
        "             )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "207/207 [==============================] - 202s 978ms/step - loss: 3.0349 - categorical_accuracy: 0.2906 - f1_met: 0.1364 - precision: 0.1603 - recall: 0.1281 - val_loss: 1.0926 - val_categorical_accuracy: 0.7745 - val_f1_met: 0.4468 - val_precision: 0.4972 - val_recall: 0.4264\n",
            "Epoch 2/4\n",
            "207/207 [==============================] - 202s 975ms/step - loss: 0.5729 - categorical_accuracy: 0.8619 - f1_met: 0.7208 - precision: 0.7657 - recall: 0.7063 - val_loss: 0.4369 - val_categorical_accuracy: 0.9067 - val_f1_met: 0.7790 - val_precision: 0.8156 - val_recall: 0.7638\n",
            "Epoch 3/4\n",
            "207/207 [==============================] - 202s 978ms/step - loss: 0.2365 - categorical_accuracy: 0.9437 - f1_met: 0.8311 - precision: 0.8499 - recall: 0.8258 - val_loss: 0.3671 - val_categorical_accuracy: 0.9192 - val_f1_met: 0.8058 - val_precision: 0.8346 - val_recall: 0.7954\n",
            "Epoch 4/4\n",
            "207/207 [==============================] - 202s 976ms/step - loss: 0.1420 - categorical_accuracy: 0.9663 - f1_met: 0.8543 - precision: 0.8659 - recall: 0.8511 - val_loss: 0.3634 - val_categorical_accuracy: 0.9227 - val_f1_met: 0.8143 - val_precision: 0.8385 - val_recall: 0.8075\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7ca12f4d68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 284
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XRmhIRA2ifgE"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LIXo-d-MifgK",
        "colab": {}
      },
      "source": [
        "x_test['sc'] = y_test\n",
        "x_test['lang'] = [class_to_language[y] for y in list(y_test.iloc[:,0])]\n",
        "x_train['sc'] = y_train\n",
        "x_train['lang'] = [class_to_language[y] for y in list(y_train.iloc[:,0])]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbsUXroCik0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert(x, tokenizer_char, tokenizer_word, maxlen_char, maxlen_word):\n",
        "    X_char = tokenizer_char.texts_to_sequences(x.sent)\n",
        "    X_word = tokenizer_word.texts_to_sequences(x.sent)\n",
        "\n",
        "    ## Pad chars\n",
        "    X_char = pad_sequences(X_char, maxlen=maxlen_char)\n",
        "\n",
        "    ## Pad words\n",
        "    X_word = pad_sequences(X_word, maxlen=maxlen_word)\n",
        "\n",
        "    return (X_char, X_word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUYVAmRe1tEz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# New metric!\n",
        "def met(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)), axis=0)\n",
        "    false_positives = K.sum(K.round(K.clip((1 - y_true) * y_pred, 0, 1)), axis=0)\n",
        "    true_negatives = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)), axis=0)\n",
        "    false_negatives = K.sum(K.round(K.clip(y_true * (1 - y_pred), 0, 1)), axis=0)\n",
        "    precision = true_positives / (true_positives + false_positives  + K.epsilon())\n",
        "    recall = true_positives / (true_positives + false_negatives  + K.epsilon())\n",
        "    f1 = 2 * precision * recall / (precision + recall + K.epsilon())\n",
        "    return precision, recall, f1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eXHS2UEkifgX"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g20c21Q-ns24",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_char, x_word = convert(x_test, tokenizer_char, tokenizer_words, maxlen_char, maxlen_word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXvca94Vn7mx",
        "colab_type": "code",
        "outputId": "47d379fb-12f4-429f-9b56-400b04629011",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "y = lb.fit_transform(y_test.values)\n",
        "dummy_y_test = to_categorical(y)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:251: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViVAmYQMns7L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "e80ca74f-522d-4977-9125-461de0b6ecec"
      },
      "source": [
        "y_pred_rnn = double_rnn_model.predict([x_char, x_word])"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-d7748be18fff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred_rnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdouble_rnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_char\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_word\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'double_rnn_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dA8vNiBMok1F",
        "colab": {}
      },
      "source": [
        "p, r, f = met(dummy_y_test, y_pred_rnn)\n",
        "raw_metrics_rnn = pd.DataFrame(\n",
        "    {'precision': p,\n",
        "     'recall': r,\n",
        "     'f1': f\n",
        "    })\n",
        "metrics_rnn = raw_metrics_rnn.rename(class_to_language, axis='index')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lewvapp4ns-j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_cnn = double_model.predict([x_char, x_word])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gT5N-zsBok1P",
        "colab": {}
      },
      "source": [
        "p, r, f = met(dummy_y_test, y_pred_cnn)\n",
        "raw_metrics_cnn = pd.DataFrame(\n",
        "    {'precision': p,\n",
        "     'recall': r,\n",
        "     'f1': f\n",
        "    })\n",
        "metrics_cnn = raw_metrics_cnn.rename(class_to_language, axis='index')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "5f333614-9b03-4648-a1f5-fe57c4d0f424",
        "id": "8NPx1FlIok1R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "metrics_rnn[metrics_rnn.f1 < 0.7]"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>bos</th>\n",
              "      <td>0.634078</td>\n",
              "      <td>0.454</td>\n",
              "      <td>0.529137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cbk</th>\n",
              "      <td>0.921502</td>\n",
              "      <td>0.540</td>\n",
              "      <td>0.680958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>eng</th>\n",
              "      <td>0.610837</td>\n",
              "      <td>0.496</td>\n",
              "      <td>0.547461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hbs</th>\n",
              "      <td>0.480541</td>\n",
              "      <td>0.568</td>\n",
              "      <td>0.520623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hrv</th>\n",
              "      <td>0.681319</td>\n",
              "      <td>0.124</td>\n",
              "      <td>0.209814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>spa</th>\n",
              "      <td>0.657426</td>\n",
              "      <td>0.664</td>\n",
              "      <td>0.660696</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     precision  recall        f1\n",
              "bos   0.634078   0.454  0.529137\n",
              "cbk   0.921502   0.540  0.680958\n",
              "eng   0.610837   0.496  0.547461\n",
              "hbs   0.480541   0.568  0.520623\n",
              "hrv   0.681319   0.124  0.209814\n",
              "spa   0.657426   0.664  0.660696"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_4vq2x09TcD",
        "colab_type": "code",
        "outputId": "ce687a7f-8ab1-4cbd-8dc9-797113395904",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "metrics_rnn[metrics_rnn.f1 > 0.95].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(121, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 303
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O677cW306pID",
        "colab_type": "code",
        "outputId": "63cba974-e4ab-4c56-98f1-0d4828d272ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "metrics_cnn[metrics_cnn.f1 < 0.7]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>bos</th>\n",
              "      <td>0.551402</td>\n",
              "      <td>0.590</td>\n",
              "      <td>0.570048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>eng</th>\n",
              "      <td>0.607921</td>\n",
              "      <td>0.614</td>\n",
              "      <td>0.610945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hbs</th>\n",
              "      <td>0.566667</td>\n",
              "      <td>0.374</td>\n",
              "      <td>0.450602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hrv</th>\n",
              "      <td>0.545692</td>\n",
              "      <td>0.418</td>\n",
              "      <td>0.473386</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     precision  recall        f1\n",
              "bos   0.551402   0.590  0.570048\n",
              "eng   0.607921   0.614  0.610945\n",
              "hbs   0.566667   0.374  0.450602\n",
              "hrv   0.545692   0.418  0.473386"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 293
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZNJ0JpJ9Wid",
        "colab_type": "code",
        "outputId": "9d4f42e4-c5df-4b86-f537-ea10eebcd88d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "metrics_cnn[metrics_cnn.f1 > 0.95].shape"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(120, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clcmJUe-zXo3",
        "colab_type": "text"
      },
      "source": [
        "# My"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQZTpyljpG4R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my = pd.DataFrame(\n",
        "    {'sent': ['English is a West Germanic language that was first spoken in early medieval England and eventually became a global lingua franca.[4][5] It is named after the Angles, one of the ancient Germanic peoples that migrated to the area of Great Britain that later took their name, England. Both names derive from Anglia, ',\n",
        "              'язык англо-фризской подгруппы западной группы германской ветви индоевропейской языковой семьи. Английский язык — важнейший международный язык[4], что является следствием колониальной политики Британской империи в XIX веке и мирового влияния США в XX—XXI веках. Существует значительное разнообразие диалектов и говоров английского языка.',\n",
        "              'Produkcja aparatów fotograficznych w kijowskich zakładach Arsenal rozpoczęła się od przeniesienia w 1946 r. z Drezna całej, ledwie uruchomionej po zniszczeniach wojennych linii produkcyjnej aparatów małoobrazkowych Contax, wraz z zatrudnionymi przy niej fachowcami. ',\n",
        "              'З 1944 года дзейнічае Дзяржаўны літаратурны музей Янкі Купалы. У гонар паэта ў 1957 годзе была заснавана Літаратурная прэмія імя Янкі Купалы. З 1995 года сістэматычна праводзяцца штогадовыя Купалаўскія чытанні — прафесійны форум для абмеркавання навуковых дасягненняў і праблем купалазнаўства.'\n",
        "              ],\n",
        "    })"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaQacjIxzfP2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_char, x_word = convert(my, tokenizer_char, tokenizer_words, maxlen_char, maxlen_word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1vdlKvpz6rs",
        "colab_type": "code",
        "outputId": "1ba7a91c-8500-46b3-f95d-15bbca31c137",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ys = double_model.predict([x_char, x_word])\n",
        "ys.argmax(axis=1)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 50, 177, 168,  18])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RkJ4yjnnrwv",
        "colab_type": "code",
        "outputId": "d133328b-5f08-4b8f-b100-3162a0856046",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ys = double_rnn_model.predict([x_char, x_word])\n",
        "ys.argmax(axis=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([228, 177, 168,  18])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 297
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csZ668ko9ENQ",
        "colab_type": "code",
        "outputId": "e3bcd1fe-3999-4520-be23-91eaf8425aab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "class_to_language[164]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'pcd'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 298
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUQrR-s29G5I",
        "colab_type": "code",
        "outputId": "4c82edf4-7801-441a-cf88-0fddf1855086",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "class_to_language[228]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'xho'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 299
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gnA4ZEn0v2d",
        "colab_type": "code",
        "outputId": "0d2be843-9d29-43f6-977e-0fd97b5f22ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "class_to_language[50]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'eng'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 236
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uo6mDP6GzmDX",
        "colab_type": "code",
        "outputId": "b7e5b8d9-1c88-4110-a8bd-246f85202765",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "class_to_language[177]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'rus'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 237
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6UjGQGmzrs0",
        "colab_type": "code",
        "outputId": "c7fe0aed-7f10-43de-8d60-bc7e977e2d60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "class_to_language[168]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'pol'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 238
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6n7eluk1zyIS",
        "colab_type": "code",
        "outputId": "2a491c12-155e-4b71-e12e-502006fa27f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "class_to_language[18]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'bel'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 239
        }
      ]
    }
  ]
}